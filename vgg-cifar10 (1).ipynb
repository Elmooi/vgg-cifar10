{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7904dc9b-3a1b-4de7-8a47-c351ad164ceb",
   "metadata": {},
   "source": [
    "커널사이즈 수정 ,\n",
    "맥스풀링 삭제,\n",
    "레이어 삭제하고 vgg11비슷하게,\n",
    "dropout 삭제,\n",
    "중간에 batch normal 넣는거 vs 안넣는거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596417ef-6f5f-41a8-bd4c-9666fe11fe1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7cbb3fe-a521-4cf9-bb1e-d1c5fb64ccd7",
   "metadata": {},
   "source": [
    "1. 커널 사이즈 수정 2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34528e0-d75b-4ebe-9e23-a35eb78861fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "2.10.0\n",
      "Epoch 1/2500\n",
      "Epoch 1/2500 - Train Accuracy: 0.3969 - Val Accuracy: 0.3944 - Test Accuracy: 0.4032\n",
      "312/312 - 144s - loss: 12.5994 - accuracy: 0.3315 - val_loss: 9.6911 - val_accuracy: 0.3944 - lr: 0.1000 - 144s/epoch - 462ms/step\n",
      "Epoch 2/2500\n",
      "Epoch 2/2500 - Train Accuracy: 0.3552 - Val Accuracy: 0.3530 - Test Accuracy: 0.3584\n",
      "312/312 - 128s - loss: 7.5228 - accuracy: 0.4536 - val_loss: 6.1274 - val_accuracy: 0.3530 - lr: 0.1000 - 128s/epoch - 411ms/step\n",
      "Epoch 3/2500\n",
      "Epoch 3/2500 - Train Accuracy: 0.3952 - Val Accuracy: 0.3953 - Test Accuracy: 0.3828\n",
      "312/312 - 128s - loss: 4.6783 - accuracy: 0.5115 - val_loss: 4.1460 - val_accuracy: 0.3953 - lr: 0.1000 - 128s/epoch - 410ms/step\n",
      "Epoch 4/2500\n",
      "Epoch 4/2500 - Train Accuracy: 0.4530 - Val Accuracy: 0.4439 - Test Accuracy: 0.4549\n",
      "312/312 - 128s - loss: 3.1654 - accuracy: 0.5561 - val_loss: 3.0853 - val_accuracy: 0.4439 - lr: 0.1000 - 128s/epoch - 411ms/step\n",
      "Epoch 5/2500\n",
      "Epoch 5/2500 - Train Accuracy: 0.5237 - Val Accuracy: 0.5117 - Test Accuracy: 0.5045\n",
      "312/312 - 129s - loss: 2.3465 - accuracy: 0.5940 - val_loss: 2.3886 - val_accuracy: 0.5117 - lr: 0.1000 - 129s/epoch - 412ms/step\n",
      "Epoch 6/2500\n",
      "Epoch 6/2500 - Train Accuracy: 0.5682 - Val Accuracy: 0.5561 - Test Accuracy: 0.5578\n",
      "312/312 - 128s - loss: 1.9073 - accuracy: 0.6202 - val_loss: 2.0647 - val_accuracy: 0.5561 - lr: 0.1000 - 128s/epoch - 410ms/step\n",
      "Epoch 7/2500\n",
      "Epoch 7/2500 - Train Accuracy: 0.6270 - Val Accuracy: 0.6160 - Test Accuracy: 0.6080\n",
      "312/312 - 128s - loss: 1.6776 - accuracy: 0.6430 - val_loss: 1.8375 - val_accuracy: 0.6160 - lr: 0.1000 - 128s/epoch - 411ms/step\n",
      "Epoch 8/2500\n",
      "Epoch 8/2500 - Train Accuracy: 0.6968 - Val Accuracy: 0.6810 - Test Accuracy: 0.6841\n",
      "312/312 - 128s - loss: 1.5522 - accuracy: 0.6675 - val_loss: 1.5087 - val_accuracy: 0.6810 - lr: 0.1000 - 128s/epoch - 411ms/step\n",
      "Epoch 9/2500\n",
      "Epoch 9/2500 - Train Accuracy: 0.7168 - Val Accuracy: 0.6995 - Test Accuracy: 0.6963\n",
      "312/312 - 128s - loss: 1.5086 - accuracy: 0.6787 - val_loss: 1.4512 - val_accuracy: 0.6995 - lr: 0.1000 - 128s/epoch - 410ms/step\n",
      "Epoch 10/2500\n",
      "Epoch 10/2500 - Train Accuracy: 0.6786 - Val Accuracy: 0.6677 - Test Accuracy: 0.6647\n",
      "312/312 - 128s - loss: 1.4644 - accuracy: 0.6967 - val_loss: 1.6270 - val_accuracy: 0.6677 - lr: 0.1000 - 128s/epoch - 410ms/step\n",
      "Epoch 11/2500\n",
      "Epoch 11/2500 - Train Accuracy: 0.7226 - Val Accuracy: 0.7078 - Test Accuracy: 0.7024\n",
      "312/312 - 129s - loss: 1.4782 - accuracy: 0.7028 - val_loss: 1.4978 - val_accuracy: 0.7078 - lr: 0.1000 - 129s/epoch - 412ms/step\n",
      "Epoch 12/2500\n",
      "Epoch 12/2500 - Train Accuracy: 0.7560 - Val Accuracy: 0.7377 - Test Accuracy: 0.7336\n",
      "312/312 - 128s - loss: 1.4645 - accuracy: 0.7158 - val_loss: 1.4295 - val_accuracy: 0.7377 - lr: 0.1000 - 128s/epoch - 411ms/step\n",
      "Epoch 13/2500\n",
      "Epoch 13/2500 - Train Accuracy: 0.7019 - Val Accuracy: 0.6941 - Test Accuracy: 0.6792\n",
      "312/312 - 128s - loss: 1.4640 - accuracy: 0.7194 - val_loss: 1.6370 - val_accuracy: 0.6941 - lr: 0.1000 - 128s/epoch - 410ms/step\n",
      "Epoch 14/2500\n",
      "Epoch 14/2500 - Train Accuracy: 0.7471 - Val Accuracy: 0.7324 - Test Accuracy: 0.7287\n",
      "312/312 - 128s - loss: 1.5089 - accuracy: 0.7237 - val_loss: 1.5484 - val_accuracy: 0.7324 - lr: 0.1000 - 128s/epoch - 412ms/step\n",
      "Epoch 15/2500\n",
      "Epoch 15/2500 - Train Accuracy: 0.7396 - Val Accuracy: 0.7172 - Test Accuracy: 0.7196\n",
      "312/312 - 129s - loss: 1.5148 - accuracy: 0.7345 - val_loss: 1.5765 - val_accuracy: 0.7172 - lr: 0.1000 - 129s/epoch - 412ms/step\n",
      "Epoch 16/2500\n",
      "Epoch 16/2500 - Train Accuracy: 0.7922 - Val Accuracy: 0.7670 - Test Accuracy: 0.7654\n",
      "312/312 - 128s - loss: 1.5103 - accuracy: 0.7379 - val_loss: 1.4324 - val_accuracy: 0.7670 - lr: 0.1000 - 128s/epoch - 411ms/step\n",
      "Epoch 17/2500\n",
      "Epoch 17/2500 - Train Accuracy: 0.7534 - Val Accuracy: 0.7418 - Test Accuracy: 0.7368\n",
      "312/312 - 129s - loss: 1.5541 - accuracy: 0.7394 - val_loss: 1.6654 - val_accuracy: 0.7418 - lr: 0.1000 - 129s/epoch - 412ms/step\n",
      "Epoch 18/2500\n",
      "Epoch 18/2500 - Train Accuracy: 0.7703 - Val Accuracy: 0.7506 - Test Accuracy: 0.7428\n",
      "312/312 - 128s - loss: 1.5884 - accuracy: 0.7474 - val_loss: 1.5942 - val_accuracy: 0.7506 - lr: 0.1000 - 128s/epoch - 411ms/step\n",
      "Epoch 19/2500\n",
      "Epoch 19/2500 - Train Accuracy: 0.7587 - Val Accuracy: 0.7390 - Test Accuracy: 0.7321\n",
      "312/312 - 128s - loss: 1.5642 - accuracy: 0.7493 - val_loss: 1.6228 - val_accuracy: 0.7390 - lr: 0.1000 - 128s/epoch - 411ms/step\n",
      "Epoch 20/2500\n",
      "Epoch 20/2500 - Train Accuracy: 0.7512 - Val Accuracy: 0.7300 - Test Accuracy: 0.7202\n",
      "312/312 - 129s - loss: 1.5819 - accuracy: 0.7520 - val_loss: 1.7366 - val_accuracy: 0.7300 - lr: 0.1000 - 129s/epoch - 412ms/step\n",
      "Epoch 21/2500\n",
      "Epoch 21/2500 - Train Accuracy: 0.8243 - Val Accuracy: 0.8013 - Test Accuracy: 0.7934\n",
      "312/312 - 128s - loss: 1.4560 - accuracy: 0.7962 - val_loss: 1.3809 - val_accuracy: 0.8013 - lr: 0.0500 - 128s/epoch - 411ms/step\n",
      "Epoch 22/2500\n",
      "Epoch 22/2500 - Train Accuracy: 0.8530 - Val Accuracy: 0.8172 - Test Accuracy: 0.8160\n",
      "312/312 - 128s - loss: 1.3191 - accuracy: 0.8068 - val_loss: 1.2626 - val_accuracy: 0.8172 - lr: 0.0500 - 128s/epoch - 411ms/step\n",
      "Epoch 23/2500\n",
      "Epoch 23/2500 - Train Accuracy: 0.8393 - Val Accuracy: 0.8106 - Test Accuracy: 0.8015\n",
      "312/312 - 129s - loss: 1.2796 - accuracy: 0.8057 - val_loss: 1.2856 - val_accuracy: 0.8106 - lr: 0.0500 - 129s/epoch - 412ms/step\n",
      "Epoch 24/2500\n",
      "Epoch 24/2500 - Train Accuracy: 0.8415 - Val Accuracy: 0.8114 - Test Accuracy: 0.8032\n",
      "312/312 - 128s - loss: 1.2598 - accuracy: 0.8059 - val_loss: 1.2772 - val_accuracy: 0.8114 - lr: 0.0500 - 128s/epoch - 411ms/step\n",
      "Epoch 25/2500\n",
      "Epoch 25/2500 - Train Accuracy: 0.7970 - Val Accuracy: 0.7660 - Test Accuracy: 0.7643\n",
      "312/312 - 128s - loss: 1.2707 - accuracy: 0.8054 - val_loss: 1.4875 - val_accuracy: 0.7660 - lr: 0.0500 - 128s/epoch - 411ms/step\n",
      "Epoch 26/2500\n",
      "Epoch 26/2500 - Train Accuracy: 0.8311 - Val Accuracy: 0.7960 - Test Accuracy: 0.7916\n",
      "312/312 - 128s - loss: 1.2991 - accuracy: 0.8066 - val_loss: 1.3438 - val_accuracy: 0.7960 - lr: 0.0500 - 128s/epoch - 411ms/step\n",
      "Epoch 27/2500\n",
      "Epoch 27/2500 - Train Accuracy: 0.8491 - Val Accuracy: 0.8137 - Test Accuracy: 0.8066\n",
      "312/312 - 128s - loss: 1.2837 - accuracy: 0.8124 - val_loss: 1.3160 - val_accuracy: 0.8137 - lr: 0.0500 - 128s/epoch - 410ms/step\n",
      "Epoch 28/2500\n",
      "Epoch 28/2500 - Train Accuracy: 0.8457 - Val Accuracy: 0.8025 - Test Accuracy: 0.8013\n",
      "312/312 - 128s - loss: 1.2973 - accuracy: 0.8152 - val_loss: 1.3657 - val_accuracy: 0.8025 - lr: 0.0500 - 128s/epoch - 411ms/step\n",
      "Epoch 29/2500\n",
      "Epoch 29/2500 - Train Accuracy: 0.8634 - Val Accuracy: 0.8233 - Test Accuracy: 0.8161\n",
      "312/312 - 128s - loss: 1.2995 - accuracy: 0.8183 - val_loss: 1.2951 - val_accuracy: 0.8233 - lr: 0.0500 - 128s/epoch - 411ms/step\n",
      "Epoch 30/2500\n",
      "Epoch 30/2500 - Train Accuracy: 0.8346 - Val Accuracy: 0.8028 - Test Accuracy: 0.7924\n",
      "312/312 - 129s - loss: 1.2992 - accuracy: 0.8183 - val_loss: 1.3777 - val_accuracy: 0.8028 - lr: 0.0500 - 129s/epoch - 412ms/step\n",
      "Epoch 31/2500\n",
      "Epoch 31/2500 - Train Accuracy: 0.8532 - Val Accuracy: 0.8162 - Test Accuracy: 0.8142\n",
      "312/312 - 128s - loss: 1.3215 - accuracy: 0.8165 - val_loss: 1.3720 - val_accuracy: 0.8162 - lr: 0.0500 - 128s/epoch - 412ms/step\n",
      "Epoch 32/2500\n",
      "Epoch 32/2500 - Train Accuracy: 0.8491 - Val Accuracy: 0.8158 - Test Accuracy: 0.8099\n",
      "312/312 - 128s - loss: 1.3339 - accuracy: 0.8197 - val_loss: 1.3749 - val_accuracy: 0.8158 - lr: 0.0500 - 128s/epoch - 412ms/step\n",
      "Epoch 33/2500\n",
      "Epoch 33/2500 - Train Accuracy: 0.8562 - Val Accuracy: 0.8258 - Test Accuracy: 0.8129\n",
      "312/312 - 128s - loss: 1.3739 - accuracy: 0.8201 - val_loss: 1.3933 - val_accuracy: 0.8258 - lr: 0.0500 - 128s/epoch - 412ms/step\n",
      "Epoch 34/2500\n",
      "Epoch 34/2500 - Train Accuracy: 0.8397 - Val Accuracy: 0.8109 - Test Accuracy: 0.7953\n",
      "312/312 - 128s - loss: 1.3737 - accuracy: 0.8201 - val_loss: 1.4836 - val_accuracy: 0.8109 - lr: 0.0500 - 128s/epoch - 410ms/step\n",
      "Epoch 35/2500\n",
      "Epoch 35/2500 - Train Accuracy: 0.8407 - Val Accuracy: 0.8108 - Test Accuracy: 0.7972\n",
      "312/312 - 128s - loss: 1.3899 - accuracy: 0.8228 - val_loss: 1.4533 - val_accuracy: 0.8108 - lr: 0.0500 - 128s/epoch - 411ms/step\n",
      "Epoch 36/2500\n",
      "Epoch 36/2500 - Train Accuracy: 0.8461 - Val Accuracy: 0.8161 - Test Accuracy: 0.8110\n",
      "312/312 - 128s - loss: 1.4064 - accuracy: 0.8196 - val_loss: 1.4660 - val_accuracy: 0.8161 - lr: 0.0500 - 128s/epoch - 411ms/step\n",
      "Epoch 37/2500\n",
      "Epoch 37/2500 - Train Accuracy: 0.8771 - Val Accuracy: 0.8357 - Test Accuracy: 0.8283\n",
      "312/312 - 128s - loss: 1.4255 - accuracy: 0.8272 - val_loss: 1.4060 - val_accuracy: 0.8357 - lr: 0.0500 - 128s/epoch - 411ms/step\n",
      "Epoch 38/2500\n",
      "Epoch 38/2500 - Train Accuracy: 0.8501 - Val Accuracy: 0.8097 - Test Accuracy: 0.8076\n",
      "312/312 - 128s - loss: 1.4390 - accuracy: 0.8270 - val_loss: 1.5126 - val_accuracy: 0.8097 - lr: 0.0500 - 128s/epoch - 411ms/step\n",
      "Epoch 39/2500\n",
      "Epoch 39/2500 - Train Accuracy: 0.8429 - Val Accuracy: 0.8077 - Test Accuracy: 0.7998\n",
      "312/312 - 128s - loss: 1.4294 - accuracy: 0.8295 - val_loss: 1.5867 - val_accuracy: 0.8077 - lr: 0.0500 - 128s/epoch - 411ms/step\n",
      "Epoch 40/2500\n",
      "Epoch 40/2500 - Train Accuracy: 0.8245 - Val Accuracy: 0.7909 - Test Accuracy: 0.7865\n",
      "312/312 - 128s - loss: 1.4664 - accuracy: 0.8284 - val_loss: 1.6586 - val_accuracy: 0.7909 - lr: 0.0500 - 128s/epoch - 411ms/step\n",
      "Epoch 41/2500\n",
      "Epoch 41/2500 - Train Accuracy: 0.9241 - Val Accuracy: 0.8776 - Test Accuracy: 0.8708\n",
      "312/312 - 128s - loss: 1.3986 - accuracy: 0.8580 - val_loss: 1.3132 - val_accuracy: 0.8776 - lr: 0.0250 - 128s/epoch - 411ms/step\n",
      "Epoch 42/2500\n",
      "Epoch 42/2500 - Train Accuracy: 0.9133 - Val Accuracy: 0.8659 - Test Accuracy: 0.8599\n",
      "312/312 - 128s - loss: 1.2724 - accuracy: 0.8751 - val_loss: 1.2909 - val_accuracy: 0.8659 - lr: 0.0250 - 128s/epoch - 411ms/step\n",
      "Epoch 43/2500\n",
      "Epoch 43/2500 - Train Accuracy: 0.9098 - Val Accuracy: 0.8527 - Test Accuracy: 0.8482\n",
      "312/312 - 128s - loss: 1.1962 - accuracy: 0.8803 - val_loss: 1.2763 - val_accuracy: 0.8527 - lr: 0.0250 - 128s/epoch - 411ms/step\n",
      "Epoch 44/2500\n",
      "Epoch 44/2500 - Train Accuracy: 0.9100 - Val Accuracy: 0.8584 - Test Accuracy: 0.8475\n",
      "312/312 - 128s - loss: 1.1641 - accuracy: 0.8769 - val_loss: 1.2218 - val_accuracy: 0.8584 - lr: 0.0250 - 128s/epoch - 411ms/step\n",
      "Epoch 45/2500\n",
      "Epoch 45/2500 - Train Accuracy: 0.9277 - Val Accuracy: 0.8711 - Test Accuracy: 0.8669\n",
      "312/312 - 128s - loss: 1.1301 - accuracy: 0.8790 - val_loss: 1.1667 - val_accuracy: 0.8711 - lr: 0.0250 - 128s/epoch - 410ms/step\n",
      "Epoch 46/2500\n",
      "Epoch 46/2500 - Train Accuracy: 0.8928 - Val Accuracy: 0.8338 - Test Accuracy: 0.8241\n",
      "312/312 - 128s - loss: 1.1109 - accuracy: 0.8807 - val_loss: 1.2928 - val_accuracy: 0.8338 - lr: 0.0250 - 128s/epoch - 411ms/step\n",
      "Epoch 47/2500\n",
      "Epoch 47/2500 - Train Accuracy: 0.9203 - Val Accuracy: 0.8592 - Test Accuracy: 0.8555\n",
      "312/312 - 128s - loss: 1.1115 - accuracy: 0.8778 - val_loss: 1.2078 - val_accuracy: 0.8592 - lr: 0.0250 - 128s/epoch - 412ms/step\n",
      "Epoch 48/2500\n",
      "Epoch 48/2500 - Train Accuracy: 0.9220 - Val Accuracy: 0.8644 - Test Accuracy: 0.8573\n",
      "312/312 - 128s - loss: 1.1126 - accuracy: 0.8787 - val_loss: 1.1842 - val_accuracy: 0.8644 - lr: 0.0250 - 128s/epoch - 410ms/step\n",
      "Epoch 49/2500\n",
      "Epoch 49/2500 - Train Accuracy: 0.9226 - Val Accuracy: 0.8627 - Test Accuracy: 0.8540\n",
      "312/312 - 128s - loss: 1.1269 - accuracy: 0.8731 - val_loss: 1.2015 - val_accuracy: 0.8627 - lr: 0.0250 - 128s/epoch - 412ms/step\n",
      "Epoch 50/2500\n",
      "Epoch 50/2500 - Train Accuracy: 0.8778 - Val Accuracy: 0.8261 - Test Accuracy: 0.8156\n",
      "312/312 - 128s - loss: 1.1196 - accuracy: 0.8806 - val_loss: 1.3752 - val_accuracy: 0.8261 - lr: 0.0250 - 128s/epoch - 412ms/step\n",
      "Epoch 51/2500\n",
      "Epoch 51/2500 - Train Accuracy: 0.9160 - Val Accuracy: 0.8610 - Test Accuracy: 0.8502\n",
      "312/312 - 128s - loss: 1.1293 - accuracy: 0.8795 - val_loss: 1.2288 - val_accuracy: 0.8610 - lr: 0.0250 - 128s/epoch - 411ms/step\n",
      "Epoch 52/2500\n",
      "Epoch 52/2500 - Train Accuracy: 0.9018 - Val Accuracy: 0.8454 - Test Accuracy: 0.8355\n",
      "312/312 - 128s - loss: 1.1203 - accuracy: 0.8811 - val_loss: 1.2742 - val_accuracy: 0.8454 - lr: 0.0250 - 128s/epoch - 411ms/step\n",
      "Epoch 53/2500\n",
      "Epoch 53/2500 - Train Accuracy: 0.9237 - Val Accuracy: 0.8652 - Test Accuracy: 0.8560\n",
      "312/312 - 129s - loss: 1.1197 - accuracy: 0.8815 - val_loss: 1.2002 - val_accuracy: 0.8652 - lr: 0.0250 - 129s/epoch - 412ms/step\n",
      "Epoch 54/2500\n",
      "Epoch 54/2500 - Train Accuracy: 0.9072 - Val Accuracy: 0.8514 - Test Accuracy: 0.8481\n",
      "312/312 - 128s - loss: 1.1421 - accuracy: 0.8791 - val_loss: 1.2995 - val_accuracy: 0.8514 - lr: 0.0250 - 128s/epoch - 412ms/step\n",
      "Epoch 55/2500\n",
      "Epoch 55/2500 - Train Accuracy: 0.9168 - Val Accuracy: 0.8531 - Test Accuracy: 0.8513\n",
      "312/312 - 128s - loss: 1.1360 - accuracy: 0.8837 - val_loss: 1.2545 - val_accuracy: 0.8531 - lr: 0.0250 - 128s/epoch - 411ms/step\n",
      "Epoch 56/2500\n",
      "Epoch 56/2500 - Train Accuracy: 0.9072 - Val Accuracy: 0.8433 - Test Accuracy: 0.8376\n",
      "312/312 - 128s - loss: 1.1389 - accuracy: 0.8838 - val_loss: 1.3187 - val_accuracy: 0.8433 - lr: 0.0250 - 128s/epoch - 412ms/step\n",
      "Epoch 57/2500\n",
      "Epoch 57/2500 - Train Accuracy: 0.9368 - Val Accuracy: 0.8738 - Test Accuracy: 0.8629\n",
      "312/312 - 128s - loss: 1.1305 - accuracy: 0.8873 - val_loss: 1.2255 - val_accuracy: 0.8738 - lr: 0.0250 - 128s/epoch - 411ms/step\n",
      "Epoch 58/2500\n",
      "Epoch 58/2500 - Train Accuracy: 0.9125 - Val Accuracy: 0.8541 - Test Accuracy: 0.8416\n",
      "312/312 - 128s - loss: 1.1461 - accuracy: 0.8856 - val_loss: 1.2768 - val_accuracy: 0.8541 - lr: 0.0250 - 128s/epoch - 411ms/step\n",
      "Epoch 59/2500\n",
      "Epoch 59/2500 - Train Accuracy: 0.9208 - Val Accuracy: 0.8545 - Test Accuracy: 0.8546\n",
      "312/312 - 128s - loss: 1.1524 - accuracy: 0.8872 - val_loss: 1.2793 - val_accuracy: 0.8545 - lr: 0.0250 - 128s/epoch - 411ms/step\n",
      "Epoch 60/2500\n",
      "Epoch 60/2500 - Train Accuracy: 0.9283 - Val Accuracy: 0.8674 - Test Accuracy: 0.8577\n",
      "312/312 - 128s - loss: 1.1488 - accuracy: 0.8868 - val_loss: 1.2563 - val_accuracy: 0.8674 - lr: 0.0250 - 128s/epoch - 411ms/step\n",
      "Epoch 61/2500\n",
      "Epoch 61/2500 - Train Accuracy: 0.9653 - Val Accuracy: 0.8984 - Test Accuracy: 0.8902\n",
      "312/312 - 128s - loss: 1.0624 - accuracy: 0.9147 - val_loss: 1.1116 - val_accuracy: 0.8984 - lr: 0.0125 - 128s/epoch - 412ms/step\n",
      "Epoch 62/2500\n",
      "Epoch 62/2500 - Train Accuracy: 0.9696 - Val Accuracy: 0.8964 - Test Accuracy: 0.8899\n",
      "312/312 - 128s - loss: 0.9874 - accuracy: 0.9284 - val_loss: 1.0799 - val_accuracy: 0.8964 - lr: 0.0125 - 128s/epoch - 412ms/step\n",
      "Epoch 63/2500\n",
      "Epoch 63/2500 - Train Accuracy: 0.9700 - Val Accuracy: 0.8959 - Test Accuracy: 0.8905\n",
      "312/312 - 128s - loss: 0.9441 - accuracy: 0.9319 - val_loss: 1.0605 - val_accuracy: 0.8959 - lr: 0.0125 - 128s/epoch - 411ms/step\n",
      "Epoch 64/2500\n",
      "Epoch 64/2500 - Train Accuracy: 0.9675 - Val Accuracy: 0.8962 - Test Accuracy: 0.8862\n",
      "312/312 - 128s - loss: 0.9101 - accuracy: 0.9338 - val_loss: 1.0417 - val_accuracy: 0.8962 - lr: 0.0125 - 128s/epoch - 411ms/step\n",
      "Epoch 65/2500\n",
      "Epoch 65/2500 - Train Accuracy: 0.9761 - Val Accuracy: 0.8956 - Test Accuracy: 0.8915\n",
      "312/312 - 128s - loss: 0.8875 - accuracy: 0.9329 - val_loss: 1.0209 - val_accuracy: 0.8956 - lr: 0.0125 - 128s/epoch - 412ms/step\n",
      "Epoch 66/2500\n",
      "Epoch 66/2500 - Train Accuracy: 0.9667 - Val Accuracy: 0.8868 - Test Accuracy: 0.8798\n",
      "312/312 - 128s - loss: 0.8665 - accuracy: 0.9344 - val_loss: 1.0345 - val_accuracy: 0.8868 - lr: 0.0125 - 128s/epoch - 411ms/step\n",
      "Epoch 67/2500\n",
      "Epoch 67/2500 - Train Accuracy: 0.9669 - Val Accuracy: 0.8834 - Test Accuracy: 0.8804\n",
      "312/312 - 128s - loss: 0.8550 - accuracy: 0.9325 - val_loss: 1.0365 - val_accuracy: 0.8834 - lr: 0.0125 - 128s/epoch - 411ms/step\n",
      "Epoch 68/2500\n",
      "Epoch 68/2500 - Train Accuracy: 0.9715 - Val Accuracy: 0.8905 - Test Accuracy: 0.8863\n",
      "312/312 - 128s - loss: 0.8441 - accuracy: 0.9340 - val_loss: 0.9990 - val_accuracy: 0.8905 - lr: 0.0125 - 128s/epoch - 412ms/step\n",
      "Epoch 69/2500\n",
      "Epoch 69/2500 - Train Accuracy: 0.9739 - Val Accuracy: 0.8943 - Test Accuracy: 0.8837\n",
      "312/312 - 128s - loss: 0.8367 - accuracy: 0.9330 - val_loss: 0.9844 - val_accuracy: 0.8943 - lr: 0.0125 - 128s/epoch - 411ms/step\n",
      "Epoch 70/2500\n",
      "Epoch 70/2500 - Train Accuracy: 0.9641 - Val Accuracy: 0.8823 - Test Accuracy: 0.8729\n",
      "312/312 - 128s - loss: 0.8366 - accuracy: 0.9307 - val_loss: 1.0333 - val_accuracy: 0.8823 - lr: 0.0125 - 128s/epoch - 411ms/step\n",
      "Epoch 71/2500\n",
      "Epoch 71/2500 - Train Accuracy: 0.9633 - Val Accuracy: 0.8817 - Test Accuracy: 0.8758\n",
      "312/312 - 129s - loss: 0.8313 - accuracy: 0.9307 - val_loss: 1.0217 - val_accuracy: 0.8817 - lr: 0.0125 - 129s/epoch - 414ms/step\n",
      "Epoch 72/2500\n",
      "Epoch 72/2500 - Train Accuracy: 0.9635 - Val Accuracy: 0.8778 - Test Accuracy: 0.8763\n",
      "312/312 - 128s - loss: 0.8401 - accuracy: 0.9285 - val_loss: 1.0569 - val_accuracy: 0.8778 - lr: 0.0125 - 128s/epoch - 411ms/step\n",
      "Epoch 73/2500\n",
      "Epoch 73/2500 - Train Accuracy: 0.9741 - Val Accuracy: 0.8932 - Test Accuracy: 0.8890\n",
      "312/312 - 128s - loss: 0.8495 - accuracy: 0.9262 - val_loss: 0.9943 - val_accuracy: 0.8932 - lr: 0.0125 - 128s/epoch - 411ms/step\n",
      "Epoch 74/2500\n",
      "Epoch 74/2500 - Train Accuracy: 0.9754 - Val Accuracy: 0.8947 - Test Accuracy: 0.8828\n",
      "312/312 - 128s - loss: 0.8463 - accuracy: 0.9304 - val_loss: 0.9914 - val_accuracy: 0.8947 - lr: 0.0125 - 128s/epoch - 411ms/step\n",
      "Epoch 75/2500\n",
      "Epoch 75/2500 - Train Accuracy: 0.9662 - Val Accuracy: 0.8818 - Test Accuracy: 0.8737\n",
      "312/312 - 128s - loss: 0.8460 - accuracy: 0.9289 - val_loss: 1.0500 - val_accuracy: 0.8818 - lr: 0.0125 - 128s/epoch - 411ms/step\n",
      "Epoch 76/2500\n",
      "Epoch 76/2500 - Train Accuracy: 0.9698 - Val Accuracy: 0.8852 - Test Accuracy: 0.8798\n",
      "312/312 - 128s - loss: 0.8534 - accuracy: 0.9289 - val_loss: 1.0326 - val_accuracy: 0.8852 - lr: 0.0125 - 128s/epoch - 410ms/step\n",
      "Epoch 77/2500\n",
      "Epoch 77/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8758 - Test Accuracy: 0.8656\n",
      "312/312 - 128s - loss: 0.8519 - accuracy: 0.9299 - val_loss: 1.0859 - val_accuracy: 0.8758 - lr: 0.0125 - 128s/epoch - 411ms/step\n",
      "Epoch 78/2500\n",
      "Epoch 78/2500 - Train Accuracy: 0.9736 - Val Accuracy: 0.8935 - Test Accuracy: 0.8848\n",
      "312/312 - 128s - loss: 0.8531 - accuracy: 0.9321 - val_loss: 1.0135 - val_accuracy: 0.8935 - lr: 0.0125 - 128s/epoch - 411ms/step\n",
      "Epoch 79/2500\n",
      "Epoch 79/2500 - Train Accuracy: 0.9551 - Val Accuracy: 0.8729 - Test Accuracy: 0.8679\n",
      "312/312 - 128s - loss: 0.8542 - accuracy: 0.9315 - val_loss: 1.0650 - val_accuracy: 0.8729 - lr: 0.0125 - 128s/epoch - 411ms/step\n",
      "Epoch 80/2500\n",
      "Epoch 80/2500 - Train Accuracy: 0.9590 - Val Accuracy: 0.8762 - Test Accuracy: 0.8749\n",
      "312/312 - 128s - loss: 0.8625 - accuracy: 0.9282 - val_loss: 1.0846 - val_accuracy: 0.8762 - lr: 0.0125 - 128s/epoch - 411ms/step\n",
      "Epoch 81/2500\n",
      "Epoch 81/2500 - Train Accuracy: 0.9829 - Val Accuracy: 0.9026 - Test Accuracy: 0.8973\n",
      "312/312 - 128s - loss: 0.7993 - accuracy: 0.9502 - val_loss: 0.9684 - val_accuracy: 0.9026 - lr: 0.0063 - 128s/epoch - 411ms/step\n",
      "Epoch 82/2500\n",
      "Epoch 82/2500 - Train Accuracy: 0.9905 - Val Accuracy: 0.9073 - Test Accuracy: 0.9036\n",
      "312/312 - 128s - loss: 0.7624 - accuracy: 0.9592 - val_loss: 0.9393 - val_accuracy: 0.9073 - lr: 0.0063 - 128s/epoch - 411ms/step\n",
      "Epoch 83/2500\n",
      "Epoch 83/2500 - Train Accuracy: 0.9877 - Val Accuracy: 0.9043 - Test Accuracy: 0.8995\n",
      "312/312 - 128s - loss: 0.7403 - accuracy: 0.9615 - val_loss: 0.9369 - val_accuracy: 0.9043 - lr: 0.0063 - 128s/epoch - 411ms/step\n",
      "Epoch 84/2500\n",
      "Epoch 84/2500 - Train Accuracy: 0.9939 - Val Accuracy: 0.9107 - Test Accuracy: 0.9089\n",
      "312/312 - 128s - loss: 0.7206 - accuracy: 0.9635 - val_loss: 0.8960 - val_accuracy: 0.9107 - lr: 0.0063 - 128s/epoch - 410ms/step\n",
      "Epoch 85/2500\n",
      "Epoch 85/2500 - Train Accuracy: 0.9899 - Val Accuracy: 0.9082 - Test Accuracy: 0.9023\n",
      "312/312 - 128s - loss: 0.7002 - accuracy: 0.9654 - val_loss: 0.9002 - val_accuracy: 0.9082 - lr: 0.0063 - 128s/epoch - 411ms/step\n",
      "Epoch 86/2500\n",
      "Epoch 86/2500 - Train Accuracy: 0.9945 - Val Accuracy: 0.9155 - Test Accuracy: 0.9104\n",
      "312/312 - 129s - loss: 0.6797 - accuracy: 0.9680 - val_loss: 0.8618 - val_accuracy: 0.9155 - lr: 0.0063 - 129s/epoch - 412ms/step\n",
      "Epoch 87/2500\n",
      "Epoch 87/2500 - Train Accuracy: 0.9912 - Val Accuracy: 0.9059 - Test Accuracy: 0.9004\n",
      "312/312 - 128s - loss: 0.6634 - accuracy: 0.9691 - val_loss: 0.8855 - val_accuracy: 0.9059 - lr: 0.0063 - 128s/epoch - 411ms/step\n",
      "Epoch 88/2500\n",
      "Epoch 88/2500 - Train Accuracy: 0.9866 - Val Accuracy: 0.8966 - Test Accuracy: 0.8934\n",
      "312/312 - 128s - loss: 0.6520 - accuracy: 0.9684 - val_loss: 0.9071 - val_accuracy: 0.8966 - lr: 0.0063 - 128s/epoch - 411ms/step\n",
      "Epoch 89/2500\n",
      "Epoch 89/2500 - Train Accuracy: 0.9954 - Val Accuracy: 0.9138 - Test Accuracy: 0.9079\n",
      "312/312 - 128s - loss: 0.6368 - accuracy: 0.9701 - val_loss: 0.8406 - val_accuracy: 0.9138 - lr: 0.0063 - 128s/epoch - 412ms/step\n",
      "Epoch 90/2500\n",
      "Epoch 90/2500 - Train Accuracy: 0.9886 - Val Accuracy: 0.9031 - Test Accuracy: 0.8954\n",
      "312/312 - 128s - loss: 0.6280 - accuracy: 0.9683 - val_loss: 0.8629 - val_accuracy: 0.9031 - lr: 0.0063 - 128s/epoch - 411ms/step\n",
      "Epoch 91/2500\n",
      "Epoch 91/2500 - Train Accuracy: 0.9946 - Val Accuracy: 0.9091 - Test Accuracy: 0.9038\n",
      "312/312 - 128s - loss: 0.6182 - accuracy: 0.9683 - val_loss: 0.8334 - val_accuracy: 0.9091 - lr: 0.0063 - 128s/epoch - 411ms/step\n",
      "Epoch 92/2500\n",
      "Epoch 92/2500 - Train Accuracy: 0.9912 - Val Accuracy: 0.9004 - Test Accuracy: 0.8980\n",
      "312/312 - 128s - loss: 0.6100 - accuracy: 0.9686 - val_loss: 0.8683 - val_accuracy: 0.9004 - lr: 0.0063 - 128s/epoch - 412ms/step\n",
      "Epoch 93/2500\n",
      "Epoch 93/2500 - Train Accuracy: 0.9920 - Val Accuracy: 0.9042 - Test Accuracy: 0.8984\n",
      "312/312 - 128s - loss: 0.6056 - accuracy: 0.9680 - val_loss: 0.8465 - val_accuracy: 0.9042 - lr: 0.0063 - 128s/epoch - 411ms/step\n",
      "Epoch 94/2500\n",
      "Epoch 94/2500 - Train Accuracy: 0.9903 - Val Accuracy: 0.9037 - Test Accuracy: 0.8958\n",
      "312/312 - 128s - loss: 0.5939 - accuracy: 0.9696 - val_loss: 0.8485 - val_accuracy: 0.9037 - lr: 0.0063 - 128s/epoch - 410ms/step\n",
      "Epoch 95/2500\n",
      "Epoch 95/2500 - Train Accuracy: 0.9946 - Val Accuracy: 0.9061 - Test Accuracy: 0.9030\n",
      "312/312 - 128s - loss: 0.5881 - accuracy: 0.9689 - val_loss: 0.8330 - val_accuracy: 0.9061 - lr: 0.0063 - 128s/epoch - 412ms/step\n",
      "Epoch 96/2500\n",
      "Epoch 96/2500 - Train Accuracy: 0.9930 - Val Accuracy: 0.9060 - Test Accuracy: 0.9024\n",
      "312/312 - 128s - loss: 0.5869 - accuracy: 0.9671 - val_loss: 0.8277 - val_accuracy: 0.9060 - lr: 0.0063 - 128s/epoch - 411ms/step\n",
      "Epoch 97/2500\n",
      "Epoch 97/2500 - Train Accuracy: 0.9932 - Val Accuracy: 0.9039 - Test Accuracy: 0.8997\n",
      "312/312 - 128s - loss: 0.5810 - accuracy: 0.9670 - val_loss: 0.8374 - val_accuracy: 0.9039 - lr: 0.0063 - 128s/epoch - 411ms/step\n",
      "Epoch 98/2500\n",
      "Epoch 98/2500 - Train Accuracy: 0.9895 - Val Accuracy: 0.9000 - Test Accuracy: 0.8951\n",
      "312/312 - 128s - loss: 0.5786 - accuracy: 0.9663 - val_loss: 0.8306 - val_accuracy: 0.9000 - lr: 0.0063 - 128s/epoch - 411ms/step\n",
      "Epoch 99/2500\n",
      "Epoch 99/2500 - Train Accuracy: 0.9891 - Val Accuracy: 0.8966 - Test Accuracy: 0.8923\n",
      "312/312 - 128s - loss: 0.5698 - accuracy: 0.9681 - val_loss: 0.8404 - val_accuracy: 0.8966 - lr: 0.0063 - 128s/epoch - 411ms/step\n",
      "Epoch 100/2500\n",
      "Epoch 100/2500 - Train Accuracy: 0.9892 - Val Accuracy: 0.9033 - Test Accuracy: 0.8992\n",
      "312/312 - 128s - loss: 0.5726 - accuracy: 0.9656 - val_loss: 0.8272 - val_accuracy: 0.9033 - lr: 0.0063 - 128s/epoch - 411ms/step\n",
      "Epoch 101/2500\n",
      "Epoch 101/2500 - Train Accuracy: 0.9959 - Val Accuracy: 0.9096 - Test Accuracy: 0.9081\n",
      "312/312 - 128s - loss: 0.5482 - accuracy: 0.9733 - val_loss: 0.7838 - val_accuracy: 0.9096 - lr: 0.0031 - 128s/epoch - 411ms/step\n",
      "Epoch 102/2500\n",
      "Epoch 102/2500 - Train Accuracy: 0.9974 - Val Accuracy: 0.9156 - Test Accuracy: 0.9136\n",
      "312/312 - 128s - loss: 0.5266 - accuracy: 0.9797 - val_loss: 0.7588 - val_accuracy: 0.9156 - lr: 0.0031 - 128s/epoch - 411ms/step\n",
      "Epoch 103/2500\n",
      "Epoch 103/2500 - Train Accuracy: 0.9977 - Val Accuracy: 0.9160 - Test Accuracy: 0.9125\n",
      "312/312 - 128s - loss: 0.5146 - accuracy: 0.9816 - val_loss: 0.7556 - val_accuracy: 0.9160 - lr: 0.0031 - 128s/epoch - 410ms/step\n",
      "Epoch 104/2500\n",
      "Epoch 104/2500 - Train Accuracy: 0.9975 - Val Accuracy: 0.9178 - Test Accuracy: 0.9129\n",
      "312/312 - 128s - loss: 0.5080 - accuracy: 0.9812 - val_loss: 0.7447 - val_accuracy: 0.9178 - lr: 0.0031 - 128s/epoch - 411ms/step\n",
      "Epoch 105/2500\n",
      "Epoch 105/2500 - Train Accuracy: 0.9979 - Val Accuracy: 0.9159 - Test Accuracy: 0.9133\n",
      "312/312 - 128s - loss: 0.4987 - accuracy: 0.9825 - val_loss: 0.7410 - val_accuracy: 0.9159 - lr: 0.0031 - 128s/epoch - 411ms/step\n",
      "Epoch 106/2500\n",
      "Epoch 106/2500 - Train Accuracy: 0.9988 - Val Accuracy: 0.9157 - Test Accuracy: 0.9149\n",
      "312/312 - 128s - loss: 0.4856 - accuracy: 0.9848 - val_loss: 0.7434 - val_accuracy: 0.9157 - lr: 0.0031 - 128s/epoch - 410ms/step\n",
      "Epoch 107/2500\n",
      "Epoch 107/2500 - Train Accuracy: 0.9990 - Val Accuracy: 0.9177 - Test Accuracy: 0.9146\n",
      "312/312 - 128s - loss: 0.4822 - accuracy: 0.9848 - val_loss: 0.7314 - val_accuracy: 0.9177 - lr: 0.0031 - 128s/epoch - 411ms/step\n",
      "Epoch 108/2500\n",
      "Epoch 108/2500 - Train Accuracy: 0.9977 - Val Accuracy: 0.9155 - Test Accuracy: 0.9104\n",
      "312/312 - 128s - loss: 0.4747 - accuracy: 0.9842 - val_loss: 0.7334 - val_accuracy: 0.9155 - lr: 0.0031 - 128s/epoch - 412ms/step\n",
      "Epoch 109/2500\n",
      "Epoch 109/2500 - Train Accuracy: 0.9987 - Val Accuracy: 0.9142 - Test Accuracy: 0.9147\n",
      "312/312 - 128s - loss: 0.4693 - accuracy: 0.9847 - val_loss: 0.7165 - val_accuracy: 0.9142 - lr: 0.0031 - 128s/epoch - 411ms/step\n",
      "Epoch 110/2500\n",
      "Epoch 110/2500 - Train Accuracy: 0.9988 - Val Accuracy: 0.9171 - Test Accuracy: 0.9156\n",
      "312/312 - 129s - loss: 0.4586 - accuracy: 0.9866 - val_loss: 0.7173 - val_accuracy: 0.9171 - lr: 0.0031 - 129s/epoch - 412ms/step\n",
      "Epoch 111/2500\n",
      "Epoch 111/2500 - Train Accuracy: 0.9990 - Val Accuracy: 0.9187 - Test Accuracy: 0.9183\n",
      "312/312 - 128s - loss: 0.4524 - accuracy: 0.9865 - val_loss: 0.7094 - val_accuracy: 0.9187 - lr: 0.0031 - 128s/epoch - 412ms/step\n",
      "Epoch 112/2500\n",
      "Epoch 112/2500 - Train Accuracy: 0.9979 - Val Accuracy: 0.9112 - Test Accuracy: 0.9104\n",
      "312/312 - 128s - loss: 0.4482 - accuracy: 0.9865 - val_loss: 0.7178 - val_accuracy: 0.9112 - lr: 0.0031 - 128s/epoch - 411ms/step\n",
      "Epoch 113/2500\n",
      "Epoch 113/2500 - Train Accuracy: 0.9990 - Val Accuracy: 0.9159 - Test Accuracy: 0.9134\n",
      "312/312 - 129s - loss: 0.4393 - accuracy: 0.9878 - val_loss: 0.6966 - val_accuracy: 0.9159 - lr: 0.0031 - 129s/epoch - 412ms/step\n",
      "Epoch 114/2500\n",
      "Epoch 114/2500 - Train Accuracy: 0.9989 - Val Accuracy: 0.9159 - Test Accuracy: 0.9139\n",
      "312/312 - 128s - loss: 0.4365 - accuracy: 0.9867 - val_loss: 0.6977 - val_accuracy: 0.9159 - lr: 0.0031 - 128s/epoch - 412ms/step\n",
      "Epoch 115/2500\n",
      "Epoch 115/2500 - Train Accuracy: 0.9987 - Val Accuracy: 0.9186 - Test Accuracy: 0.9183\n",
      "312/312 - 128s - loss: 0.4288 - accuracy: 0.9872 - val_loss: 0.6917 - val_accuracy: 0.9186 - lr: 0.0031 - 128s/epoch - 411ms/step\n",
      "Epoch 116/2500\n",
      "Epoch 116/2500 - Train Accuracy: 0.9989 - Val Accuracy: 0.9175 - Test Accuracy: 0.9160\n",
      "312/312 - 128s - loss: 0.4261 - accuracy: 0.9869 - val_loss: 0.6859 - val_accuracy: 0.9175 - lr: 0.0031 - 128s/epoch - 411ms/step\n",
      "Epoch 117/2500\n",
      "Epoch 117/2500 - Train Accuracy: 0.9977 - Val Accuracy: 0.9167 - Test Accuracy: 0.9103\n",
      "312/312 - 128s - loss: 0.4181 - accuracy: 0.9876 - val_loss: 0.6836 - val_accuracy: 0.9167 - lr: 0.0031 - 128s/epoch - 412ms/step\n",
      "Epoch 118/2500\n",
      "Epoch 118/2500 - Train Accuracy: 0.9988 - Val Accuracy: 0.9162 - Test Accuracy: 0.9122\n",
      "312/312 - 128s - loss: 0.4127 - accuracy: 0.9877 - val_loss: 0.6838 - val_accuracy: 0.9162 - lr: 0.0031 - 128s/epoch - 411ms/step\n",
      "Epoch 119/2500\n",
      "Epoch 119/2500 - Train Accuracy: 0.9983 - Val Accuracy: 0.9155 - Test Accuracy: 0.9128\n",
      "312/312 - 128s - loss: 0.4095 - accuracy: 0.9871 - val_loss: 0.6827 - val_accuracy: 0.9155 - lr: 0.0031 - 128s/epoch - 412ms/step\n",
      "Epoch 120/2500\n",
      "Epoch 120/2500 - Train Accuracy: 0.9988 - Val Accuracy: 0.9127 - Test Accuracy: 0.9128\n",
      "312/312 - 128s - loss: 0.4030 - accuracy: 0.9876 - val_loss: 0.6788 - val_accuracy: 0.9127 - lr: 0.0031 - 128s/epoch - 412ms/step\n",
      "Epoch 121/2500\n",
      "Epoch 121/2500 - Train Accuracy: 0.9998 - Val Accuracy: 0.9234 - Test Accuracy: 0.9201\n",
      "312/312 - 128s - loss: 0.3957 - accuracy: 0.9889 - val_loss: 0.6516 - val_accuracy: 0.9234 - lr: 0.0016 - 128s/epoch - 411ms/step\n",
      "Epoch 122/2500\n",
      "Epoch 122/2500 - Train Accuracy: 0.9998 - Val Accuracy: 0.9204 - Test Accuracy: 0.9193\n",
      "312/312 - 128s - loss: 0.3872 - accuracy: 0.9909 - val_loss: 0.6481 - val_accuracy: 0.9204 - lr: 0.0016 - 128s/epoch - 411ms/step\n",
      "Epoch 123/2500\n",
      "Epoch 123/2500 - Train Accuracy: 0.9997 - Val Accuracy: 0.9234 - Test Accuracy: 0.9219\n",
      "312/312 - 128s - loss: 0.3830 - accuracy: 0.9919 - val_loss: 0.6354 - val_accuracy: 0.9234 - lr: 0.0016 - 128s/epoch - 411ms/step\n",
      "Epoch 124/2500\n",
      "Epoch 124/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9243 - Test Accuracy: 0.9206\n",
      "312/312 - 129s - loss: 0.3794 - accuracy: 0.9914 - val_loss: 0.6338 - val_accuracy: 0.9243 - lr: 0.0016 - 129s/epoch - 412ms/step\n",
      "Epoch 125/2500\n",
      "Epoch 125/2500 - Train Accuracy: 0.9997 - Val Accuracy: 0.9216 - Test Accuracy: 0.9183\n",
      "312/312 - 132s - loss: 0.3750 - accuracy: 0.9927 - val_loss: 0.6365 - val_accuracy: 0.9216 - lr: 0.0016 - 132s/epoch - 423ms/step\n",
      "Epoch 126/2500\n",
      "Epoch 126/2500 - Train Accuracy: 0.9996 - Val Accuracy: 0.9219 - Test Accuracy: 0.9188\n",
      "312/312 - 128s - loss: 0.3730 - accuracy: 0.9921 - val_loss: 0.6397 - val_accuracy: 0.9219 - lr: 0.0016 - 128s/epoch - 412ms/step\n",
      "Epoch 127/2500\n",
      "Epoch 127/2500 - Train Accuracy: 0.9997 - Val Accuracy: 0.9240 - Test Accuracy: 0.9196\n",
      "312/312 - 128s - loss: 0.3686 - accuracy: 0.9931 - val_loss: 0.6392 - val_accuracy: 0.9240 - lr: 0.0016 - 128s/epoch - 411ms/step\n",
      "Epoch 128/2500\n",
      "Epoch 128/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9271 - Test Accuracy: 0.9216\n",
      "312/312 - 128s - loss: 0.3650 - accuracy: 0.9929 - val_loss: 0.6212 - val_accuracy: 0.9271 - lr: 0.0016 - 128s/epoch - 412ms/step\n",
      "Epoch 129/2500\n",
      "Epoch 129/2500 - Train Accuracy: 0.9996 - Val Accuracy: 0.9207 - Test Accuracy: 0.9172\n",
      "312/312 - 128s - loss: 0.3607 - accuracy: 0.9939 - val_loss: 0.6306 - val_accuracy: 0.9207 - lr: 0.0016 - 128s/epoch - 412ms/step\n",
      "Epoch 130/2500\n",
      "Epoch 130/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9233 - Test Accuracy: 0.9213\n",
      "312/312 - 128s - loss: 0.3587 - accuracy: 0.9935 - val_loss: 0.6218 - val_accuracy: 0.9233 - lr: 0.0016 - 128s/epoch - 412ms/step\n",
      "Epoch 131/2500\n",
      "Epoch 131/2500 - Train Accuracy: 0.9998 - Val Accuracy: 0.9251 - Test Accuracy: 0.9220\n",
      "312/312 - 129s - loss: 0.3567 - accuracy: 0.9932 - val_loss: 0.6154 - val_accuracy: 0.9251 - lr: 0.0016 - 129s/epoch - 412ms/step\n",
      "Epoch 132/2500\n",
      "Epoch 132/2500 - Train Accuracy: 0.9998 - Val Accuracy: 0.9226 - Test Accuracy: 0.9209\n",
      "312/312 - 128s - loss: 0.3543 - accuracy: 0.9926 - val_loss: 0.6227 - val_accuracy: 0.9226 - lr: 0.0016 - 128s/epoch - 412ms/step\n",
      "Epoch 133/2500\n",
      "Epoch 133/2500 - Train Accuracy: 0.9996 - Val Accuracy: 0.9237 - Test Accuracy: 0.9212\n",
      "312/312 - 128s - loss: 0.3493 - accuracy: 0.9934 - val_loss: 0.6207 - val_accuracy: 0.9237 - lr: 0.0016 - 128s/epoch - 411ms/step\n",
      "Epoch 134/2500\n",
      "Epoch 134/2500 - Train Accuracy: 0.9998 - Val Accuracy: 0.9234 - Test Accuracy: 0.9211\n",
      "312/312 - 129s - loss: 0.3456 - accuracy: 0.9941 - val_loss: 0.6123 - val_accuracy: 0.9234 - lr: 0.0016 - 129s/epoch - 412ms/step\n",
      "Epoch 135/2500\n",
      "Epoch 135/2500 - Train Accuracy: 0.9997 - Val Accuracy: 0.9244 - Test Accuracy: 0.9197\n",
      "312/312 - 128s - loss: 0.3450 - accuracy: 0.9928 - val_loss: 0.6112 - val_accuracy: 0.9244 - lr: 0.0016 - 128s/epoch - 412ms/step\n",
      "Epoch 136/2500\n",
      "Epoch 136/2500 - Train Accuracy: 0.9997 - Val Accuracy: 0.9234 - Test Accuracy: 0.9198\n",
      "312/312 - 128s - loss: 0.3389 - accuracy: 0.9944 - val_loss: 0.6067 - val_accuracy: 0.9234 - lr: 0.0016 - 128s/epoch - 411ms/step\n",
      "Epoch 137/2500\n",
      "Epoch 137/2500 - Train Accuracy: 0.9997 - Val Accuracy: 0.9249 - Test Accuracy: 0.9210\n",
      "312/312 - 129s - loss: 0.3377 - accuracy: 0.9939 - val_loss: 0.6036 - val_accuracy: 0.9249 - lr: 0.0016 - 129s/epoch - 412ms/step\n",
      "Epoch 138/2500\n",
      "Epoch 138/2500 - Train Accuracy: 0.9998 - Val Accuracy: 0.9257 - Test Accuracy: 0.9220\n",
      "312/312 - 128s - loss: 0.3346 - accuracy: 0.9940 - val_loss: 0.5971 - val_accuracy: 0.9257 - lr: 0.0016 - 128s/epoch - 412ms/step\n",
      "Epoch 139/2500\n",
      "Epoch 139/2500 - Train Accuracy: 0.9995 - Val Accuracy: 0.9230 - Test Accuracy: 0.9202\n",
      "312/312 - 128s - loss: 0.3322 - accuracy: 0.9943 - val_loss: 0.6087 - val_accuracy: 0.9230 - lr: 0.0016 - 128s/epoch - 411ms/step\n",
      "Epoch 140/2500\n",
      "Epoch 140/2500 - Train Accuracy: 0.9996 - Val Accuracy: 0.9214 - Test Accuracy: 0.9216\n",
      "312/312 - 128s - loss: 0.3288 - accuracy: 0.9942 - val_loss: 0.5999 - val_accuracy: 0.9214 - lr: 0.0016 - 128s/epoch - 412ms/step\n",
      "Epoch 141/2500\n",
      "Epoch 141/2500 - Train Accuracy: 0.9998 - Val Accuracy: 0.9253 - Test Accuracy: 0.9233\n",
      "312/312 - 128s - loss: 0.3255 - accuracy: 0.9948 - val_loss: 0.5882 - val_accuracy: 0.9253 - lr: 7.8125e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 142/2500\n",
      "Epoch 142/2500 - Train Accuracy: 0.9997 - Val Accuracy: 0.9266 - Test Accuracy: 0.9244\n",
      "312/312 - 128s - loss: 0.3237 - accuracy: 0.9946 - val_loss: 0.5886 - val_accuracy: 0.9266 - lr: 7.8125e-04 - 128s/epoch - 412ms/step\n",
      "Epoch 143/2500\n",
      "Epoch 143/2500 - Train Accuracy: 0.9997 - Val Accuracy: 0.9240 - Test Accuracy: 0.9220\n",
      "312/312 - 128s - loss: 0.3224 - accuracy: 0.9951 - val_loss: 0.5905 - val_accuracy: 0.9240 - lr: 7.8125e-04 - 128s/epoch - 412ms/step\n",
      "Epoch 144/2500\n",
      "Epoch 144/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9272 - Test Accuracy: 0.9243\n",
      "312/312 - 128s - loss: 0.3199 - accuracy: 0.9952 - val_loss: 0.5837 - val_accuracy: 0.9272 - lr: 7.8125e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 145/2500\n",
      "Epoch 145/2500 - Train Accuracy: 0.9998 - Val Accuracy: 0.9266 - Test Accuracy: 0.9243\n",
      "312/312 - 128s - loss: 0.3184 - accuracy: 0.9950 - val_loss: 0.5865 - val_accuracy: 0.9266 - lr: 7.8125e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 146/2500\n",
      "Epoch 146/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9260 - Test Accuracy: 0.9215\n",
      "312/312 - 128s - loss: 0.3177 - accuracy: 0.9950 - val_loss: 0.5841 - val_accuracy: 0.9260 - lr: 7.8125e-04 - 128s/epoch - 412ms/step\n",
      "Epoch 147/2500\n",
      "Epoch 147/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9277 - Test Accuracy: 0.9243\n",
      "312/312 - 128s - loss: 0.3140 - accuracy: 0.9957 - val_loss: 0.5781 - val_accuracy: 0.9277 - lr: 7.8125e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 148/2500\n",
      "Epoch 148/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9271 - Test Accuracy: 0.9230\n",
      "312/312 - 128s - loss: 0.3133 - accuracy: 0.9957 - val_loss: 0.5812 - val_accuracy: 0.9271 - lr: 7.8125e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 149/2500\n",
      "Epoch 149/2500 - Train Accuracy: 0.9998 - Val Accuracy: 0.9272 - Test Accuracy: 0.9218\n",
      "312/312 - 128s - loss: 0.3111 - accuracy: 0.9960 - val_loss: 0.5825 - val_accuracy: 0.9272 - lr: 7.8125e-04 - 128s/epoch - 412ms/step\n",
      "Epoch 150/2500\n",
      "Epoch 150/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9280 - Test Accuracy: 0.9238\n",
      "312/312 - 128s - loss: 0.3105 - accuracy: 0.9956 - val_loss: 0.5769 - val_accuracy: 0.9280 - lr: 7.8125e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 151/2500\n",
      "Epoch 151/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9277 - Test Accuracy: 0.9242\n",
      "312/312 - 128s - loss: 0.3088 - accuracy: 0.9959 - val_loss: 0.5692 - val_accuracy: 0.9277 - lr: 7.8125e-04 - 128s/epoch - 409ms/step\n",
      "Epoch 152/2500\n",
      "Epoch 152/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9279 - Test Accuracy: 0.9236\n",
      "312/312 - 128s - loss: 0.3070 - accuracy: 0.9963 - val_loss: 0.5688 - val_accuracy: 0.9279 - lr: 7.8125e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 153/2500\n",
      "Epoch 153/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9266 - Test Accuracy: 0.9236\n",
      "312/312 - 128s - loss: 0.3059 - accuracy: 0.9960 - val_loss: 0.5709 - val_accuracy: 0.9266 - lr: 7.8125e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 154/2500\n",
      "Epoch 154/2500 - Train Accuracy: 0.9998 - Val Accuracy: 0.9271 - Test Accuracy: 0.9226\n",
      "312/312 - 128s - loss: 0.3047 - accuracy: 0.9960 - val_loss: 0.5718 - val_accuracy: 0.9271 - lr: 7.8125e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 155/2500\n",
      "Epoch 155/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9266 - Test Accuracy: 0.9215\n",
      "312/312 - 128s - loss: 0.3031 - accuracy: 0.9959 - val_loss: 0.5720 - val_accuracy: 0.9266 - lr: 7.8125e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 156/2500\n",
      "Epoch 156/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9274 - Test Accuracy: 0.9237\n",
      "312/312 - 128s - loss: 0.3019 - accuracy: 0.9959 - val_loss: 0.5660 - val_accuracy: 0.9274 - lr: 7.8125e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 157/2500\n",
      "Epoch 157/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9283 - Test Accuracy: 0.9232\n",
      "312/312 - 128s - loss: 0.2999 - accuracy: 0.9961 - val_loss: 0.5647 - val_accuracy: 0.9283 - lr: 7.8125e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 158/2500\n",
      "Epoch 158/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9280 - Test Accuracy: 0.9253\n",
      "312/312 - 128s - loss: 0.2989 - accuracy: 0.9959 - val_loss: 0.5628 - val_accuracy: 0.9280 - lr: 7.8125e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 159/2500\n",
      "Epoch 159/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9279 - Test Accuracy: 0.9261\n",
      "312/312 - 128s - loss: 0.2982 - accuracy: 0.9961 - val_loss: 0.5620 - val_accuracy: 0.9279 - lr: 7.8125e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 160/2500\n",
      "Epoch 160/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9277 - Test Accuracy: 0.9243\n",
      "312/312 - 128s - loss: 0.2960 - accuracy: 0.9961 - val_loss: 0.5670 - val_accuracy: 0.9277 - lr: 7.8125e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 161/2500\n",
      "Epoch 161/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9286 - Test Accuracy: 0.9272\n",
      "312/312 - 128s - loss: 0.2948 - accuracy: 0.9965 - val_loss: 0.5607 - val_accuracy: 0.9286 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 162/2500\n",
      "Epoch 162/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9287 - Test Accuracy: 0.9251\n",
      "312/312 - 128s - loss: 0.2933 - accuracy: 0.9966 - val_loss: 0.5614 - val_accuracy: 0.9287 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 163/2500\n",
      "Epoch 163/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9281 - Test Accuracy: 0.9249\n",
      "312/312 - 128s - loss: 0.2925 - accuracy: 0.9967 - val_loss: 0.5570 - val_accuracy: 0.9281 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 164/2500\n",
      "Epoch 164/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9273 - Test Accuracy: 0.9235\n",
      "312/312 - 128s - loss: 0.2922 - accuracy: 0.9964 - val_loss: 0.5603 - val_accuracy: 0.9273 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 165/2500\n",
      "Epoch 165/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9273 - Test Accuracy: 0.9227\n",
      "312/312 - 128s - loss: 0.2922 - accuracy: 0.9963 - val_loss: 0.5597 - val_accuracy: 0.9273 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 166/2500\n",
      "Epoch 166/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9290 - Test Accuracy: 0.9257\n",
      "312/312 - 128s - loss: 0.2900 - accuracy: 0.9970 - val_loss: 0.5528 - val_accuracy: 0.9290 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 167/2500\n",
      "Epoch 167/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9282 - Test Accuracy: 0.9256\n",
      "312/312 - 128s - loss: 0.2889 - accuracy: 0.9972 - val_loss: 0.5535 - val_accuracy: 0.9282 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 168/2500\n",
      "Epoch 168/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9270 - Test Accuracy: 0.9259\n",
      "312/312 - 128s - loss: 0.2892 - accuracy: 0.9966 - val_loss: 0.5580 - val_accuracy: 0.9270 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 169/2500\n",
      "Epoch 169/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9277 - Test Accuracy: 0.9249\n",
      "312/312 - 128s - loss: 0.2893 - accuracy: 0.9967 - val_loss: 0.5524 - val_accuracy: 0.9277 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 170/2500\n",
      "Epoch 170/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9279 - Test Accuracy: 0.9265\n",
      "312/312 - 128s - loss: 0.2856 - accuracy: 0.9977 - val_loss: 0.5509 - val_accuracy: 0.9279 - lr: 3.9063e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 171/2500\n",
      "Epoch 171/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9292 - Test Accuracy: 0.9261\n",
      "312/312 - 128s - loss: 0.2866 - accuracy: 0.9970 - val_loss: 0.5489 - val_accuracy: 0.9292 - lr: 3.9063e-04 - 128s/epoch - 409ms/step\n",
      "Epoch 172/2500\n",
      "Epoch 172/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9288 - Test Accuracy: 0.9270\n",
      "312/312 - 128s - loss: 0.2857 - accuracy: 0.9974 - val_loss: 0.5485 - val_accuracy: 0.9288 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 173/2500\n",
      "Epoch 173/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9296 - Test Accuracy: 0.9282\n",
      "312/312 - 128s - loss: 0.2852 - accuracy: 0.9972 - val_loss: 0.5495 - val_accuracy: 0.9296 - lr: 3.9063e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 174/2500\n",
      "Epoch 174/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9291 - Test Accuracy: 0.9269\n",
      "312/312 - 128s - loss: 0.2846 - accuracy: 0.9971 - val_loss: 0.5528 - val_accuracy: 0.9291 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 175/2500\n",
      "Epoch 175/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9290 - Test Accuracy: 0.9271\n",
      "312/312 - 128s - loss: 0.2839 - accuracy: 0.9970 - val_loss: 0.5495 - val_accuracy: 0.9290 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 176/2500\n",
      "Epoch 176/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9274 - Test Accuracy: 0.9264\n",
      "312/312 - 128s - loss: 0.2834 - accuracy: 0.9970 - val_loss: 0.5493 - val_accuracy: 0.9274 - lr: 3.9063e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 177/2500\n",
      "Epoch 177/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9278 - Test Accuracy: 0.9268\n",
      "312/312 - 128s - loss: 0.2826 - accuracy: 0.9973 - val_loss: 0.5507 - val_accuracy: 0.9278 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 178/2500\n",
      "Epoch 178/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9294 - Test Accuracy: 0.9281\n",
      "312/312 - 128s - loss: 0.2816 - accuracy: 0.9970 - val_loss: 0.5432 - val_accuracy: 0.9294 - lr: 3.9063e-04 - 128s/epoch - 409ms/step\n",
      "Epoch 179/2500\n",
      "Epoch 179/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9266 - Test Accuracy: 0.9267\n",
      "312/312 - 128s - loss: 0.2811 - accuracy: 0.9970 - val_loss: 0.5479 - val_accuracy: 0.9266 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 180/2500\n",
      "Epoch 180/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9294 - Test Accuracy: 0.9269\n",
      "312/312 - 128s - loss: 0.2807 - accuracy: 0.9974 - val_loss: 0.5451 - val_accuracy: 0.9294 - lr: 3.9063e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 181/2500\n",
      "Epoch 181/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9284 - Test Accuracy: 0.9265\n",
      "312/312 - 128s - loss: 0.2801 - accuracy: 0.9972 - val_loss: 0.5457 - val_accuracy: 0.9284 - lr: 1.9531e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 182/2500\n",
      "Epoch 182/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9288 - Test Accuracy: 0.9265\n",
      "312/312 - 128s - loss: 0.2786 - accuracy: 0.9976 - val_loss: 0.5455 - val_accuracy: 0.9288 - lr: 1.9531e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 183/2500\n",
      "Epoch 183/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9277 - Test Accuracy: 0.9264\n",
      "312/312 - 128s - loss: 0.2792 - accuracy: 0.9974 - val_loss: 0.5469 - val_accuracy: 0.9277 - lr: 1.9531e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 184/2500\n",
      "Epoch 184/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9282 - Test Accuracy: 0.9263\n",
      "312/312 - 128s - loss: 0.2782 - accuracy: 0.9976 - val_loss: 0.5445 - val_accuracy: 0.9282 - lr: 1.9531e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 185/2500\n",
      "Epoch 185/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9277 - Test Accuracy: 0.9261\n",
      "312/312 - 128s - loss: 0.2784 - accuracy: 0.9975 - val_loss: 0.5464 - val_accuracy: 0.9277 - lr: 1.9531e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 186/2500\n",
      "Epoch 186/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9286 - Test Accuracy: 0.9264\n",
      "312/312 - 128s - loss: 0.2780 - accuracy: 0.9976 - val_loss: 0.5449 - val_accuracy: 0.9286 - lr: 1.9531e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 187/2500\n",
      "Epoch 187/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9290 - Test Accuracy: 0.9265\n",
      "312/312 - 128s - loss: 0.2779 - accuracy: 0.9973 - val_loss: 0.5436 - val_accuracy: 0.9290 - lr: 1.9531e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 188/2500\n",
      "Epoch 188/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9293 - Test Accuracy: 0.9261\n",
      "312/312 - 128s - loss: 0.2779 - accuracy: 0.9971 - val_loss: 0.5440 - val_accuracy: 0.9293 - lr: 1.9531e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 189/2500\n",
      "Epoch 189/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9296 - Test Accuracy: 0.9271\n",
      "312/312 - 128s - loss: 0.2778 - accuracy: 0.9972 - val_loss: 0.5434 - val_accuracy: 0.9296 - lr: 1.9531e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 190/2500\n",
      "Epoch 190/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9294 - Test Accuracy: 0.9264\n",
      "312/312 - 128s - loss: 0.2770 - accuracy: 0.9972 - val_loss: 0.5427 - val_accuracy: 0.9294 - lr: 1.9531e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 191/2500\n",
      "Epoch 191/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9287 - Test Accuracy: 0.9270\n",
      "312/312 - 128s - loss: 0.2764 - accuracy: 0.9973 - val_loss: 0.5425 - val_accuracy: 0.9287 - lr: 1.9531e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 192/2500\n",
      "Epoch 192/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9293 - Test Accuracy: 0.9265\n",
      "312/312 - 128s - loss: 0.2761 - accuracy: 0.9975 - val_loss: 0.5416 - val_accuracy: 0.9293 - lr: 1.9531e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 193/2500\n",
      "Epoch 193/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9298 - Test Accuracy: 0.9262\n",
      "312/312 - 128s - loss: 0.2764 - accuracy: 0.9973 - val_loss: 0.5417 - val_accuracy: 0.9298 - lr: 1.9531e-04 - 128s/epoch - 409ms/step\n",
      "Epoch 194/2500\n",
      "Epoch 194/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9290 - Test Accuracy: 0.9263\n",
      "312/312 - 128s - loss: 0.2752 - accuracy: 0.9976 - val_loss: 0.5419 - val_accuracy: 0.9290 - lr: 1.9531e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 195/2500\n",
      "Epoch 195/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9299 - Test Accuracy: 0.9265\n",
      "312/312 - 128s - loss: 0.2750 - accuracy: 0.9974 - val_loss: 0.5403 - val_accuracy: 0.9299 - lr: 1.9531e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 196/2500\n",
      "Epoch 196/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9297 - Test Accuracy: 0.9265\n",
      "312/312 - 128s - loss: 0.2752 - accuracy: 0.9975 - val_loss: 0.5381 - val_accuracy: 0.9297 - lr: 1.9531e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 197/2500\n",
      "Epoch 197/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9292 - Test Accuracy: 0.9260\n",
      "312/312 - 128s - loss: 0.2746 - accuracy: 0.9973 - val_loss: 0.5391 - val_accuracy: 0.9292 - lr: 1.9531e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 198/2500\n",
      "Epoch 198/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9285 - Test Accuracy: 0.9254\n",
      "312/312 - 128s - loss: 0.2732 - accuracy: 0.9979 - val_loss: 0.5396 - val_accuracy: 0.9285 - lr: 1.9531e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 199/2500\n",
      "Epoch 199/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9297 - Test Accuracy: 0.9271\n",
      "312/312 - 128s - loss: 0.2737 - accuracy: 0.9974 - val_loss: 0.5375 - val_accuracy: 0.9297 - lr: 1.9531e-04 - 128s/epoch - 410ms/step\n",
      "Epoch 200/2500\n",
      "Epoch 200/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9288 - Test Accuracy: 0.9270\n",
      "312/312 - 128s - loss: 0.2726 - accuracy: 0.9979 - val_loss: 0.5397 - val_accuracy: 0.9288 - lr: 1.9531e-04 - 128s/epoch - 411ms/step\n",
      "Epoch 201/2500\n",
      "Epoch 201/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9286 - Test Accuracy: 0.9272\n",
      "312/312 - 128s - loss: 0.2718 - accuracy: 0.9981 - val_loss: 0.5370 - val_accuracy: 0.9286 - lr: 9.7656e-05 - 128s/epoch - 411ms/step\n",
      "Epoch 202/2500\n",
      "Epoch 202/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9291 - Test Accuracy: 0.9272\n",
      "312/312 - 128s - loss: 0.2720 - accuracy: 0.9981 - val_loss: 0.5362 - val_accuracy: 0.9291 - lr: 9.7656e-05 - 128s/epoch - 410ms/step\n",
      "Epoch 203/2500\n",
      "Epoch 203/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9293 - Test Accuracy: 0.9274\n",
      "312/312 - 128s - loss: 0.2718 - accuracy: 0.9977 - val_loss: 0.5369 - val_accuracy: 0.9293 - lr: 9.7656e-05 - 128s/epoch - 410ms/step\n",
      "Epoch 204/2500\n",
      "Epoch 204/2500 - Train Accuracy: 0.9999 - Val Accuracy: 0.9293 - Test Accuracy: 0.9270\n",
      "312/312 - 128s - loss: 0.2730 - accuracy: 0.9974 - val_loss: 0.5376 - val_accuracy: 0.9293 - lr: 9.7656e-05 - 128s/epoch - 411ms/step\n",
      "Epoch 205/2500\n",
      "Epoch 205/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9287 - Test Accuracy: 0.9268\n",
      "312/312 - 128s - loss: 0.2724 - accuracy: 0.9975 - val_loss: 0.5376 - val_accuracy: 0.9287 - lr: 9.7656e-05 - 128s/epoch - 410ms/step\n",
      "Epoch 206/2500\n",
      "Epoch 206/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9296 - Test Accuracy: 0.9276\n",
      "312/312 - 128s - loss: 0.2724 - accuracy: 0.9976 - val_loss: 0.5362 - val_accuracy: 0.9296 - lr: 9.7656e-05 - 128s/epoch - 410ms/step\n",
      "Epoch 207/2500\n",
      "Epoch 207/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9289 - Test Accuracy: 0.9276\n",
      "312/312 - 128s - loss: 0.2718 - accuracy: 0.9979 - val_loss: 0.5362 - val_accuracy: 0.9289 - lr: 9.7656e-05 - 128s/epoch - 410ms/step\n",
      "Epoch 208/2500\n",
      "Epoch 208/2500 - Train Accuracy: 1.0000 - Val Accuracy: 0.9287 - Test Accuracy: 0.9269\n",
      "312/312 - 128s - loss: 0.2718 - accuracy: 0.9975 - val_loss: 0.5374 - val_accuracy: 0.9287 - lr: 9.7656e-05 - 128s/epoch - 410ms/step\n",
      "Epoch 209/2500\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/vgg16_model_2/dense_4/MatMul/MatMul_1' defined at (most recent call last):\n    File \"C:\\Users\\User\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\User\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\User\\anaconda3\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"C:\\Users\\User\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\User\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\User\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7552\\4230676952.py\", line 162, in <module>\n      model.fit(datagen.flow(train_images, train_labels,\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/vgg16_model_2/dense_4/MatMul/MatMul_1'\nOOM when allocating tensor with shape[524288,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/vgg16_model_2/dense_4/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2580636]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 162\u001b[0m\n\u001b[0;32m    158\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m    159\u001b[0m                                     decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, momentum\u001b[38;5;241m=\u001b[39mmomentum, nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 162\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEpochEndCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/vgg16_model_2/dense_4/MatMul/MatMul_1' defined at (most recent call last):\n    File \"C:\\Users\\User\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\User\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\User\\anaconda3\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"C:\\Users\\User\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\User\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\User\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7552\\4230676952.py\", line 162, in <module>\n      model.fit(datagen.flow(train_images, train_labels,\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/vgg16_model_2/dense_4/MatMul/MatMul_1'\nOOM when allocating tensor with shape[524288,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/vgg16_model_2/dense_4/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2580636]"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def normalization(train_images, test_images):\n",
    "    mean = np.mean(train_images, axis=(0, 1, 2, 3))\n",
    "    std = np.std(train_images, axis=(0, 1, 2, 3))\n",
    "    train_images = (train_images - mean) / (std + 1e-7)\n",
    "    test_images = (test_images - mean) / (std + 1e-7)\n",
    "    return train_images, test_images\n",
    "\n",
    "\n",
    "def load_images():\n",
    "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "    train_images = train_images.astype(np.float32)\n",
    "    test_images = test_images.astype(np.float32)\n",
    "\n",
    "    (train_images, test_images) = normalization(train_images, test_images)\n",
    "\n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "    # Randomly select 20% of the training data as validation data\n",
    "    validation_split = 0.2\n",
    "    split_index = int(train_images.shape[0] * (1 - validation_split))\n",
    "    train_images, val_images = train_images[:split_index], train_images[split_index:]\n",
    "    train_labels, val_labels = train_labels[:split_index], train_labels[split_index:]\n",
    "\n",
    "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
    "\n",
    "class EpochEndCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_data, val_data, test_data):\n",
    "        super(EpochEndCallback, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_loss, train_accuracy = self.model.evaluate(self.train_data[0], self.train_data[1], verbose=0)\n",
    "        val_loss, val_accuracy = self.model.evaluate(self.val_data[0], self.val_data[1], verbose=0)\n",
    "        test_loss, test_accuracy = self.model.evaluate(self.test_data[0], self.test_data[1], verbose=0)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{training_epochs} - '\n",
    "              f'Train Accuracy: {train_accuracy:.4f} - '\n",
    "              f'Val Accuracy: {val_accuracy:.4f} - '\n",
    "              f'Test Accuracy: {test_accuracy:.4f}')\n",
    "class ConvBNRelu(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size=3, strides=1, padding='SAME', weight_decay=0.0005, rate=0.4, drop=True):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.drop = drop\n",
    "        self.conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                                        padding=padding, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dropOut = keras.layers.Dropout(rate=rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        layer = self.conv(inputs)\n",
    "        layer = tf.nn.relu(layer)\n",
    "        layer = self.batchnorm(layer)\n",
    "        if self.drop:\n",
    "            layer = self.dropOut(layer)\n",
    "\n",
    "        return layer\n",
    "\n",
    "class VGG16Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16Model, self).__init__()\n",
    "        self.conv1 = ConvBNRelu(filters=64, kernel_size=[3, 3], rate=0.3)\n",
    "        self.conv2 = ConvBNRelu(filters=64, kernel_size=[3, 3], drop=False)\n",
    "        self.conv3 = ConvBNRelu(filters=128, kernel_size=[3, 3])\n",
    "        self.conv4 = ConvBNRelu(filters=128, kernel_size=[3, 3], drop=False)\n",
    "        self.conv5 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv6 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv7 = ConvBNRelu(filters=256, kernel_size=[3, 3], drop=False)\n",
    "        self.conv11 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv12 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv13 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.conv14 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv15 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv16 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.flat = keras.layers.Flatten()\n",
    "        self.dropOut = keras.layers.Dropout(rate=0.5)\n",
    "        self.dense1 = keras.layers.Dense(units=512,\n",
    "                                         activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dense2 = keras.layers.Dense(units=10)\n",
    "        self.softmax = keras.layers.Activation('softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs, training=training)\n",
    "        net = self.conv2(net, training=training)\n",
    "        net = self.conv3(net, training=training)\n",
    "        net = self.conv4(net, training=training)\n",
    "        net = self.conv5(net, training=training)\n",
    "        net = self.conv6(net, training=training)\n",
    "        net = self.conv7(net, training=training)\n",
    "        net = self.conv11(net, training=training)\n",
    "        net = self.conv12(net, training=training)\n",
    "        net = self.conv13(net, training=training)\n",
    "        net = self.conv14(net, training=training)\n",
    "        net = self.conv15(net, training=training)\n",
    "        net = self.conv16(net, training=training)\n",
    "        net = self.dropOut(net)\n",
    "        net = self.flat(net)\n",
    "        net = self.dense1(net)\n",
    "        net = self.batchnorm(net)\n",
    "        net = self.dense2(net)\n",
    "        net = self.softmax(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(tf.__version__)\n",
    "    print(keras.__version__)\n",
    "\n",
    "    training_epochs = 2500\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.9\n",
    "    lr_decay = 1e-6\n",
    "    lr_drop = 20\n",
    "\n",
    "    tf.random.set_seed(777)\n",
    "\n",
    "    def lr_scheduler(epoch):\n",
    "        return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "\n",
    "    reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    train_images, train_labels, val_images, val_labels, test_images, test_labels = load_images()\n",
    "\n",
    "    # data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model = VGG16Model()\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,\n",
    "                                        decay=1e-6, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.fit(datagen.flow(train_images, train_labels,\n",
    "                                     batch_size=batch_size), \n",
    "                        epochs=training_epochs, \n",
    "                        verbose=2, \n",
    "                        callbacks=[reduce_lr, EpochEndCallback((train_images, train_labels), (val_images, val_labels), (test_images, test_labels))],\n",
    "                        steps_per_epoch=train_images.shape[0] // batch_size,\n",
    "                        validation_data=(val_images, val_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c1c8ce-d97d-4a23-8ae2-63c5d78b135e",
   "metadata": {},
   "source": [
    "2. bn제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21fc60e5-afd9-4669-8355-60e34fc20006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "2.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7552\\2296324173.py:170: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(train_images, train_labels,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "Epoch 1/2500 - Train Accuracy: 0.1681 - Val Accuracy: 0.1711 - Test Accuracy: 0.1663\n",
      "312/312 - 25s - loss: 15.3884 - accuracy: 0.1865 - val_loss: 12.2614 - val_accuracy: 0.1711 - lr: 0.1000 - 25s/epoch - 79ms/step\n",
      "Epoch 2/2500\n",
      "Epoch 2/2500 - Train Accuracy: 0.1599 - Val Accuracy: 0.1668 - Test Accuracy: 0.1671\n",
      "312/312 - 22s - loss: 9.3646 - accuracy: 0.2746 - val_loss: 7.8426 - val_accuracy: 0.1668 - lr: 0.1000 - 22s/epoch - 71ms/step\n",
      "Epoch 3/2500\n",
      "Epoch 3/2500 - Train Accuracy: 0.2077 - Val Accuracy: 0.2083 - Test Accuracy: 0.2051\n",
      "312/312 - 22s - loss: 5.8377 - accuracy: 0.3283 - val_loss: 5.7074 - val_accuracy: 0.2083 - lr: 0.1000 - 22s/epoch - 72ms/step\n",
      "Epoch 4/2500\n",
      "Epoch 4/2500 - Train Accuracy: 0.4217 - Val Accuracy: 0.4233 - Test Accuracy: 0.4236\n",
      "312/312 - 23s - loss: 3.9215 - accuracy: 0.3941 - val_loss: 3.2750 - val_accuracy: 0.4233 - lr: 0.1000 - 23s/epoch - 74ms/step\n",
      "Epoch 5/2500\n",
      "Epoch 5/2500 - Train Accuracy: 0.4241 - Val Accuracy: 0.4230 - Test Accuracy: 0.4246\n",
      "312/312 - 22s - loss: 2.9087 - accuracy: 0.4405 - val_loss: 2.6963 - val_accuracy: 0.4230 - lr: 0.1000 - 22s/epoch - 72ms/step\n",
      "Epoch 6/2500\n",
      "Epoch 6/2500 - Train Accuracy: 0.4190 - Val Accuracy: 0.4140 - Test Accuracy: 0.4236\n",
      "312/312 - 22s - loss: 2.3563 - accuracy: 0.4835 - val_loss: 2.4254 - val_accuracy: 0.4140 - lr: 0.1000 - 22s/epoch - 72ms/step\n",
      "Epoch 7/2500\n",
      "Epoch 7/2500 - Train Accuracy: 0.4970 - Val Accuracy: 0.4950 - Test Accuracy: 0.4934\n",
      "312/312 - 22s - loss: 2.0885 - accuracy: 0.5119 - val_loss: 2.0981 - val_accuracy: 0.4950 - lr: 0.1000 - 22s/epoch - 72ms/step\n",
      "Epoch 8/2500\n",
      "Epoch 8/2500 - Train Accuracy: 0.5369 - Val Accuracy: 0.5277 - Test Accuracy: 0.5344\n",
      "312/312 - 23s - loss: 2.0836 - accuracy: 0.5034 - val_loss: 2.0127 - val_accuracy: 0.5277 - lr: 0.1000 - 23s/epoch - 75ms/step\n",
      "Epoch 9/2500\n",
      "Epoch 9/2500 - Train Accuracy: 0.5570 - Val Accuracy: 0.5539 - Test Accuracy: 0.5466\n",
      "312/312 - 22s - loss: 2.0592 - accuracy: 0.5246 - val_loss: 1.9695 - val_accuracy: 0.5539 - lr: 0.1000 - 22s/epoch - 72ms/step\n",
      "Epoch 10/2500\n",
      "Epoch 10/2500 - Train Accuracy: 0.5291 - Val Accuracy: 0.5259 - Test Accuracy: 0.5252\n",
      "312/312 - 22s - loss: 1.9954 - accuracy: 0.5432 - val_loss: 2.0203 - val_accuracy: 0.5259 - lr: 0.1000 - 22s/epoch - 72ms/step\n",
      "Epoch 11/2500\n",
      "Epoch 11/2500 - Train Accuracy: 0.5412 - Val Accuracy: 0.5397 - Test Accuracy: 0.5358\n",
      "312/312 - 23s - loss: 1.9524 - accuracy: 0.5574 - val_loss: 2.0308 - val_accuracy: 0.5397 - lr: 0.1000 - 23s/epoch - 72ms/step\n",
      "Epoch 12/2500\n",
      "Epoch 12/2500 - Train Accuracy: 0.5098 - Val Accuracy: 0.5107 - Test Accuracy: 0.5055\n",
      "312/312 - 22s - loss: 1.9467 - accuracy: 0.5731 - val_loss: 2.2832 - val_accuracy: 0.5107 - lr: 0.1000 - 22s/epoch - 72ms/step\n",
      "Epoch 13/2500\n",
      "Epoch 13/2500 - Train Accuracy: 0.6403 - Val Accuracy: 0.6373 - Test Accuracy: 0.6228\n",
      "312/312 - 23s - loss: 2.0680 - accuracy: 0.5553 - val_loss: 1.7778 - val_accuracy: 0.6373 - lr: 0.1000 - 23s/epoch - 73ms/step\n",
      "Epoch 14/2500\n",
      "Epoch 14/2500 - Train Accuracy: 0.6598 - Val Accuracy: 0.6482 - Test Accuracy: 0.6543\n",
      "312/312 - 22s - loss: 1.9051 - accuracy: 0.5917 - val_loss: 1.6834 - val_accuracy: 0.6482 - lr: 0.1000 - 22s/epoch - 72ms/step\n",
      "Epoch 15/2500\n",
      "Epoch 15/2500 - Train Accuracy: 0.6740 - Val Accuracy: 0.6605 - Test Accuracy: 0.6577\n",
      "312/312 - 23s - loss: 1.8343 - accuracy: 0.6031 - val_loss: 1.6366 - val_accuracy: 0.6605 - lr: 0.1000 - 23s/epoch - 74ms/step\n",
      "Epoch 16/2500\n",
      "Epoch 16/2500 - Train Accuracy: 0.5802 - Val Accuracy: 0.5775 - Test Accuracy: 0.5716\n",
      "312/312 - 23s - loss: 1.7351 - accuracy: 0.6314 - val_loss: 2.0446 - val_accuracy: 0.5775 - lr: 0.1000 - 23s/epoch - 73ms/step\n",
      "Epoch 17/2500\n",
      "Epoch 17/2500 - Train Accuracy: 0.6692 - Val Accuracy: 0.6618 - Test Accuracy: 0.6652\n",
      "312/312 - 24s - loss: 1.7966 - accuracy: 0.6202 - val_loss: 1.7127 - val_accuracy: 0.6618 - lr: 0.1000 - 24s/epoch - 76ms/step\n",
      "Epoch 18/2500\n",
      "Epoch 18/2500 - Train Accuracy: 0.6771 - Val Accuracy: 0.6756 - Test Accuracy: 0.6707\n",
      "312/312 - 23s - loss: 1.8380 - accuracy: 0.6201 - val_loss: 1.6988 - val_accuracy: 0.6756 - lr: 0.1000 - 23s/epoch - 74ms/step\n",
      "Epoch 19/2500\n",
      "Epoch 19/2500 - Train Accuracy: 0.6904 - Val Accuracy: 0.6834 - Test Accuracy: 0.6783\n",
      "312/312 - 23s - loss: 1.8530 - accuracy: 0.6251 - val_loss: 1.6958 - val_accuracy: 0.6834 - lr: 0.1000 - 23s/epoch - 72ms/step\n",
      "Epoch 20/2500\n",
      "Epoch 20/2500 - Train Accuracy: 0.6974 - Val Accuracy: 0.6846 - Test Accuracy: 0.6824\n",
      "312/312 - 23s - loss: 1.7195 - accuracy: 0.6599 - val_loss: 1.6226 - val_accuracy: 0.6846 - lr: 0.1000 - 23s/epoch - 75ms/step\n",
      "Epoch 21/2500\n",
      "Epoch 21/2500 - Train Accuracy: 0.7603 - Val Accuracy: 0.7539 - Test Accuracy: 0.7415\n",
      "312/312 - 23s - loss: 1.4998 - accuracy: 0.7146 - val_loss: 1.3356 - val_accuracy: 0.7539 - lr: 0.0500 - 23s/epoch - 73ms/step\n",
      "Epoch 22/2500\n",
      "Epoch 22/2500 - Train Accuracy: 0.7710 - Val Accuracy: 0.7616 - Test Accuracy: 0.7592\n",
      "312/312 - 23s - loss: 1.4933 - accuracy: 0.7006 - val_loss: 1.2882 - val_accuracy: 0.7616 - lr: 0.0500 - 23s/epoch - 74ms/step\n",
      "Epoch 23/2500\n",
      "Epoch 23/2500 - Train Accuracy: 0.7720 - Val Accuracy: 0.7622 - Test Accuracy: 0.7602\n",
      "312/312 - 23s - loss: 1.3642 - accuracy: 0.7263 - val_loss: 1.2200 - val_accuracy: 0.7622 - lr: 0.0500 - 23s/epoch - 72ms/step\n",
      "Epoch 24/2500\n",
      "Epoch 24/2500 - Train Accuracy: 0.7684 - Val Accuracy: 0.7572 - Test Accuracy: 0.7530\n",
      "312/312 - 24s - loss: 1.3040 - accuracy: 0.7356 - val_loss: 1.2566 - val_accuracy: 0.7572 - lr: 0.0500 - 24s/epoch - 76ms/step\n",
      "Epoch 25/2500\n",
      "Epoch 25/2500 - Train Accuracy: 0.7789 - Val Accuracy: 0.7664 - Test Accuracy: 0.7638\n",
      "312/312 - 23s - loss: 1.3660 - accuracy: 0.7201 - val_loss: 1.2420 - val_accuracy: 0.7664 - lr: 0.0500 - 23s/epoch - 72ms/step\n",
      "Epoch 26/2500\n",
      "Epoch 26/2500 - Train Accuracy: 0.7653 - Val Accuracy: 0.7547 - Test Accuracy: 0.7464\n",
      "312/312 - 23s - loss: 1.3175 - accuracy: 0.7376 - val_loss: 1.3015 - val_accuracy: 0.7547 - lr: 0.0500 - 23s/epoch - 74ms/step\n",
      "Epoch 27/2500\n",
      "Epoch 27/2500 - Train Accuracy: 0.7904 - Val Accuracy: 0.7806 - Test Accuracy: 0.7739\n",
      "312/312 - 22s - loss: 1.2756 - accuracy: 0.7479 - val_loss: 1.1818 - val_accuracy: 0.7806 - lr: 0.0500 - 22s/epoch - 72ms/step\n",
      "Epoch 28/2500\n",
      "Epoch 28/2500 - Train Accuracy: 0.7910 - Val Accuracy: 0.7787 - Test Accuracy: 0.7721\n",
      "312/312 - 22s - loss: 1.2665 - accuracy: 0.7526 - val_loss: 1.1967 - val_accuracy: 0.7787 - lr: 0.0500 - 22s/epoch - 72ms/step\n",
      "Epoch 29/2500\n",
      "Epoch 29/2500 - Train Accuracy: 0.8237 - Val Accuracy: 0.8010 - Test Accuracy: 0.8037\n",
      "312/312 - 23s - loss: 1.2455 - accuracy: 0.7602 - val_loss: 1.1029 - val_accuracy: 0.8010 - lr: 0.0500 - 23s/epoch - 74ms/step\n",
      "Epoch 30/2500\n",
      "Epoch 30/2500 - Train Accuracy: 0.7871 - Val Accuracy: 0.7705 - Test Accuracy: 0.7747\n",
      "312/312 - 23s - loss: 1.2529 - accuracy: 0.7571 - val_loss: 1.2378 - val_accuracy: 0.7705 - lr: 0.0500 - 23s/epoch - 74ms/step\n",
      "Epoch 31/2500\n",
      "Epoch 31/2500 - Train Accuracy: 0.7932 - Val Accuracy: 0.7756 - Test Accuracy: 0.7741\n",
      "312/312 - 23s - loss: 1.2540 - accuracy: 0.7605 - val_loss: 1.2106 - val_accuracy: 0.7756 - lr: 0.0500 - 23s/epoch - 73ms/step\n",
      "Epoch 32/2500\n",
      "Epoch 32/2500 - Train Accuracy: 0.8107 - Val Accuracy: 0.7969 - Test Accuracy: 0.7890\n",
      "312/312 - 23s - loss: 1.2332 - accuracy: 0.7703 - val_loss: 1.1559 - val_accuracy: 0.7969 - lr: 0.0500 - 23s/epoch - 73ms/step\n",
      "Epoch 33/2500\n",
      "Epoch 33/2500 - Train Accuracy: 0.7852 - Val Accuracy: 0.7706 - Test Accuracy: 0.7621\n",
      "312/312 - 23s - loss: 1.2445 - accuracy: 0.7680 - val_loss: 1.2762 - val_accuracy: 0.7706 - lr: 0.0500 - 23s/epoch - 74ms/step\n",
      "Epoch 34/2500\n",
      "Epoch 34/2500 - Train Accuracy: 0.8108 - Val Accuracy: 0.7946 - Test Accuracy: 0.7886\n",
      "312/312 - 23s - loss: 1.2558 - accuracy: 0.7691 - val_loss: 1.2002 - val_accuracy: 0.7946 - lr: 0.0500 - 23s/epoch - 73ms/step\n",
      "Epoch 35/2500\n",
      "Epoch 35/2500 - Train Accuracy: 0.7928 - Val Accuracy: 0.7700 - Test Accuracy: 0.7737\n",
      "312/312 - 23s - loss: 1.2336 - accuracy: 0.7773 - val_loss: 1.2613 - val_accuracy: 0.7700 - lr: 0.0500 - 23s/epoch - 73ms/step\n",
      "Epoch 36/2500\n",
      "Epoch 36/2500 - Train Accuracy: 0.8063 - Val Accuracy: 0.7926 - Test Accuracy: 0.7811\n",
      "312/312 - 23s - loss: 1.2562 - accuracy: 0.7739 - val_loss: 1.2406 - val_accuracy: 0.7926 - lr: 0.0500 - 23s/epoch - 75ms/step\n",
      "Epoch 37/2500\n",
      "Epoch 37/2500 - Train Accuracy: 0.8288 - Val Accuracy: 0.8061 - Test Accuracy: 0.7994\n",
      "312/312 - 23s - loss: 1.2468 - accuracy: 0.7827 - val_loss: 1.1688 - val_accuracy: 0.8061 - lr: 0.0500 - 23s/epoch - 72ms/step\n",
      "Epoch 38/2500\n",
      "Epoch 38/2500 - Train Accuracy: 0.8052 - Val Accuracy: 0.7899 - Test Accuracy: 0.7815\n",
      "312/312 - 23s - loss: 1.2416 - accuracy: 0.7812 - val_loss: 1.2245 - val_accuracy: 0.7899 - lr: 0.0500 - 23s/epoch - 73ms/step\n",
      "Epoch 39/2500\n",
      "Epoch 39/2500 - Train Accuracy: 0.8349 - Val Accuracy: 0.8077 - Test Accuracy: 0.8107\n",
      "312/312 - 22s - loss: 1.2404 - accuracy: 0.7852 - val_loss: 1.1695 - val_accuracy: 0.8077 - lr: 0.0500 - 22s/epoch - 72ms/step\n",
      "Epoch 40/2500\n",
      "Epoch 40/2500 - Train Accuracy: 0.8294 - Val Accuracy: 0.8085 - Test Accuracy: 0.8053\n",
      "312/312 - 23s - loss: 1.2368 - accuracy: 0.7853 - val_loss: 1.1788 - val_accuracy: 0.8085 - lr: 0.0500 - 23s/epoch - 74ms/step\n",
      "Epoch 41/2500\n",
      "Epoch 41/2500 - Train Accuracy: 0.8712 - Val Accuracy: 0.8419 - Test Accuracy: 0.8441\n",
      "312/312 - 23s - loss: 1.1205 - accuracy: 0.8181 - val_loss: 1.0213 - val_accuracy: 0.8419 - lr: 0.0250 - 23s/epoch - 73ms/step\n",
      "Epoch 42/2500\n",
      "Epoch 42/2500 - Train Accuracy: 0.8826 - Val Accuracy: 0.8519 - Test Accuracy: 0.8511\n",
      "312/312 - 23s - loss: 1.0471 - accuracy: 0.8306 - val_loss: 0.9638 - val_accuracy: 0.8519 - lr: 0.0250 - 23s/epoch - 73ms/step\n",
      "Epoch 43/2500\n",
      "Epoch 43/2500 - Train Accuracy: 0.8801 - Val Accuracy: 0.8517 - Test Accuracy: 0.8487\n",
      "312/312 - 23s - loss: 1.0052 - accuracy: 0.8359 - val_loss: 0.9410 - val_accuracy: 0.8517 - lr: 0.0250 - 23s/epoch - 73ms/step\n",
      "Epoch 44/2500\n",
      "Epoch 44/2500 - Train Accuracy: 0.8824 - Val Accuracy: 0.8540 - Test Accuracy: 0.8513\n",
      "312/312 - 23s - loss: 0.9864 - accuracy: 0.8347 - val_loss: 0.9182 - val_accuracy: 0.8540 - lr: 0.0250 - 23s/epoch - 73ms/step\n",
      "Epoch 45/2500\n",
      "Epoch 45/2500 - Train Accuracy: 0.8882 - Val Accuracy: 0.8578 - Test Accuracy: 0.8520\n",
      "312/312 - 23s - loss: 0.9741 - accuracy: 0.8348 - val_loss: 0.9038 - val_accuracy: 0.8578 - lr: 0.0250 - 23s/epoch - 73ms/step\n",
      "Epoch 46/2500\n",
      "Epoch 46/2500 - Train Accuracy: 0.8612 - Val Accuracy: 0.8381 - Test Accuracy: 0.8274\n",
      "312/312 - 23s - loss: 0.9764 - accuracy: 0.8318 - val_loss: 0.9630 - val_accuracy: 0.8381 - lr: 0.0250 - 23s/epoch - 75ms/step\n",
      "Epoch 47/2500\n",
      "Epoch 47/2500 - Train Accuracy: 0.8609 - Val Accuracy: 0.8366 - Test Accuracy: 0.8259\n",
      "312/312 - 26s - loss: 0.9688 - accuracy: 0.8345 - val_loss: 0.9725 - val_accuracy: 0.8366 - lr: 0.0250 - 26s/epoch - 83ms/step\n",
      "Epoch 48/2500\n",
      "Epoch 48/2500 - Train Accuracy: 0.8776 - Val Accuracy: 0.8450 - Test Accuracy: 0.8442\n",
      "312/312 - 23s - loss: 0.9594 - accuracy: 0.8382 - val_loss: 0.9310 - val_accuracy: 0.8450 - lr: 0.0250 - 23s/epoch - 75ms/step\n",
      "Epoch 49/2500\n",
      "Epoch 49/2500 - Train Accuracy: 0.8718 - Val Accuracy: 0.8390 - Test Accuracy: 0.8385\n",
      "312/312 - 23s - loss: 0.9606 - accuracy: 0.8376 - val_loss: 0.9404 - val_accuracy: 0.8390 - lr: 0.0250 - 23s/epoch - 74ms/step\n",
      "Epoch 50/2500\n",
      "Epoch 50/2500 - Train Accuracy: 0.8772 - Val Accuracy: 0.8448 - Test Accuracy: 0.8422\n",
      "312/312 - 23s - loss: 0.9583 - accuracy: 0.8394 - val_loss: 0.9444 - val_accuracy: 0.8448 - lr: 0.0250 - 23s/epoch - 74ms/step\n",
      "Epoch 51/2500\n",
      "Epoch 51/2500 - Train Accuracy: 0.8680 - Val Accuracy: 0.8363 - Test Accuracy: 0.8302\n",
      "312/312 - 23s - loss: 0.9608 - accuracy: 0.8389 - val_loss: 0.9777 - val_accuracy: 0.8363 - lr: 0.0250 - 23s/epoch - 74ms/step\n",
      "Epoch 52/2500\n",
      "Epoch 52/2500 - Train Accuracy: 0.8813 - Val Accuracy: 0.8541 - Test Accuracy: 0.8467\n",
      "312/312 - 24s - loss: 0.9527 - accuracy: 0.8423 - val_loss: 0.9267 - val_accuracy: 0.8541 - lr: 0.0250 - 24s/epoch - 77ms/step\n",
      "Epoch 53/2500\n",
      "Epoch 53/2500 - Train Accuracy: 0.8938 - Val Accuracy: 0.8656 - Test Accuracy: 0.8550\n",
      "312/312 - 23s - loss: 0.9598 - accuracy: 0.8397 - val_loss: 0.8940 - val_accuracy: 0.8656 - lr: 0.0250 - 23s/epoch - 74ms/step\n",
      "Epoch 54/2500\n",
      "Epoch 54/2500 - Train Accuracy: 0.8720 - Val Accuracy: 0.8459 - Test Accuracy: 0.8386\n",
      "312/312 - 23s - loss: 0.9660 - accuracy: 0.8392 - val_loss: 0.9610 - val_accuracy: 0.8459 - lr: 0.0250 - 23s/epoch - 73ms/step\n",
      "Epoch 55/2500\n",
      "Epoch 55/2500 - Train Accuracy: 0.8852 - Val Accuracy: 0.8545 - Test Accuracy: 0.8480\n",
      "312/312 - 22s - loss: 0.9568 - accuracy: 0.8447 - val_loss: 0.9138 - val_accuracy: 0.8545 - lr: 0.0250 - 22s/epoch - 72ms/step\n",
      "Epoch 56/2500\n",
      "Epoch 56/2500 - Train Accuracy: 0.8859 - Val Accuracy: 0.8537 - Test Accuracy: 0.8511\n",
      "312/312 - 24s - loss: 0.9632 - accuracy: 0.8435 - val_loss: 0.9419 - val_accuracy: 0.8537 - lr: 0.0250 - 24s/epoch - 75ms/step\n",
      "Epoch 57/2500\n",
      "Epoch 57/2500 - Train Accuracy: 0.8809 - Val Accuracy: 0.8540 - Test Accuracy: 0.8490\n",
      "312/312 - 23s - loss: 0.9598 - accuracy: 0.8474 - val_loss: 0.9395 - val_accuracy: 0.8540 - lr: 0.0250 - 23s/epoch - 73ms/step\n",
      "Epoch 58/2500\n",
      "Epoch 58/2500 - Train Accuracy: 0.8739 - Val Accuracy: 0.8475 - Test Accuracy: 0.8401\n",
      "312/312 - 23s - loss: 0.9711 - accuracy: 0.8448 - val_loss: 0.9899 - val_accuracy: 0.8475 - lr: 0.0250 - 23s/epoch - 72ms/step\n",
      "Epoch 59/2500\n",
      "Epoch 59/2500 - Train Accuracy: 0.8907 - Val Accuracy: 0.8613 - Test Accuracy: 0.8545\n",
      "312/312 - 23s - loss: 0.9712 - accuracy: 0.8454 - val_loss: 0.9228 - val_accuracy: 0.8613 - lr: 0.0250 - 23s/epoch - 73ms/step\n",
      "Epoch 60/2500\n",
      "Epoch 60/2500 - Train Accuracy: 0.8949 - Val Accuracy: 0.8651 - Test Accuracy: 0.8567\n",
      "312/312 - 22s - loss: 0.9729 - accuracy: 0.8442 - val_loss: 0.9095 - val_accuracy: 0.8651 - lr: 0.0250 - 22s/epoch - 71ms/step\n",
      "Epoch 61/2500\n",
      "Epoch 61/2500 - Train Accuracy: 0.9242 - Val Accuracy: 0.8894 - Test Accuracy: 0.8817\n",
      "312/312 - 22s - loss: 0.8903 - accuracy: 0.8693 - val_loss: 0.8246 - val_accuracy: 0.8894 - lr: 0.0125 - 22s/epoch - 72ms/step\n",
      "Epoch 62/2500\n",
      "Epoch 62/2500 - Train Accuracy: 0.9215 - Val Accuracy: 0.8849 - Test Accuracy: 0.8743\n",
      "312/312 - 23s - loss: 0.8388 - accuracy: 0.8789 - val_loss: 0.8236 - val_accuracy: 0.8849 - lr: 0.0125 - 23s/epoch - 73ms/step\n",
      "Epoch 63/2500\n",
      "Epoch 63/2500 - Train Accuracy: 0.9342 - Val Accuracy: 0.8961 - Test Accuracy: 0.8873\n",
      "312/312 - 23s - loss: 0.8142 - accuracy: 0.8821 - val_loss: 0.7717 - val_accuracy: 0.8961 - lr: 0.0125 - 23s/epoch - 74ms/step\n",
      "Epoch 64/2500\n",
      "Epoch 64/2500 - Train Accuracy: 0.9282 - Val Accuracy: 0.8863 - Test Accuracy: 0.8816\n",
      "312/312 - 23s - loss: 0.7990 - accuracy: 0.8830 - val_loss: 0.7869 - val_accuracy: 0.8863 - lr: 0.0125 - 23s/epoch - 73ms/step\n",
      "Epoch 65/2500\n",
      "Epoch 65/2500 - Train Accuracy: 0.9288 - Val Accuracy: 0.8879 - Test Accuracy: 0.8822\n",
      "312/312 - 23s - loss: 0.7900 - accuracy: 0.8817 - val_loss: 0.7798 - val_accuracy: 0.8879 - lr: 0.0125 - 23s/epoch - 74ms/step\n",
      "Epoch 66/2500\n",
      "Epoch 66/2500 - Train Accuracy: 0.9353 - Val Accuracy: 0.8916 - Test Accuracy: 0.8841\n",
      "312/312 - 23s - loss: 0.7805 - accuracy: 0.8830 - val_loss: 0.7572 - val_accuracy: 0.8916 - lr: 0.0125 - 23s/epoch - 73ms/step\n",
      "Epoch 67/2500\n",
      "Epoch 67/2500 - Train Accuracy: 0.9314 - Val Accuracy: 0.8901 - Test Accuracy: 0.8796\n",
      "312/312 - 23s - loss: 0.7680 - accuracy: 0.8855 - val_loss: 0.7555 - val_accuracy: 0.8901 - lr: 0.0125 - 23s/epoch - 74ms/step\n",
      "Epoch 68/2500\n",
      "Epoch 68/2500 - Train Accuracy: 0.9309 - Val Accuracy: 0.8885 - Test Accuracy: 0.8837\n",
      "312/312 - 24s - loss: 0.7612 - accuracy: 0.8835 - val_loss: 0.7598 - val_accuracy: 0.8885 - lr: 0.0125 - 24s/epoch - 77ms/step\n",
      "Epoch 69/2500\n",
      "Epoch 69/2500 - Train Accuracy: 0.9330 - Val Accuracy: 0.8879 - Test Accuracy: 0.8895\n",
      "312/312 - 22s - loss: 0.7670 - accuracy: 0.8834 - val_loss: 0.7535 - val_accuracy: 0.8879 - lr: 0.0125 - 22s/epoch - 72ms/step\n",
      "Epoch 70/2500\n",
      "Epoch 70/2500 - Train Accuracy: 0.9144 - Val Accuracy: 0.8687 - Test Accuracy: 0.8691\n",
      "312/312 - 23s - loss: 0.7480 - accuracy: 0.8862 - val_loss: 0.8067 - val_accuracy: 0.8687 - lr: 0.0125 - 23s/epoch - 73ms/step\n",
      "Epoch 71/2500\n",
      "Epoch 71/2500 - Train Accuracy: 0.9221 - Val Accuracy: 0.8789 - Test Accuracy: 0.8724\n",
      "312/312 - 23s - loss: 0.7463 - accuracy: 0.8865 - val_loss: 0.7845 - val_accuracy: 0.8789 - lr: 0.0125 - 23s/epoch - 73ms/step\n",
      "Epoch 72/2500\n",
      "Epoch 72/2500 - Train Accuracy: 0.9342 - Val Accuracy: 0.8903 - Test Accuracy: 0.8841\n",
      "312/312 - 23s - loss: 0.7491 - accuracy: 0.8864 - val_loss: 0.7387 - val_accuracy: 0.8903 - lr: 0.0125 - 23s/epoch - 75ms/step\n",
      "Epoch 73/2500\n",
      "Epoch 73/2500 - Train Accuracy: 0.9359 - Val Accuracy: 0.8954 - Test Accuracy: 0.8892\n",
      "312/312 - 23s - loss: 0.7426 - accuracy: 0.8876 - val_loss: 0.7307 - val_accuracy: 0.8954 - lr: 0.0125 - 23s/epoch - 73ms/step\n",
      "Epoch 74/2500\n",
      "Epoch 74/2500 - Train Accuracy: 0.9358 - Val Accuracy: 0.8920 - Test Accuracy: 0.8841\n",
      "312/312 - 23s - loss: 0.7423 - accuracy: 0.8859 - val_loss: 0.7402 - val_accuracy: 0.8920 - lr: 0.0125 - 23s/epoch - 74ms/step\n",
      "Epoch 75/2500\n",
      "Epoch 75/2500 - Train Accuracy: 0.9320 - Val Accuracy: 0.8905 - Test Accuracy: 0.8818\n",
      "312/312 - 23s - loss: 0.7415 - accuracy: 0.8878 - val_loss: 0.7451 - val_accuracy: 0.8905 - lr: 0.0125 - 23s/epoch - 74ms/step\n",
      "Epoch 76/2500\n",
      "Epoch 76/2500 - Train Accuracy: 0.9258 - Val Accuracy: 0.8820 - Test Accuracy: 0.8776\n",
      "312/312 - 22s - loss: 0.7397 - accuracy: 0.8872 - val_loss: 0.7723 - val_accuracy: 0.8820 - lr: 0.0125 - 22s/epoch - 72ms/step\n",
      "Epoch 77/2500\n",
      "Epoch 77/2500 - Train Accuracy: 0.9371 - Val Accuracy: 0.8906 - Test Accuracy: 0.8829\n",
      "312/312 - 23s - loss: 0.7442 - accuracy: 0.8854 - val_loss: 0.7323 - val_accuracy: 0.8906 - lr: 0.0125 - 23s/epoch - 73ms/step\n",
      "Epoch 78/2500\n",
      "Epoch 78/2500 - Train Accuracy: 0.9348 - Val Accuracy: 0.8890 - Test Accuracy: 0.8851\n",
      "312/312 - 22s - loss: 0.7407 - accuracy: 0.8852 - val_loss: 0.7466 - val_accuracy: 0.8890 - lr: 0.0125 - 22s/epoch - 72ms/step\n",
      "Epoch 79/2500\n",
      "Epoch 79/2500 - Train Accuracy: 0.9312 - Val Accuracy: 0.8842 - Test Accuracy: 0.8771\n",
      "312/312 - 22s - loss: 0.7432 - accuracy: 0.8854 - val_loss: 0.7603 - val_accuracy: 0.8842 - lr: 0.0125 - 22s/epoch - 72ms/step\n",
      "Epoch 80/2500\n",
      "Epoch 80/2500 - Train Accuracy: 0.9286 - Val Accuracy: 0.8805 - Test Accuracy: 0.8719\n",
      "312/312 - 23s - loss: 0.7374 - accuracy: 0.8870 - val_loss: 0.7782 - val_accuracy: 0.8805 - lr: 0.0125 - 23s/epoch - 73ms/step\n",
      "Epoch 81/2500\n",
      "Epoch 81/2500 - Train Accuracy: 0.9484 - Val Accuracy: 0.9001 - Test Accuracy: 0.8927\n",
      "312/312 - 23s - loss: 0.6832 - accuracy: 0.9062 - val_loss: 0.7111 - val_accuracy: 0.9001 - lr: 0.0063 - 23s/epoch - 74ms/step\n",
      "Epoch 82/2500\n",
      "Epoch 82/2500 - Train Accuracy: 0.9583 - Val Accuracy: 0.9087 - Test Accuracy: 0.9005\n",
      "312/312 - 22s - loss: 0.6485 - accuracy: 0.9133 - val_loss: 0.6815 - val_accuracy: 0.9087 - lr: 0.0063 - 22s/epoch - 72ms/step\n",
      "Epoch 83/2500\n",
      "Epoch 83/2500 - Train Accuracy: 0.9564 - Val Accuracy: 0.9034 - Test Accuracy: 0.8957\n",
      "312/312 - 23s - loss: 0.6427 - accuracy: 0.9134 - val_loss: 0.6808 - val_accuracy: 0.9034 - lr: 0.0063 - 23s/epoch - 74ms/step\n",
      "Epoch 84/2500\n",
      "Epoch 84/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.9056 - Test Accuracy: 0.9014\n",
      "312/312 - 24s - loss: 0.6224 - accuracy: 0.9178 - val_loss: 0.6706 - val_accuracy: 0.9056 - lr: 0.0063 - 24s/epoch - 76ms/step\n",
      "Epoch 85/2500\n",
      "Epoch 85/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.9069 - Test Accuracy: 0.8970\n",
      "312/312 - 23s - loss: 0.6177 - accuracy: 0.9163 - val_loss: 0.6679 - val_accuracy: 0.9069 - lr: 0.0063 - 23s/epoch - 74ms/step\n",
      "Epoch 86/2500\n",
      "Epoch 86/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.9081 - Test Accuracy: 0.9002\n",
      "312/312 - 23s - loss: 0.6066 - accuracy: 0.9184 - val_loss: 0.6611 - val_accuracy: 0.9081 - lr: 0.0063 - 23s/epoch - 74ms/step\n",
      "Epoch 87/2500\n",
      "Epoch 87/2500 - Train Accuracy: 0.9581 - Val Accuracy: 0.9026 - Test Accuracy: 0.8940\n",
      "312/312 - 23s - loss: 0.6019 - accuracy: 0.9191 - val_loss: 0.6710 - val_accuracy: 0.9026 - lr: 0.0063 - 23s/epoch - 73ms/step\n",
      "Epoch 88/2500\n",
      "Epoch 88/2500 - Train Accuracy: 0.9642 - Val Accuracy: 0.9094 - Test Accuracy: 0.8980\n",
      "312/312 - 24s - loss: 0.5996 - accuracy: 0.9200 - val_loss: 0.6489 - val_accuracy: 0.9094 - lr: 0.0063 - 24s/epoch - 76ms/step\n",
      "Epoch 89/2500\n",
      "Epoch 89/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.9038 - Test Accuracy: 0.8962\n",
      "312/312 - 23s - loss: 0.5876 - accuracy: 0.9219 - val_loss: 0.6669 - val_accuracy: 0.9038 - lr: 0.0063 - 23s/epoch - 74ms/step\n",
      "Epoch 90/2500\n",
      "Epoch 90/2500 - Train Accuracy: 0.9639 - Val Accuracy: 0.9065 - Test Accuracy: 0.9016\n",
      "312/312 - 23s - loss: 0.5800 - accuracy: 0.9221 - val_loss: 0.6505 - val_accuracy: 0.9065 - lr: 0.0063 - 23s/epoch - 74ms/step\n",
      "Epoch 91/2500\n",
      "Epoch 91/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.9026 - Test Accuracy: 0.8956\n",
      "312/312 - 23s - loss: 0.5800 - accuracy: 0.9206 - val_loss: 0.6582 - val_accuracy: 0.9026 - lr: 0.0063 - 23s/epoch - 73ms/step\n",
      "Epoch 92/2500\n",
      "Epoch 92/2500 - Train Accuracy: 0.9582 - Val Accuracy: 0.9029 - Test Accuracy: 0.8939\n",
      "312/312 - 23s - loss: 0.5760 - accuracy: 0.9227 - val_loss: 0.6558 - val_accuracy: 0.9029 - lr: 0.0063 - 23s/epoch - 74ms/step\n",
      "Epoch 93/2500\n",
      "Epoch 93/2500 - Train Accuracy: 0.9590 - Val Accuracy: 0.8996 - Test Accuracy: 0.8957\n",
      "312/312 - 23s - loss: 0.5761 - accuracy: 0.9209 - val_loss: 0.6626 - val_accuracy: 0.8996 - lr: 0.0063 - 23s/epoch - 73ms/step\n",
      "Epoch 94/2500\n",
      "Epoch 94/2500 - Train Accuracy: 0.9643 - Val Accuracy: 0.9079 - Test Accuracy: 0.8998\n",
      "312/312 - 23s - loss: 0.5741 - accuracy: 0.9216 - val_loss: 0.6385 - val_accuracy: 0.9079 - lr: 0.0063 - 23s/epoch - 72ms/step\n",
      "Epoch 95/2500\n",
      "Epoch 95/2500 - Train Accuracy: 0.9570 - Val Accuracy: 0.8981 - Test Accuracy: 0.8895\n",
      "312/312 - 23s - loss: 0.5715 - accuracy: 0.9217 - val_loss: 0.6640 - val_accuracy: 0.8981 - lr: 0.0063 - 23s/epoch - 73ms/step\n",
      "Epoch 96/2500\n",
      "Epoch 96/2500 - Train Accuracy: 0.9548 - Val Accuracy: 0.8962 - Test Accuracy: 0.8870\n",
      "312/312 - 23s - loss: 0.5672 - accuracy: 0.9222 - val_loss: 0.6797 - val_accuracy: 0.8962 - lr: 0.0063 - 23s/epoch - 73ms/step\n",
      "Epoch 97/2500\n",
      "Epoch 97/2500 - Train Accuracy: 0.9541 - Val Accuracy: 0.8955 - Test Accuracy: 0.8907\n",
      "312/312 - 23s - loss: 0.5676 - accuracy: 0.9207 - val_loss: 0.6734 - val_accuracy: 0.8955 - lr: 0.0063 - 23s/epoch - 74ms/step\n",
      "Epoch 98/2500\n",
      "Epoch 98/2500 - Train Accuracy: 0.9526 - Val Accuracy: 0.8939 - Test Accuracy: 0.8847\n",
      "312/312 - 23s - loss: 0.5657 - accuracy: 0.9229 - val_loss: 0.6775 - val_accuracy: 0.8939 - lr: 0.0063 - 23s/epoch - 74ms/step\n",
      "Epoch 99/2500\n",
      "Epoch 99/2500 - Train Accuracy: 0.9672 - Val Accuracy: 0.9066 - Test Accuracy: 0.9036\n",
      "312/312 - 23s - loss: 0.5603 - accuracy: 0.9225 - val_loss: 0.6269 - val_accuracy: 0.9066 - lr: 0.0063 - 23s/epoch - 73ms/step\n",
      "Epoch 100/2500\n",
      "Epoch 100/2500 - Train Accuracy: 0.9580 - Val Accuracy: 0.8951 - Test Accuracy: 0.8880\n",
      "312/312 - 24s - loss: 0.5565 - accuracy: 0.9240 - val_loss: 0.6771 - val_accuracy: 0.8951 - lr: 0.0063 - 24s/epoch - 76ms/step\n",
      "Epoch 101/2500\n",
      "Epoch 101/2500 - Train Accuracy: 0.9781 - Val Accuracy: 0.9129 - Test Accuracy: 0.9106\n",
      "312/312 - 23s - loss: 0.5280 - accuracy: 0.9325 - val_loss: 0.6024 - val_accuracy: 0.9129 - lr: 0.0031 - 23s/epoch - 75ms/step\n",
      "Epoch 102/2500\n",
      "Epoch 102/2500 - Train Accuracy: 0.9754 - Val Accuracy: 0.9135 - Test Accuracy: 0.9087\n",
      "312/312 - 23s - loss: 0.5072 - accuracy: 0.9395 - val_loss: 0.6098 - val_accuracy: 0.9135 - lr: 0.0031 - 23s/epoch - 73ms/step\n",
      "Epoch 103/2500\n",
      "Epoch 103/2500 - Train Accuracy: 0.9774 - Val Accuracy: 0.9135 - Test Accuracy: 0.9085\n",
      "312/312 - 23s - loss: 0.4962 - accuracy: 0.9412 - val_loss: 0.6050 - val_accuracy: 0.9135 - lr: 0.0031 - 23s/epoch - 72ms/step\n",
      "Epoch 104/2500\n",
      "Epoch 104/2500 - Train Accuracy: 0.9775 - Val Accuracy: 0.9134 - Test Accuracy: 0.9069\n",
      "312/312 - 23s - loss: 0.4919 - accuracy: 0.9408 - val_loss: 0.6042 - val_accuracy: 0.9134 - lr: 0.0031 - 23s/epoch - 75ms/step\n",
      "Epoch 105/2500\n",
      "Epoch 105/2500 - Train Accuracy: 0.9793 - Val Accuracy: 0.9159 - Test Accuracy: 0.9120\n",
      "312/312 - 23s - loss: 0.4861 - accuracy: 0.9422 - val_loss: 0.5929 - val_accuracy: 0.9159 - lr: 0.0031 - 23s/epoch - 72ms/step\n",
      "Epoch 106/2500\n",
      "Epoch 106/2500 - Train Accuracy: 0.9818 - Val Accuracy: 0.9190 - Test Accuracy: 0.9115\n",
      "312/312 - 23s - loss: 0.4789 - accuracy: 0.9424 - val_loss: 0.5769 - val_accuracy: 0.9190 - lr: 0.0031 - 23s/epoch - 72ms/step\n",
      "Epoch 107/2500\n",
      "Epoch 107/2500 - Train Accuracy: 0.9785 - Val Accuracy: 0.9130 - Test Accuracy: 0.9050\n",
      "312/312 - 23s - loss: 0.4679 - accuracy: 0.9470 - val_loss: 0.5964 - val_accuracy: 0.9130 - lr: 0.0031 - 23s/epoch - 73ms/step\n",
      "Epoch 108/2500\n",
      "Epoch 108/2500 - Train Accuracy: 0.9775 - Val Accuracy: 0.9137 - Test Accuracy: 0.9080\n",
      "312/312 - 23s - loss: 0.4692 - accuracy: 0.9446 - val_loss: 0.6024 - val_accuracy: 0.9137 - lr: 0.0031 - 23s/epoch - 72ms/step\n",
      "Epoch 109/2500\n",
      "Epoch 109/2500 - Train Accuracy: 0.9827 - Val Accuracy: 0.9187 - Test Accuracy: 0.9103\n",
      "312/312 - 23s - loss: 0.4643 - accuracy: 0.9450 - val_loss: 0.5771 - val_accuracy: 0.9187 - lr: 0.0031 - 23s/epoch - 72ms/step\n",
      "Epoch 110/2500\n",
      "Epoch 110/2500 - Train Accuracy: 0.9772 - Val Accuracy: 0.9116 - Test Accuracy: 0.9024\n",
      "312/312 - 23s - loss: 0.4585 - accuracy: 0.9460 - val_loss: 0.6037 - val_accuracy: 0.9116 - lr: 0.0031 - 23s/epoch - 73ms/step\n",
      "Epoch 111/2500\n",
      "Epoch 111/2500 - Train Accuracy: 0.9818 - Val Accuracy: 0.9173 - Test Accuracy: 0.9126\n",
      "312/312 - 23s - loss: 0.4559 - accuracy: 0.9464 - val_loss: 0.5832 - val_accuracy: 0.9173 - lr: 0.0031 - 23s/epoch - 73ms/step\n",
      "Epoch 112/2500\n",
      "Epoch 112/2500 - Train Accuracy: 0.9800 - Val Accuracy: 0.9137 - Test Accuracy: 0.9048\n",
      "312/312 - 23s - loss: 0.4516 - accuracy: 0.9483 - val_loss: 0.5868 - val_accuracy: 0.9137 - lr: 0.0031 - 23s/epoch - 72ms/step\n",
      "Epoch 113/2500\n",
      "Epoch 113/2500 - Train Accuracy: 0.9795 - Val Accuracy: 0.9118 - Test Accuracy: 0.9059\n",
      "312/312 - 23s - loss: 0.4498 - accuracy: 0.9474 - val_loss: 0.5958 - val_accuracy: 0.9118 - lr: 0.0031 - 23s/epoch - 75ms/step\n",
      "Epoch 114/2500\n",
      "Epoch 114/2500 - Train Accuracy: 0.9807 - Val Accuracy: 0.9171 - Test Accuracy: 0.9094\n",
      "312/312 - 23s - loss: 0.4486 - accuracy: 0.9481 - val_loss: 0.5807 - val_accuracy: 0.9171 - lr: 0.0031 - 23s/epoch - 73ms/step\n",
      "Epoch 115/2500\n",
      "Epoch 115/2500 - Train Accuracy: 0.9805 - Val Accuracy: 0.9168 - Test Accuracy: 0.9093\n",
      "312/312 - 23s - loss: 0.4479 - accuracy: 0.9465 - val_loss: 0.5716 - val_accuracy: 0.9168 - lr: 0.0031 - 23s/epoch - 74ms/step\n",
      "Epoch 116/2500\n",
      "Epoch 116/2500 - Train Accuracy: 0.9846 - Val Accuracy: 0.9212 - Test Accuracy: 0.9145\n",
      "312/312 - 24s - loss: 0.4385 - accuracy: 0.9475 - val_loss: 0.5603 - val_accuracy: 0.9212 - lr: 0.0031 - 24s/epoch - 76ms/step\n",
      "Epoch 117/2500\n",
      "Epoch 117/2500 - Train Accuracy: 0.9783 - Val Accuracy: 0.9106 - Test Accuracy: 0.9051\n",
      "312/312 - 23s - loss: 0.4391 - accuracy: 0.9486 - val_loss: 0.5936 - val_accuracy: 0.9106 - lr: 0.0031 - 23s/epoch - 75ms/step\n",
      "Epoch 118/2500\n",
      "Epoch 118/2500 - Train Accuracy: 0.9863 - Val Accuracy: 0.9173 - Test Accuracy: 0.9163\n",
      "312/312 - 23s - loss: 0.4373 - accuracy: 0.9477 - val_loss: 0.5628 - val_accuracy: 0.9173 - lr: 0.0031 - 23s/epoch - 74ms/step\n",
      "Epoch 119/2500\n",
      "Epoch 119/2500 - Train Accuracy: 0.9800 - Val Accuracy: 0.9134 - Test Accuracy: 0.9093\n",
      "312/312 - 23s - loss: 0.4350 - accuracy: 0.9483 - val_loss: 0.5784 - val_accuracy: 0.9134 - lr: 0.0031 - 23s/epoch - 75ms/step\n",
      "Epoch 120/2500\n",
      "Epoch 120/2500 - Train Accuracy: 0.9815 - Val Accuracy: 0.9120 - Test Accuracy: 0.9072\n",
      "312/312 - 24s - loss: 0.4339 - accuracy: 0.9487 - val_loss: 0.5735 - val_accuracy: 0.9120 - lr: 0.0031 - 24s/epoch - 75ms/step\n",
      "Epoch 121/2500\n",
      "Epoch 121/2500 - Train Accuracy: 0.9892 - Val Accuracy: 0.9228 - Test Accuracy: 0.9150\n",
      "312/312 - 23s - loss: 0.4107 - accuracy: 0.9557 - val_loss: 0.5419 - val_accuracy: 0.9228 - lr: 0.0016 - 23s/epoch - 73ms/step\n",
      "Epoch 122/2500\n",
      "Epoch 122/2500 - Train Accuracy: 0.9874 - Val Accuracy: 0.9207 - Test Accuracy: 0.9138\n",
      "312/312 - 23s - loss: 0.4030 - accuracy: 0.9583 - val_loss: 0.5558 - val_accuracy: 0.9207 - lr: 0.0016 - 23s/epoch - 73ms/step\n",
      "Epoch 123/2500\n",
      "Epoch 123/2500 - Train Accuracy: 0.9897 - Val Accuracy: 0.9222 - Test Accuracy: 0.9149\n",
      "312/312 - 23s - loss: 0.3946 - accuracy: 0.9613 - val_loss: 0.5498 - val_accuracy: 0.9222 - lr: 0.0016 - 23s/epoch - 72ms/step\n",
      "Epoch 124/2500\n",
      "Epoch 124/2500 - Train Accuracy: 0.9902 - Val Accuracy: 0.9231 - Test Accuracy: 0.9174\n",
      "312/312 - 22s - loss: 0.3894 - accuracy: 0.9621 - val_loss: 0.5439 - val_accuracy: 0.9231 - lr: 0.0016 - 22s/epoch - 72ms/step\n",
      "Epoch 125/2500\n",
      "Epoch 125/2500 - Train Accuracy: 0.9885 - Val Accuracy: 0.9194 - Test Accuracy: 0.9127\n",
      "312/312 - 23s - loss: 0.3894 - accuracy: 0.9614 - val_loss: 0.5575 - val_accuracy: 0.9194 - lr: 0.0016 - 23s/epoch - 73ms/step\n",
      "Epoch 126/2500\n",
      "Epoch 126/2500 - Train Accuracy: 0.9909 - Val Accuracy: 0.9246 - Test Accuracy: 0.9175\n",
      "312/312 - 23s - loss: 0.3828 - accuracy: 0.9618 - val_loss: 0.5350 - val_accuracy: 0.9246 - lr: 0.0016 - 23s/epoch - 73ms/step\n",
      "Epoch 127/2500\n",
      "Epoch 127/2500 - Train Accuracy: 0.9858 - Val Accuracy: 0.9147 - Test Accuracy: 0.9096\n",
      "312/312 - 23s - loss: 0.3785 - accuracy: 0.9628 - val_loss: 0.5699 - val_accuracy: 0.9147 - lr: 0.0016 - 23s/epoch - 73ms/step\n",
      "Epoch 128/2500\n",
      "Epoch 128/2500 - Train Accuracy: 0.9916 - Val Accuracy: 0.9233 - Test Accuracy: 0.9171\n",
      "312/312 - 23s - loss: 0.3729 - accuracy: 0.9636 - val_loss: 0.5440 - val_accuracy: 0.9233 - lr: 0.0016 - 23s/epoch - 73ms/step\n",
      "Epoch 129/2500\n",
      "Epoch 129/2500 - Train Accuracy: 0.9912 - Val Accuracy: 0.9234 - Test Accuracy: 0.9175\n",
      "312/312 - 23s - loss: 0.3773 - accuracy: 0.9628 - val_loss: 0.5454 - val_accuracy: 0.9234 - lr: 0.0016 - 23s/epoch - 74ms/step\n",
      "Epoch 130/2500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 170\u001b[0m\n\u001b[0;32m    166\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m    167\u001b[0m                                     decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, momentum\u001b[38;5;241m=\u001b[39mmomentum, nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    168\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 170\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEpochEndCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2507\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2495\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2496\u001b[0m \n\u001b[0;32m   2497\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2498\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2499\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2500\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2501\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2502\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2503\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2504\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2505\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2506\u001b[0m )\n\u001b[1;32m-> 2507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2509\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2519\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2521\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def normalization(train_images, test_images):\n",
    "    mean = np.mean(train_images, axis=(0, 1, 2, 3))\n",
    "    std = np.std(train_images, axis=(0, 1, 2, 3))\n",
    "    train_images = (train_images - mean) / (std + 1e-7)\n",
    "    test_images = (test_images - mean) / (std + 1e-7)\n",
    "    return train_images, test_images\n",
    "\n",
    "\n",
    "def load_images():\n",
    "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "    train_images = train_images.astype(np.float32)\n",
    "    test_images = test_images.astype(np.float32)\n",
    "\n",
    "    (train_images, test_images) = normalization(train_images, test_images)\n",
    "\n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "    # Randomly select 20% of the training data as validation data\n",
    "    validation_split = 0.2\n",
    "    split_index = int(train_images.shape[0] * (1 - validation_split))\n",
    "    train_images, val_images = train_images[:split_index], train_images[split_index:]\n",
    "    train_labels, val_labels = train_labels[:split_index], train_labels[split_index:]\n",
    "\n",
    "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
    "\n",
    "class EpochEndCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_data, val_data, test_data):\n",
    "        super(EpochEndCallback, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_loss, train_accuracy = self.model.evaluate(self.train_data[0], self.train_data[1], verbose=0)\n",
    "        val_loss, val_accuracy = self.model.evaluate(self.val_data[0], self.val_data[1], verbose=0)\n",
    "        test_loss, test_accuracy = self.model.evaluate(self.test_data[0], self.test_data[1], verbose=0)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{training_epochs} - '\n",
    "              f'Train Accuracy: {train_accuracy:.4f} - '\n",
    "              f'Val Accuracy: {val_accuracy:.4f} - '\n",
    "              f'Test Accuracy: {test_accuracy:.4f}')\n",
    "class ConvBNRelu(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size=3, strides=1, padding='SAME', weight_decay=0.0005, rate=0.4, drop=True):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.drop = drop\n",
    "        self.conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                                        padding=padding, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dropOut = keras.layers.Dropout(rate=rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        layer = self.conv(inputs)\n",
    "        layer = tf.nn.relu(layer)\n",
    "        layer = self.batchnorm(layer)\n",
    "        if self.drop:\n",
    "            layer = self.dropOut(layer)\n",
    "\n",
    "        return layer\n",
    "\n",
    "class VGG16Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16Model, self).__init__()\n",
    "        self.conv1 = ConvBNRelu(filters=64, kernel_size=[3, 3], rate=0.3)\n",
    "        self.conv2 = ConvBNRelu(filters=64, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling1 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv3 = ConvBNRelu(filters=128, kernel_size=[3, 3])\n",
    "        self.conv4 = ConvBNRelu(filters=128, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling2 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv5 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv6 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv7 = ConvBNRelu(filters=256, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling3 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv11 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv12 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv13 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling5 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv14 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv15 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv16 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling6 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flat = keras.layers.Flatten()\n",
    "        self.dropOut = keras.layers.Dropout(rate=0.5)\n",
    "        self.dense1 = keras.layers.Dense(units=512,\n",
    "                                         activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "        self.dense3 = keras.layers.Dense(units=10)  # 변경된 부분: units=10\n",
    "        self.softmax = keras.layers.Activation('softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs, training=training)\n",
    "        net = self.conv2(net, training=training)\n",
    "        net = self.maxPooling1(net)\n",
    "        net = self.conv3(net, training=training)\n",
    "        net = self.conv4(net, training=training)\n",
    "        net = self.maxPooling2(net)\n",
    "        net = self.conv5(net, training=training)\n",
    "        net = self.conv6(net, training=training)\n",
    "        net = self.conv7(net, training=training)\n",
    "        net = self.maxPooling3(net)\n",
    "        net = self.conv11(net, training=training)\n",
    "        net = self.conv12(net, training=training)\n",
    "        net = self.conv13(net, training=training)\n",
    "        net = self.maxPooling5(net)\n",
    "        net = self.conv14(net, training=training)\n",
    "        net = self.conv15(net, training=training)\n",
    "        net = self.conv16(net, training=training)\n",
    "        net = self.maxPooling6(net)\n",
    "        net = self.dropOut(net)\n",
    "        net = self.flat(net)\n",
    "        net = self.dense1(net)\n",
    "        net = self.dense3(net)\n",
    "        net = self.softmax(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(tf.__version__)\n",
    "    print(keras.__version__)\n",
    "\n",
    "    training_epochs = 2500\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.9\n",
    "    lr_decay = 1e-6\n",
    "    lr_drop = 20\n",
    "\n",
    "    tf.random.set_seed(777)\n",
    "\n",
    "    def lr_scheduler(epoch):\n",
    "        return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "\n",
    "    reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    train_images, train_labels, val_images, val_labels, test_images, test_labels = load_images()\n",
    "\n",
    "    # data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model = VGG16Model()\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,\n",
    "                                        decay=1e-6, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.fit_generator(datagen.flow(train_images, train_labels,\n",
    "                                     batch_size=batch_size), \n",
    "                        epochs=training_epochs, \n",
    "                        verbose=2, \n",
    "                        callbacks=[reduce_lr, EpochEndCallback((train_images, train_labels), (val_images, val_labels), (test_images, test_labels))],\n",
    "                        steps_per_epoch=train_images.shape[0] // batch_size,\n",
    "                        validation_data=(val_images, val_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d4284-720a-4f3a-bcb7-b995035bf9b8",
   "metadata": {},
   "source": [
    "dense layer 2개without bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0513549e-b2a0-4230-814c-369ce365ef99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "2.10.0\n",
      "Epoch 1/2500 - Train Accuracy: 0.1879 - Val Accuracy: 0.1885 - Test Accuracy: 0.1936\n",
      "Epoch 2/2500 - Train Accuracy: 0.1664 - Val Accuracy: 0.1654 - Test Accuracy: 0.1706\n",
      "Epoch 3/2500 - Train Accuracy: 0.2132 - Val Accuracy: 0.2050 - Test Accuracy: 0.2132\n",
      "Epoch 4/2500 - Train Accuracy: 0.3612 - Val Accuracy: 0.3484 - Test Accuracy: 0.3558\n",
      "Epoch 5/2500 - Train Accuracy: 0.4691 - Val Accuracy: 0.4656 - Test Accuracy: 0.4625\n",
      "Epoch 6/2500 - Train Accuracy: 0.5115 - Val Accuracy: 0.5007 - Test Accuracy: 0.5073\n",
      "Epoch 7/2500 - Train Accuracy: 0.5777 - Val Accuracy: 0.5712 - Test Accuracy: 0.5719\n",
      "Epoch 8/2500 - Train Accuracy: 0.6317 - Val Accuracy: 0.6310 - Test Accuracy: 0.6239\n",
      "Epoch 9/2500 - Train Accuracy: 0.3721 - Val Accuracy: 0.3739 - Test Accuracy: 0.3786\n",
      "Epoch 10/2500 - Train Accuracy: 0.6155 - Val Accuracy: 0.6090 - Test Accuracy: 0.6005\n",
      "Epoch 11/2500 - Train Accuracy: 0.5906 - Val Accuracy: 0.5877 - Test Accuracy: 0.5774\n",
      "Epoch 12/2500 - Train Accuracy: 0.6201 - Val Accuracy: 0.6210 - Test Accuracy: 0.6123\n",
      "Epoch 13/2500 - Train Accuracy: 0.6377 - Val Accuracy: 0.6272 - Test Accuracy: 0.6314\n",
      "Epoch 14/2500 - Train Accuracy: 0.5895 - Val Accuracy: 0.5916 - Test Accuracy: 0.5833\n",
      "Epoch 15/2500 - Train Accuracy: 0.6180 - Val Accuracy: 0.6138 - Test Accuracy: 0.6104\n",
      "Epoch 16/2500 - Train Accuracy: 0.2070 - Val Accuracy: 0.2115 - Test Accuracy: 0.2101\n",
      "Epoch 17/2500 - Train Accuracy: 0.6252 - Val Accuracy: 0.6216 - Test Accuracy: 0.6157\n",
      "Epoch 18/2500 - Train Accuracy: 0.5039 - Val Accuracy: 0.4976 - Test Accuracy: 0.4959\n",
      "Epoch 19/2500 - Train Accuracy: 0.6893 - Val Accuracy: 0.6858 - Test Accuracy: 0.6805\n",
      "Epoch 20/2500 - Train Accuracy: 0.6902 - Val Accuracy: 0.6888 - Test Accuracy: 0.6827\n",
      "Epoch 21/2500 - Train Accuracy: 0.7365 - Val Accuracy: 0.7276 - Test Accuracy: 0.7219\n",
      "Epoch 22/2500 - Train Accuracy: 0.7283 - Val Accuracy: 0.7182 - Test Accuracy: 0.7156\n",
      "Epoch 23/2500 - Train Accuracy: 0.7574 - Val Accuracy: 0.7529 - Test Accuracy: 0.7405\n",
      "Epoch 24/2500 - Train Accuracy: 0.7545 - Val Accuracy: 0.7436 - Test Accuracy: 0.7405\n",
      "Epoch 25/2500 - Train Accuracy: 0.7727 - Val Accuracy: 0.7626 - Test Accuracy: 0.7496\n",
      "Epoch 26/2500 - Train Accuracy: 0.7737 - Val Accuracy: 0.7632 - Test Accuracy: 0.7553\n",
      "Epoch 27/2500 - Train Accuracy: 0.7843 - Val Accuracy: 0.7684 - Test Accuracy: 0.7690\n",
      "Epoch 28/2500 - Train Accuracy: 0.7439 - Val Accuracy: 0.7365 - Test Accuracy: 0.7368\n",
      "Epoch 29/2500 - Train Accuracy: 0.7406 - Val Accuracy: 0.7282 - Test Accuracy: 0.7228\n",
      "Epoch 30/2500 - Train Accuracy: 0.8013 - Val Accuracy: 0.7918 - Test Accuracy: 0.7838\n",
      "Epoch 31/2500 - Train Accuracy: 0.7985 - Val Accuracy: 0.7876 - Test Accuracy: 0.7803\n",
      "Epoch 32/2500 - Train Accuracy: 0.7775 - Val Accuracy: 0.7626 - Test Accuracy: 0.7611\n",
      "Epoch 33/2500 - Train Accuracy: 0.8134 - Val Accuracy: 0.8010 - Test Accuracy: 0.7928\n",
      "Epoch 34/2500 - Train Accuracy: 0.8223 - Val Accuracy: 0.8073 - Test Accuracy: 0.8035\n",
      "Epoch 35/2500 - Train Accuracy: 0.7923 - Val Accuracy: 0.7826 - Test Accuracy: 0.7695\n",
      "Epoch 36/2500 - Train Accuracy: 0.8322 - Val Accuracy: 0.8208 - Test Accuracy: 0.8109\n",
      "Epoch 37/2500 - Train Accuracy: 0.7650 - Val Accuracy: 0.7517 - Test Accuracy: 0.7499\n",
      "Epoch 38/2500 - Train Accuracy: 0.8255 - Val Accuracy: 0.8050 - Test Accuracy: 0.8002\n",
      "Epoch 39/2500 - Train Accuracy: 0.8254 - Val Accuracy: 0.8034 - Test Accuracy: 0.7999\n",
      "Epoch 40/2500 - Train Accuracy: 0.8075 - Val Accuracy: 0.7925 - Test Accuracy: 0.7850\n",
      "Epoch 41/2500 - Train Accuracy: 0.8359 - Val Accuracy: 0.8147 - Test Accuracy: 0.8080\n",
      "Epoch 42/2500 - Train Accuracy: 0.8781 - Val Accuracy: 0.8550 - Test Accuracy: 0.8505\n",
      "Epoch 43/2500 - Train Accuracy: 0.8577 - Val Accuracy: 0.8342 - Test Accuracy: 0.8292\n",
      "Epoch 44/2500 - Train Accuracy: 0.8438 - Val Accuracy: 0.8169 - Test Accuracy: 0.8141\n",
      "Epoch 45/2500 - Train Accuracy: 0.8839 - Val Accuracy: 0.8571 - Test Accuracy: 0.8528\n",
      "Epoch 46/2500 - Train Accuracy: 0.8714 - Val Accuracy: 0.8453 - Test Accuracy: 0.8442\n",
      "Epoch 47/2500 - Train Accuracy: 0.8892 - Val Accuracy: 0.8592 - Test Accuracy: 0.8552\n",
      "Epoch 48/2500 - Train Accuracy: 0.8630 - Val Accuracy: 0.8331 - Test Accuracy: 0.8355\n",
      "Epoch 49/2500 - Train Accuracy: 0.8661 - Val Accuracy: 0.8382 - Test Accuracy: 0.8366\n",
      "Epoch 50/2500 - Train Accuracy: 0.8769 - Val Accuracy: 0.8526 - Test Accuracy: 0.8453\n",
      "Epoch 51/2500 - Train Accuracy: 0.8674 - Val Accuracy: 0.8388 - Test Accuracy: 0.8346\n",
      "Epoch 52/2500 - Train Accuracy: 0.8655 - Val Accuracy: 0.8414 - Test Accuracy: 0.8322\n",
      "Epoch 53/2500 - Train Accuracy: 0.8902 - Val Accuracy: 0.8587 - Test Accuracy: 0.8546\n",
      "Epoch 54/2500 - Train Accuracy: 0.8470 - Val Accuracy: 0.8221 - Test Accuracy: 0.8154\n",
      "Epoch 55/2500 - Train Accuracy: 0.8785 - Val Accuracy: 0.8512 - Test Accuracy: 0.8408\n",
      "Epoch 56/2500 - Train Accuracy: 0.8842 - Val Accuracy: 0.8573 - Test Accuracy: 0.8490\n",
      "Epoch 57/2500 - Train Accuracy: 0.8891 - Val Accuracy: 0.8608 - Test Accuracy: 0.8543\n",
      "Epoch 58/2500 - Train Accuracy: 0.8841 - Val Accuracy: 0.8525 - Test Accuracy: 0.8457\n",
      "Epoch 59/2500 - Train Accuracy: 0.8740 - Val Accuracy: 0.8402 - Test Accuracy: 0.8379\n",
      "Epoch 60/2500 - Train Accuracy: 0.8868 - Val Accuracy: 0.8524 - Test Accuracy: 0.8483\n",
      "Epoch 61/2500 - Train Accuracy: 0.9057 - Val Accuracy: 0.8680 - Test Accuracy: 0.8628\n",
      "Epoch 62/2500 - Train Accuracy: 0.9257 - Val Accuracy: 0.8858 - Test Accuracy: 0.8838\n",
      "Epoch 63/2500 - Train Accuracy: 0.9231 - Val Accuracy: 0.8834 - Test Accuracy: 0.8799\n",
      "Epoch 64/2500 - Train Accuracy: 0.9294 - Val Accuracy: 0.8912 - Test Accuracy: 0.8832\n",
      "Epoch 65/2500 - Train Accuracy: 0.9286 - Val Accuracy: 0.8848 - Test Accuracy: 0.8814\n",
      "Epoch 66/2500 - Train Accuracy: 0.9204 - Val Accuracy: 0.8770 - Test Accuracy: 0.8743\n",
      "Epoch 67/2500 - Train Accuracy: 0.9156 - Val Accuracy: 0.8737 - Test Accuracy: 0.8680\n",
      "Epoch 68/2500 - Train Accuracy: 0.9191 - Val Accuracy: 0.8749 - Test Accuracy: 0.8705\n",
      "Epoch 69/2500 - Train Accuracy: 0.9263 - Val Accuracy: 0.8830 - Test Accuracy: 0.8748\n",
      "Epoch 70/2500 - Train Accuracy: 0.9074 - Val Accuracy: 0.8675 - Test Accuracy: 0.8618\n",
      "Epoch 71/2500 - Train Accuracy: 0.9277 - Val Accuracy: 0.8844 - Test Accuracy: 0.8819\n",
      "Epoch 72/2500 - Train Accuracy: 0.9163 - Val Accuracy: 0.8728 - Test Accuracy: 0.8693\n",
      "Epoch 73/2500 - Train Accuracy: 0.9102 - Val Accuracy: 0.8685 - Test Accuracy: 0.8628\n",
      "Epoch 74/2500 - Train Accuracy: 0.9322 - Val Accuracy: 0.8892 - Test Accuracy: 0.8810\n",
      "Epoch 75/2500 - Train Accuracy: 0.9324 - Val Accuracy: 0.8917 - Test Accuracy: 0.8816\n",
      "Epoch 76/2500 - Train Accuracy: 0.9198 - Val Accuracy: 0.8772 - Test Accuracy: 0.8717\n",
      "Epoch 77/2500 - Train Accuracy: 0.9286 - Val Accuracy: 0.8861 - Test Accuracy: 0.8832\n",
      "Epoch 78/2500 - Train Accuracy: 0.9280 - Val Accuracy: 0.8845 - Test Accuracy: 0.8743\n",
      "Epoch 79/2500 - Train Accuracy: 0.9344 - Val Accuracy: 0.8920 - Test Accuracy: 0.8815\n",
      "Epoch 80/2500 - Train Accuracy: 0.9188 - Val Accuracy: 0.8765 - Test Accuracy: 0.8679\n",
      "Epoch 81/2500 - Train Accuracy: 0.9560 - Val Accuracy: 0.9068 - Test Accuracy: 0.8974\n",
      "Epoch 82/2500 - Train Accuracy: 0.9523 - Val Accuracy: 0.8980 - Test Accuracy: 0.8938\n",
      "Epoch 83/2500 - Train Accuracy: 0.9555 - Val Accuracy: 0.9044 - Test Accuracy: 0.8987\n",
      "Epoch 84/2500 - Train Accuracy: 0.9542 - Val Accuracy: 0.9005 - Test Accuracy: 0.8948\n",
      "Epoch 85/2500 - Train Accuracy: 0.9563 - Val Accuracy: 0.9028 - Test Accuracy: 0.8952\n",
      "Epoch 86/2500 - Train Accuracy: 0.9592 - Val Accuracy: 0.9093 - Test Accuracy: 0.9012\n",
      "Epoch 87/2500 - Train Accuracy: 0.9619 - Val Accuracy: 0.9073 - Test Accuracy: 0.9005\n",
      "Epoch 88/2500 - Train Accuracy: 0.9528 - Val Accuracy: 0.8995 - Test Accuracy: 0.8954\n",
      "Epoch 89/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.9057 - Test Accuracy: 0.9013\n",
      "Epoch 90/2500 - Train Accuracy: 0.9622 - Val Accuracy: 0.9031 - Test Accuracy: 0.9030\n",
      "Epoch 91/2500 - Train Accuracy: 0.9582 - Val Accuracy: 0.9012 - Test Accuracy: 0.8977\n",
      "Epoch 92/2500 - Train Accuracy: 0.9625 - Val Accuracy: 0.9075 - Test Accuracy: 0.9037\n",
      "Epoch 93/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.9091 - Test Accuracy: 0.9004\n",
      "Epoch 94/2500 - Train Accuracy: 0.9566 - Val Accuracy: 0.9017 - Test Accuracy: 0.8961\n",
      "Epoch 95/2500 - Train Accuracy: 0.9613 - Val Accuracy: 0.9071 - Test Accuracy: 0.8973\n",
      "Epoch 96/2500 - Train Accuracy: 0.9681 - Val Accuracy: 0.9134 - Test Accuracy: 0.9044\n",
      "Epoch 97/2500 - Train Accuracy: 0.9516 - Val Accuracy: 0.8943 - Test Accuracy: 0.8901\n",
      "Epoch 98/2500 - Train Accuracy: 0.9613 - Val Accuracy: 0.9009 - Test Accuracy: 0.8951\n",
      "Epoch 99/2500 - Train Accuracy: 0.9570 - Val Accuracy: 0.8954 - Test Accuracy: 0.8905\n",
      "Epoch 100/2500 - Train Accuracy: 0.9575 - Val Accuracy: 0.8967 - Test Accuracy: 0.8944\n",
      "Epoch 101/2500 - Train Accuracy: 0.9760 - Val Accuracy: 0.9167 - Test Accuracy: 0.9124\n",
      "Epoch 102/2500 - Train Accuracy: 0.9682 - Val Accuracy: 0.9077 - Test Accuracy: 0.9031\n",
      "Epoch 103/2500 - Train Accuracy: 0.9733 - Val Accuracy: 0.9092 - Test Accuracy: 0.9088\n",
      "Epoch 104/2500 - Train Accuracy: 0.9770 - Val Accuracy: 0.9155 - Test Accuracy: 0.9093\n",
      "Epoch 105/2500 - Train Accuracy: 0.9813 - Val Accuracy: 0.9218 - Test Accuracy: 0.9160\n",
      "Epoch 106/2500 - Train Accuracy: 0.9779 - Val Accuracy: 0.9141 - Test Accuracy: 0.9075\n",
      "Epoch 107/2500 - Train Accuracy: 0.9780 - Val Accuracy: 0.9155 - Test Accuracy: 0.9098\n",
      "Epoch 108/2500 - Train Accuracy: 0.9777 - Val Accuracy: 0.9130 - Test Accuracy: 0.9062\n",
      "Epoch 109/2500 - Train Accuracy: 0.9797 - Val Accuracy: 0.9157 - Test Accuracy: 0.9098\n",
      "Epoch 110/2500 - Train Accuracy: 0.9811 - Val Accuracy: 0.9175 - Test Accuracy: 0.9146\n",
      "Epoch 111/2500 - Train Accuracy: 0.9817 - Val Accuracy: 0.9171 - Test Accuracy: 0.9104\n",
      "Epoch 112/2500 - Train Accuracy: 0.9840 - Val Accuracy: 0.9185 - Test Accuracy: 0.9151\n",
      "Epoch 113/2500 - Train Accuracy: 0.9796 - Val Accuracy: 0.9126 - Test Accuracy: 0.9116\n",
      "Epoch 114/2500 - Train Accuracy: 0.9824 - Val Accuracy: 0.9133 - Test Accuracy: 0.9099\n",
      "Epoch 115/2500 - Train Accuracy: 0.9830 - Val Accuracy: 0.9186 - Test Accuracy: 0.9114\n",
      "Epoch 116/2500 - Train Accuracy: 0.9781 - Val Accuracy: 0.9128 - Test Accuracy: 0.9066\n",
      "Epoch 117/2500 - Train Accuracy: 0.9793 - Val Accuracy: 0.9114 - Test Accuracy: 0.9037\n",
      "Epoch 118/2500 - Train Accuracy: 0.9833 - Val Accuracy: 0.9181 - Test Accuracy: 0.9111\n",
      "Epoch 119/2500 - Train Accuracy: 0.9816 - Val Accuracy: 0.9165 - Test Accuracy: 0.9098\n",
      "Epoch 120/2500 - Train Accuracy: 0.9810 - Val Accuracy: 0.9133 - Test Accuracy: 0.9037\n",
      "Epoch 121/2500 - Train Accuracy: 0.9887 - Val Accuracy: 0.9211 - Test Accuracy: 0.9185\n",
      "Epoch 122/2500 - Train Accuracy: 0.9903 - Val Accuracy: 0.9228 - Test Accuracy: 0.9187\n",
      "Epoch 123/2500 - Train Accuracy: 0.9882 - Val Accuracy: 0.9239 - Test Accuracy: 0.9171\n",
      "Epoch 124/2500 - Train Accuracy: 0.9912 - Val Accuracy: 0.9257 - Test Accuracy: 0.9185\n",
      "Epoch 125/2500 - Train Accuracy: 0.9911 - Val Accuracy: 0.9254 - Test Accuracy: 0.9187\n",
      "Epoch 126/2500 - Train Accuracy: 0.9918 - Val Accuracy: 0.9226 - Test Accuracy: 0.9196\n",
      "Epoch 127/2500 - Train Accuracy: 0.9891 - Val Accuracy: 0.9206 - Test Accuracy: 0.9132\n",
      "Epoch 128/2500 - Train Accuracy: 0.9877 - Val Accuracy: 0.9187 - Test Accuracy: 0.9125\n",
      "Epoch 129/2500 - Train Accuracy: 0.9903 - Val Accuracy: 0.9211 - Test Accuracy: 0.9141\n",
      "Epoch 130/2500 - Train Accuracy: 0.9912 - Val Accuracy: 0.9244 - Test Accuracy: 0.9155\n",
      "Epoch 131/2500 - Train Accuracy: 0.9916 - Val Accuracy: 0.9227 - Test Accuracy: 0.9155\n",
      "Epoch 132/2500 - Train Accuracy: 0.9926 - Val Accuracy: 0.9235 - Test Accuracy: 0.9178\n",
      "Epoch 133/2500 - Train Accuracy: 0.9906 - Val Accuracy: 0.9214 - Test Accuracy: 0.9148\n",
      "Epoch 134/2500 - Train Accuracy: 0.9923 - Val Accuracy: 0.9245 - Test Accuracy: 0.9169\n",
      "Epoch 135/2500 - Train Accuracy: 0.9906 - Val Accuracy: 0.9203 - Test Accuracy: 0.9106\n",
      "Epoch 136/2500 - Train Accuracy: 0.9932 - Val Accuracy: 0.9215 - Test Accuracy: 0.9158\n",
      "Epoch 137/2500 - Train Accuracy: 0.9894 - Val Accuracy: 0.9195 - Test Accuracy: 0.9124\n",
      "Epoch 138/2500 - Train Accuracy: 0.9920 - Val Accuracy: 0.9241 - Test Accuracy: 0.9159\n",
      "Epoch 139/2500 - Train Accuracy: 0.9931 - Val Accuracy: 0.9215 - Test Accuracy: 0.9159\n",
      "Epoch 140/2500 - Train Accuracy: 0.9897 - Val Accuracy: 0.9185 - Test Accuracy: 0.9130\n",
      "Epoch 141/2500 - Train Accuracy: 0.9939 - Val Accuracy: 0.9267 - Test Accuracy: 0.9186\n",
      "Epoch 142/2500 - Train Accuracy: 0.9954 - Val Accuracy: 0.9289 - Test Accuracy: 0.9224\n",
      "Epoch 143/2500 - Train Accuracy: 0.9924 - Val Accuracy: 0.9230 - Test Accuracy: 0.9174\n",
      "Epoch 144/2500 - Train Accuracy: 0.9950 - Val Accuracy: 0.9275 - Test Accuracy: 0.9206\n",
      "Epoch 145/2500 - Train Accuracy: 0.9954 - Val Accuracy: 0.9288 - Test Accuracy: 0.9180\n",
      "Epoch 146/2500 - Train Accuracy: 0.9955 - Val Accuracy: 0.9297 - Test Accuracy: 0.9214\n",
      "Epoch 147/2500 - Train Accuracy: 0.9955 - Val Accuracy: 0.9285 - Test Accuracy: 0.9205\n",
      "Epoch 148/2500 - Train Accuracy: 0.9958 - Val Accuracy: 0.9283 - Test Accuracy: 0.9200\n",
      "Epoch 149/2500 - Train Accuracy: 0.9951 - Val Accuracy: 0.9274 - Test Accuracy: 0.9198\n",
      "Epoch 150/2500 - Train Accuracy: 0.9954 - Val Accuracy: 0.9274 - Test Accuracy: 0.9189\n",
      "Epoch 151/2500 - Train Accuracy: 0.9961 - Val Accuracy: 0.9302 - Test Accuracy: 0.9209\n",
      "Epoch 152/2500 - Train Accuracy: 0.9962 - Val Accuracy: 0.9283 - Test Accuracy: 0.9231\n",
      "Epoch 153/2500 - Train Accuracy: 0.9962 - Val Accuracy: 0.9270 - Test Accuracy: 0.9217\n",
      "Epoch 154/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9269 - Test Accuracy: 0.9226\n",
      "Epoch 155/2500 - Train Accuracy: 0.9957 - Val Accuracy: 0.9269 - Test Accuracy: 0.9209\n",
      "Epoch 156/2500 - Train Accuracy: 0.9962 - Val Accuracy: 0.9269 - Test Accuracy: 0.9215\n",
      "Epoch 157/2500 - Train Accuracy: 0.9951 - Val Accuracy: 0.9242 - Test Accuracy: 0.9187\n",
      "Epoch 158/2500 - Train Accuracy: 0.9953 - Val Accuracy: 0.9266 - Test Accuracy: 0.9199\n",
      "Epoch 159/2500 - Train Accuracy: 0.9958 - Val Accuracy: 0.9270 - Test Accuracy: 0.9199\n",
      "Epoch 160/2500 - Train Accuracy: 0.9959 - Val Accuracy: 0.9261 - Test Accuracy: 0.9199\n",
      "Epoch 161/2500 - Train Accuracy: 0.9972 - Val Accuracy: 0.9293 - Test Accuracy: 0.9231\n",
      "Epoch 162/2500 - Train Accuracy: 0.9967 - Val Accuracy: 0.9284 - Test Accuracy: 0.9222\n",
      "Epoch 163/2500 - Train Accuracy: 0.9974 - Val Accuracy: 0.9307 - Test Accuracy: 0.9234\n",
      "Epoch 164/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9282 - Test Accuracy: 0.9227\n",
      "Epoch 165/2500 - Train Accuracy: 0.9964 - Val Accuracy: 0.9283 - Test Accuracy: 0.9197\n",
      "Epoch 166/2500 - Train Accuracy: 0.9971 - Val Accuracy: 0.9295 - Test Accuracy: 0.9246\n",
      "Epoch 167/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9297 - Test Accuracy: 0.9234\n",
      "Epoch 168/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9296 - Test Accuracy: 0.9230\n",
      "Epoch 169/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9292 - Test Accuracy: 0.9231\n",
      "Epoch 170/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9282 - Test Accuracy: 0.9226\n",
      "Epoch 171/2500 - Train Accuracy: 0.9974 - Val Accuracy: 0.9291 - Test Accuracy: 0.9236\n",
      "Epoch 172/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9282 - Test Accuracy: 0.9220\n",
      "Epoch 173/2500 - Train Accuracy: 0.9976 - Val Accuracy: 0.9271 - Test Accuracy: 0.9234\n",
      "Epoch 174/2500 - Train Accuracy: 0.9974 - Val Accuracy: 0.9289 - Test Accuracy: 0.9224\n",
      "Epoch 175/2500 - Train Accuracy: 0.9974 - Val Accuracy: 0.9301 - Test Accuracy: 0.9228\n",
      "Epoch 176/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9266 - Test Accuracy: 0.9228\n",
      "Epoch 177/2500 - Train Accuracy: 0.9976 - Val Accuracy: 0.9277 - Test Accuracy: 0.9243\n",
      "Epoch 178/2500 - Train Accuracy: 0.9963 - Val Accuracy: 0.9257 - Test Accuracy: 0.9216\n",
      "Epoch 179/2500 - Train Accuracy: 0.9977 - Val Accuracy: 0.9296 - Test Accuracy: 0.9221\n",
      "Epoch 180/2500 - Train Accuracy: 0.9976 - Val Accuracy: 0.9291 - Test Accuracy: 0.9215\n",
      "Epoch 181/2500 - Train Accuracy: 0.9974 - Val Accuracy: 0.9310 - Test Accuracy: 0.9230\n",
      "Epoch 182/2500 - Train Accuracy: 0.9980 - Val Accuracy: 0.9321 - Test Accuracy: 0.9235\n",
      "Epoch 183/2500 - Train Accuracy: 0.9977 - Val Accuracy: 0.9297 - Test Accuracy: 0.9231\n",
      "Epoch 184/2500 - Train Accuracy: 0.9980 - Val Accuracy: 0.9312 - Test Accuracy: 0.9227\n",
      "Epoch 185/2500 - Train Accuracy: 0.9977 - Val Accuracy: 0.9301 - Test Accuracy: 0.9226\n",
      "Epoch 186/2500 - Train Accuracy: 0.9981 - Val Accuracy: 0.9305 - Test Accuracy: 0.9224\n",
      "Epoch 187/2500 - Train Accuracy: 0.9979 - Val Accuracy: 0.9301 - Test Accuracy: 0.9227\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 172\u001b[0m\n\u001b[0;32m    168\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m    169\u001b[0m                                     decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, momentum\u001b[38;5;241m=\u001b[39mmomentum, nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    170\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 172\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 출력 숨기기\u001b[39;49;00m\n\u001b[0;32m    176\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEpochEndCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1624\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m     }\n\u001b[0;32m   1622\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[1;32m-> 1624\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1625\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:448\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    446\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m--> 448\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 48\u001b[0m, in \u001b[0;36mEpochEndCallback.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 48\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data[\u001b[38;5;241m1\u001b[39m], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     50\u001b[0m     test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data[\u001b[38;5;241m1\u001b[39m], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def normalization(train_images, test_images):\n",
    "    mean = np.mean(train_images, axis=(0, 1, 2, 3))\n",
    "    std = np.std(train_images, axis=(0, 1, 2, 3))\n",
    "    train_images = (train_images - mean) / (std + 1e-7)\n",
    "    test_images = (test_images - mean) / (std + 1e-7)\n",
    "    return train_images, test_images\n",
    "\n",
    "\n",
    "def load_images():\n",
    "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "    train_images = train_images.astype(np.float32)\n",
    "    test_images = test_images.astype(np.float32)\n",
    "\n",
    "    (train_images, test_images) = normalization(train_images, test_images)\n",
    "\n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "    # Randomly select 20% of the training data as validation data\n",
    "    validation_split = 0.2\n",
    "    split_index = int(train_images.shape[0] * (1 - validation_split))\n",
    "    train_images, val_images = train_images[:split_index], train_images[split_index:]\n",
    "    train_labels, val_labels = train_labels[:split_index], train_labels[split_index:]\n",
    "\n",
    "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
    "\n",
    "class EpochEndCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_data, val_data, test_data):\n",
    "        super(EpochEndCallback, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_loss, train_accuracy = self.model.evaluate(self.train_data[0], self.train_data[1], verbose=0)\n",
    "        val_loss, val_accuracy = self.model.evaluate(self.val_data[0], self.val_data[1], verbose=0)\n",
    "        test_loss, test_accuracy = self.model.evaluate(self.test_data[0], self.test_data[1], verbose=0)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{training_epochs} - '\n",
    "              f'Train Accuracy: {train_accuracy:.4f} - '\n",
    "              f'Val Accuracy: {val_accuracy:.4f} - '\n",
    "              f'Test Accuracy: {test_accuracy:.4f}')\n",
    "class ConvBNRelu(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size=3, strides=1, padding='SAME', weight_decay=0.0005, rate=0.4, drop=True):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.drop = drop\n",
    "        self.conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                                        padding=padding, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dropOut = keras.layers.Dropout(rate=rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        layer = self.conv(inputs)\n",
    "        layer = tf.nn.relu(layer)\n",
    "        layer = self.batchnorm(layer)\n",
    "        if self.drop:\n",
    "            layer = self.dropOut(layer)\n",
    "\n",
    "        return layer\n",
    "\n",
    "class VGG16Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16Model, self).__init__()\n",
    "        self.conv1 = ConvBNRelu(filters=64, kernel_size=[3, 3], rate=0.3)\n",
    "        self.conv2 = ConvBNRelu(filters=64, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling1 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv3 = ConvBNRelu(filters=128, kernel_size=[3, 3])\n",
    "        self.conv4 = ConvBNRelu(filters=128, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling2 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv5 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv6 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv7 = ConvBNRelu(filters=256, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling3 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv11 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv12 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv13 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling5 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv14 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv15 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv16 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling6 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flat = keras.layers.Flatten()\n",
    "        self.dropOut = keras.layers.Dropout(rate=0.5)\n",
    "        self.dense1 = keras.layers.Dense(units=512,\n",
    "                                         activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "        self.dense2 = keras.layers.Dense(units=512,\n",
    "                                         activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "        self.dense3 = keras.layers.Dense(units=10)\n",
    "        self.softmax = keras.layers.Activation('softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs, training=training)\n",
    "        net = self.conv2(net, training=training)\n",
    "        net = self.maxPooling1(net)\n",
    "        net = self.conv3(net, training=training)\n",
    "        net = self.conv4(net, training=training)\n",
    "        net = self.maxPooling2(net)\n",
    "        net = self.conv5(net, training=training)\n",
    "        net = self.conv6(net, training=training)\n",
    "        net = self.conv7(net, training=training)\n",
    "        net = self.maxPooling3(net)\n",
    "        net = self.conv11(net, training=training)\n",
    "        net = self.conv12(net, training=training)\n",
    "        net = self.conv13(net, training=training)\n",
    "        net = self.maxPooling5(net)\n",
    "        net = self.conv14(net, training=training)\n",
    "        net = self.conv15(net, training=training)\n",
    "        net = self.conv16(net, training=training)\n",
    "        net = self.maxPooling6(net)\n",
    "        net = self.dropOut(net)\n",
    "        net = self.flat(net)\n",
    "        net = self.dense1(net)\n",
    "        net = self.dense3(net)\n",
    "        net = self.softmax(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(tf.__version__)\n",
    "    print(keras.__version__)\n",
    "\n",
    "    training_epochs = 2500\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.9\n",
    "    lr_decay = 1e-6\n",
    "    lr_drop = 20\n",
    "\n",
    "    tf.random.set_seed(777)\n",
    "\n",
    "    def lr_scheduler(epoch):\n",
    "        return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "\n",
    "    reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    train_images, train_labels, val_images, val_labels, test_images, test_labels = load_images()\n",
    "\n",
    "    # data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model = VGG16Model()\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,\n",
    "                                        decay=1e-6, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.fit(datagen.flow(train_images, train_labels,\n",
    "                        batch_size=batch_size), \n",
    "          epochs=training_epochs, \n",
    "          verbose=0,  # 출력 숨기기\n",
    "          callbacks=[reduce_lr, EpochEndCallback((train_images, train_labels), (val_images, val_labels), (test_images, test_labels))],\n",
    "          steps_per_epoch=train_images.shape[0] // batch_size,\n",
    "          validation_data=(val_images, val_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5092b09-893a-4792-951d-e6655c350cda",
   "metadata": {},
   "source": [
    "##이거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0e4c3-28cb-4dd6-8153-8f26d9c568c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def normalization(train_images, test_images):\n",
    "    mean = np.mean(train_images, axis=(0, 1, 2, 3))\n",
    "    std = np.std(train_images, axis=(0, 1, 2, 3))\n",
    "    train_images = (train_images - mean) / (std + 1e-7)\n",
    "    test_images = (test_images - mean) / (std + 1e-7)\n",
    "    return train_images, test_images\n",
    "\n",
    "\n",
    "def load_images():\n",
    "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "    train_images = train_images.astype(np.float32)\n",
    "    test_images = test_images.astype(np.float32)\n",
    "\n",
    "    (train_images, test_images) = normalization(train_images, test_images)\n",
    "\n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "    # Randomly select 20% of the training data as validation data\n",
    "    validation_split = 0.2\n",
    "    split_index = int(train_images.shape[0] * (1 - validation_split))\n",
    "    train_images, val_images = train_images[:split_index], train_images[split_index:]\n",
    "    train_labels, val_labels = train_labels[:split_index], train_labels[split_index:]\n",
    "\n",
    "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
    "\n",
    "class EpochEndCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_data, val_data, test_data):\n",
    "        super(EpochEndCallback, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_loss, train_accuracy = self.model.evaluate(self.train_data[0], self.train_data[1], verbose=0)\n",
    "        val_loss, val_accuracy = self.model.evaluate(self.val_data[0], self.val_data[1], verbose=0)\n",
    "        test_loss, test_accuracy = self.model.evaluate(self.test_data[0], self.test_data[1], verbose=0)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{training_epochs} - '\n",
    "              f'Train Accuracy: {train_accuracy:.4f} - '\n",
    "              f'Val Accuracy: {val_accuracy:.4f} - '\n",
    "              f'Test Accuracy: {test_accuracy:.4f}')\n",
    "class ConvBNRelu(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size=3, strides=1, padding='SAME', weight_decay=0.0005, rate=0.4, drop=True):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.drop = drop\n",
    "        self.conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                                        padding=padding, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dropOut = keras.layers.Dropout(rate=rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        layer = self.conv(inputs)\n",
    "        layer = tf.nn.relu(layer)\n",
    "        layer = self.batchnorm(layer)\n",
    "        if self.drop:\n",
    "            layer = self.dropOut(layer)\n",
    "\n",
    "        return layer\n",
    "\n",
    "class VGG16Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16Model, self).__init__()\n",
    "        self.conv1 = ConvBNRelu(filters=64, kernel_size=[3, 3], rate=0.3)\n",
    "        self.conv2 = ConvBNRelu(filters=64, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling1 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv3 = ConvBNRelu(filters=128, kernel_size=[3, 3])\n",
    "        self.conv4 = ConvBNRelu(filters=128, kernel_size=[3, 3], drop=False)\n",
    "        self.conv5 = ConvBNRelu(filters=128, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling2 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv6 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv7 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv8 = ConvBNRelu(filters=256, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling3 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv9 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv10 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv11 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling5 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv12 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv13 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv14 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling6 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flat = keras.layers.Flatten()\n",
    "        self.dropOut = keras.layers.Dropout(rate=0.5)\n",
    "        self.dense1 = keras.layers.Dense(units=512,\n",
    "                                         activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dense3 = keras.layers.Dense(units=10)\n",
    "        self.softmax = keras.layers.Activation('softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs, training=training)\n",
    "        net = self.conv2(net, training=training)\n",
    "        net = self.maxPooling1(net)\n",
    "        net = self.conv3(net, training=training)\n",
    "        net = self.conv4(net, training=training)\n",
    "        net = self.maxPooling2(net)\n",
    "        net = self.conv5(net, training=training)\n",
    "        net = self.conv6(net, training=training)\n",
    "        net = self.conv7(net, training=training)\n",
    "        net = self.maxPooling3(net)\n",
    "        net = self.conv11(net, training=training)\n",
    "        net = self.conv12(net, training=training)\n",
    "        net = self.conv13(net, training=training)\n",
    "        net = self.maxPooling5(net)\n",
    "        net = self.conv14(net, training=training)\n",
    "        net = self.conv15(net, training=training)\n",
    "        net = self.conv16(net, training=training)\n",
    "        net = self.maxPooling6(net)\n",
    "        net = self.dropOut(net)\n",
    "        net = self.flat(net)\n",
    "        net = self.dense1(net)\n",
    "        net = self.batchnorm(net)\n",
    "        net = self.dense3(net)\n",
    "        net = self.softmax(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(tf.__version__)\n",
    "    print(keras.__version__)\n",
    "\n",
    "    training_epochs = 2500\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.9\n",
    "    lr_decay = 1e-6\n",
    "    lr_drop = 20\n",
    "\n",
    "    tf.random.set_seed(777)\n",
    "\n",
    "    def lr_scheduler(epoch):\n",
    "        return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "\n",
    "    reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    train_images, train_labels, val_images, val_labels, test_images, test_labels = load_images()\n",
    "\n",
    "    # data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model = VGG16Model()\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,\n",
    "                                        decay=1e-6, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.fit(datagen.flow(train_images, train_labels,\n",
    "                        batch_size=batch_size), \n",
    "          epochs=training_epochs, \n",
    "          verbose=0,  # 출력 숨기기\n",
    "          callbacks=[reduce_lr, EpochEndCallback((train_images, train_labels), (val_images, val_labels), (test_images, test_labels))],\n",
    "          steps_per_epoch=train_images.shape[0] // batch_size,\n",
    "          validation_data=(val_images, val_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e4c457-8216-4b6c-b1c2-73d79ca684c8",
   "metadata": {},
   "source": [
    "3. 출력 뉴런 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b205271-8669-4ad5-86c1-ca267b29a8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "2.10.0\n",
      "Epoch 1/2500\n",
      "Epoch 1/2500 - Train Accuracy: 0.4072 - Val Accuracy: 0.4122 - Test Accuracy: 0.4129\n",
      "312/312 - 124s - loss: 12.0520 - accuracy: 0.3500 - val_loss: 9.3524 - val_accuracy: 0.4122 - lr: 0.1000 - 124s/epoch - 396ms/step\n",
      "Epoch 2/2500\n",
      "Epoch 2/2500 - Train Accuracy: 0.4450 - Val Accuracy: 0.4491 - Test Accuracy: 0.4400\n",
      "312/312 - 122s - loss: 7.2676 - accuracy: 0.4595 - val_loss: 5.7114 - val_accuracy: 0.4491 - lr: 0.1000 - 122s/epoch - 391ms/step\n",
      "Epoch 3/2500\n",
      "Epoch 3/2500 - Train Accuracy: 0.4602 - Val Accuracy: 0.4539 - Test Accuracy: 0.4519\n",
      "312/312 - 122s - loss: 4.5406 - accuracy: 0.5130 - val_loss: 3.8828 - val_accuracy: 0.4539 - lr: 0.1000 - 122s/epoch - 391ms/step\n",
      "Epoch 4/2500\n",
      "Epoch 4/2500 - Train Accuracy: 0.5299 - Val Accuracy: 0.5264 - Test Accuracy: 0.5232\n",
      "312/312 - 122s - loss: 3.0693 - accuracy: 0.5545 - val_loss: 2.7438 - val_accuracy: 0.5264 - lr: 0.1000 - 122s/epoch - 392ms/step\n",
      "Epoch 5/2500\n",
      "Epoch 5/2500 - Train Accuracy: 0.5598 - Val Accuracy: 0.5514 - Test Accuracy: 0.5454\n",
      "312/312 - 122s - loss: 2.2674 - accuracy: 0.5971 - val_loss: 2.1981 - val_accuracy: 0.5514 - lr: 0.1000 - 122s/epoch - 393ms/step\n",
      "Epoch 6/2500\n",
      "Epoch 6/2500 - Train Accuracy: 0.6574 - Val Accuracy: 0.6381 - Test Accuracy: 0.6401\n",
      "312/312 - 123s - loss: 1.8367 - accuracy: 0.6250 - val_loss: 1.6852 - val_accuracy: 0.6381 - lr: 0.1000 - 123s/epoch - 395ms/step\n",
      "Epoch 7/2500\n",
      "Epoch 7/2500 - Train Accuracy: 0.6283 - Val Accuracy: 0.6192 - Test Accuracy: 0.6133\n",
      "312/312 - 124s - loss: 1.6116 - accuracy: 0.6477 - val_loss: 1.6863 - val_accuracy: 0.6192 - lr: 0.1000 - 124s/epoch - 396ms/step\n",
      "Epoch 8/2500\n",
      "Epoch 8/2500 - Train Accuracy: 0.6837 - Val Accuracy: 0.6754 - Test Accuracy: 0.6688\n",
      "312/312 - 123s - loss: 1.4967 - accuracy: 0.6599 - val_loss: 1.4549 - val_accuracy: 0.6754 - lr: 0.1000 - 123s/epoch - 396ms/step\n",
      "Epoch 9/2500\n",
      "Epoch 9/2500 - Train Accuracy: 0.6921 - Val Accuracy: 0.6740 - Test Accuracy: 0.6722\n",
      "312/312 - 124s - loss: 1.4183 - accuracy: 0.6771 - val_loss: 1.4402 - val_accuracy: 0.6740 - lr: 0.1000 - 124s/epoch - 397ms/step\n",
      "Epoch 10/2500\n",
      "Epoch 10/2500 - Train Accuracy: 0.7187 - Val Accuracy: 0.7080 - Test Accuracy: 0.7022\n",
      "312/312 - 123s - loss: 1.3895 - accuracy: 0.6884 - val_loss: 1.3490 - val_accuracy: 0.7080 - lr: 0.1000 - 123s/epoch - 395ms/step\n",
      "Epoch 11/2500\n",
      "Epoch 11/2500 - Train Accuracy: 0.7446 - Val Accuracy: 0.7346 - Test Accuracy: 0.7227\n",
      "312/312 - 124s - loss: 1.3681 - accuracy: 0.6949 - val_loss: 1.2891 - val_accuracy: 0.7346 - lr: 0.1000 - 124s/epoch - 396ms/step\n",
      "Epoch 12/2500\n",
      "Epoch 12/2500 - Train Accuracy: 0.7385 - Val Accuracy: 0.7305 - Test Accuracy: 0.7202\n",
      "312/312 - 123s - loss: 1.3550 - accuracy: 0.7096 - val_loss: 1.3285 - val_accuracy: 0.7305 - lr: 0.1000 - 123s/epoch - 396ms/step\n",
      "Epoch 13/2500\n",
      "Epoch 13/2500 - Train Accuracy: 0.7561 - Val Accuracy: 0.7414 - Test Accuracy: 0.7389\n",
      "312/312 - 123s - loss: 1.3496 - accuracy: 0.7169 - val_loss: 1.3063 - val_accuracy: 0.7414 - lr: 0.1000 - 123s/epoch - 394ms/step\n",
      "Epoch 14/2500\n",
      "Epoch 14/2500 - Train Accuracy: 0.7380 - Val Accuracy: 0.7202 - Test Accuracy: 0.7186\n",
      "312/312 - 123s - loss: 1.3515 - accuracy: 0.7231 - val_loss: 1.4050 - val_accuracy: 0.7202 - lr: 0.1000 - 123s/epoch - 396ms/step\n",
      "Epoch 15/2500\n",
      "Epoch 15/2500 - Train Accuracy: 0.7478 - Val Accuracy: 0.7346 - Test Accuracy: 0.7223\n",
      "312/312 - 123s - loss: 1.3542 - accuracy: 0.7335 - val_loss: 1.3852 - val_accuracy: 0.7346 - lr: 0.1000 - 123s/epoch - 395ms/step\n",
      "Epoch 16/2500\n",
      "Epoch 16/2500 - Train Accuracy: 0.7570 - Val Accuracy: 0.7443 - Test Accuracy: 0.7389\n",
      "312/312 - 123s - loss: 1.3590 - accuracy: 0.7354 - val_loss: 1.3565 - val_accuracy: 0.7443 - lr: 0.1000 - 123s/epoch - 395ms/step\n",
      "Epoch 17/2500\n",
      "Epoch 17/2500 - Train Accuracy: 0.7462 - Val Accuracy: 0.7300 - Test Accuracy: 0.7170\n",
      "312/312 - 124s - loss: 1.3531 - accuracy: 0.7416 - val_loss: 1.4441 - val_accuracy: 0.7300 - lr: 0.1000 - 124s/epoch - 397ms/step\n",
      "Epoch 18/2500\n",
      "Epoch 18/2500 - Train Accuracy: 0.7729 - Val Accuracy: 0.7546 - Test Accuracy: 0.7507\n",
      "312/312 - 123s - loss: 1.3647 - accuracy: 0.7478 - val_loss: 1.3754 - val_accuracy: 0.7546 - lr: 0.1000 - 123s/epoch - 394ms/step\n",
      "Epoch 19/2500\n",
      "Epoch 19/2500 - Train Accuracy: 0.7343 - Val Accuracy: 0.7204 - Test Accuracy: 0.7133\n",
      "312/312 - 124s - loss: 1.3837 - accuracy: 0.7484 - val_loss: 1.5383 - val_accuracy: 0.7204 - lr: 0.1000 - 124s/epoch - 396ms/step\n",
      "Epoch 20/2500\n",
      "Epoch 20/2500 - Train Accuracy: 0.7705 - Val Accuracy: 0.7584 - Test Accuracy: 0.7451\n",
      "312/312 - 124s - loss: 1.3787 - accuracy: 0.7542 - val_loss: 1.3878 - val_accuracy: 0.7584 - lr: 0.1000 - 124s/epoch - 396ms/step\n",
      "Epoch 21/2500\n",
      "Epoch 21/2500 - Train Accuracy: 0.8099 - Val Accuracy: 0.7921 - Test Accuracy: 0.7799\n",
      "312/312 - 123s - loss: 1.2262 - accuracy: 0.7947 - val_loss: 1.2148 - val_accuracy: 0.7921 - lr: 0.0500 - 123s/epoch - 395ms/step\n",
      "Epoch 22/2500\n",
      "Epoch 22/2500 - Train Accuracy: 0.8448 - Val Accuracy: 0.8189 - Test Accuracy: 0.8048\n",
      "312/312 - 123s - loss: 1.1452 - accuracy: 0.8019 - val_loss: 1.1060 - val_accuracy: 0.8189 - lr: 0.0500 - 123s/epoch - 395ms/step\n",
      "Epoch 23/2500\n",
      "Epoch 23/2500 - Train Accuracy: 0.8457 - Val Accuracy: 0.8171 - Test Accuracy: 0.8076\n",
      "312/312 - 123s - loss: 1.1210 - accuracy: 0.8042 - val_loss: 1.0950 - val_accuracy: 0.8171 - lr: 0.0500 - 123s/epoch - 395ms/step\n",
      "Epoch 24/2500\n",
      "Epoch 24/2500 - Train Accuracy: 0.8566 - Val Accuracy: 0.8242 - Test Accuracy: 0.8211\n",
      "312/312 - 125s - loss: 1.1128 - accuracy: 0.8053 - val_loss: 1.0770 - val_accuracy: 0.8242 - lr: 0.0500 - 125s/epoch - 400ms/step\n",
      "Epoch 25/2500\n",
      "Epoch 25/2500 - Train Accuracy: 0.8469 - Val Accuracy: 0.8137 - Test Accuracy: 0.8115\n",
      "312/312 - 125s - loss: 1.1068 - accuracy: 0.8091 - val_loss: 1.1105 - val_accuracy: 0.8137 - lr: 0.0500 - 125s/epoch - 401ms/step\n",
      "Epoch 26/2500\n",
      "Epoch 26/2500 - Train Accuracy: 0.8242 - Val Accuracy: 0.7971 - Test Accuracy: 0.7925\n",
      "312/312 - 123s - loss: 1.1219 - accuracy: 0.8069 - val_loss: 1.1835 - val_accuracy: 0.7971 - lr: 0.0500 - 123s/epoch - 395ms/step\n",
      "Epoch 27/2500\n",
      "Epoch 27/2500 - Train Accuracy: 0.8539 - Val Accuracy: 0.8213 - Test Accuracy: 0.8160\n",
      "312/312 - 122s - loss: 1.1252 - accuracy: 0.8097 - val_loss: 1.1168 - val_accuracy: 0.8213 - lr: 0.0500 - 122s/epoch - 391ms/step\n",
      "Epoch 28/2500\n",
      "Epoch 28/2500 - Train Accuracy: 0.8001 - Val Accuracy: 0.7733 - Test Accuracy: 0.7648\n",
      "312/312 - 122s - loss: 1.1314 - accuracy: 0.8113 - val_loss: 1.3196 - val_accuracy: 0.7733 - lr: 0.0500 - 122s/epoch - 391ms/step\n",
      "Epoch 29/2500\n",
      "Epoch 29/2500 - Train Accuracy: 0.8352 - Val Accuracy: 0.8064 - Test Accuracy: 0.8011\n",
      "312/312 - 122s - loss: 1.1420 - accuracy: 0.8108 - val_loss: 1.2101 - val_accuracy: 0.8064 - lr: 0.0500 - 122s/epoch - 392ms/step\n",
      "Epoch 30/2500\n",
      "Epoch 30/2500 - Train Accuracy: 0.8354 - Val Accuracy: 0.8034 - Test Accuracy: 0.8007\n",
      "312/312 - 122s - loss: 1.1519 - accuracy: 0.8144 - val_loss: 1.2096 - val_accuracy: 0.8034 - lr: 0.0500 - 122s/epoch - 391ms/step\n",
      "Epoch 31/2500\n",
      "Epoch 31/2500 - Train Accuracy: 0.8382 - Val Accuracy: 0.8021 - Test Accuracy: 0.8005\n",
      "312/312 - 122s - loss: 1.1643 - accuracy: 0.8138 - val_loss: 1.2314 - val_accuracy: 0.8021 - lr: 0.0500 - 122s/epoch - 392ms/step\n",
      "Epoch 32/2500\n",
      "Epoch 32/2500 - Train Accuracy: 0.8476 - Val Accuracy: 0.8089 - Test Accuracy: 0.8093\n",
      "312/312 - 122s - loss: 1.1600 - accuracy: 0.8175 - val_loss: 1.2057 - val_accuracy: 0.8089 - lr: 0.0500 - 122s/epoch - 392ms/step\n",
      "Epoch 33/2500\n",
      "Epoch 33/2500 - Train Accuracy: 0.8500 - Val Accuracy: 0.8175 - Test Accuracy: 0.8141\n",
      "312/312 - 122s - loss: 1.1635 - accuracy: 0.8221 - val_loss: 1.2125 - val_accuracy: 0.8175 - lr: 0.0500 - 122s/epoch - 391ms/step\n",
      "Epoch 34/2500\n",
      "Epoch 34/2500 - Train Accuracy: 0.8368 - Val Accuracy: 0.8008 - Test Accuracy: 0.7982\n",
      "312/312 - 122s - loss: 1.1769 - accuracy: 0.8210 - val_loss: 1.2907 - val_accuracy: 0.8008 - lr: 0.0500 - 122s/epoch - 391ms/step\n",
      "Epoch 35/2500\n",
      "Epoch 35/2500 - Train Accuracy: 0.8515 - Val Accuracy: 0.8117 - Test Accuracy: 0.8127\n",
      "312/312 - 122s - loss: 1.1825 - accuracy: 0.8239 - val_loss: 1.2425 - val_accuracy: 0.8117 - lr: 0.0500 - 122s/epoch - 391ms/step\n",
      "Epoch 36/2500\n",
      "Epoch 36/2500 - Train Accuracy: 0.8507 - Val Accuracy: 0.8106 - Test Accuracy: 0.8131\n",
      "312/312 - 122s - loss: 1.1906 - accuracy: 0.8257 - val_loss: 1.2705 - val_accuracy: 0.8106 - lr: 0.0500 - 122s/epoch - 391ms/step\n",
      "Epoch 37/2500\n",
      "Epoch 37/2500 - Train Accuracy: 0.8470 - Val Accuracy: 0.8111 - Test Accuracy: 0.8081\n",
      "312/312 - 122s - loss: 1.2023 - accuracy: 0.8268 - val_loss: 1.2890 - val_accuracy: 0.8111 - lr: 0.0500 - 122s/epoch - 391ms/step\n",
      "Epoch 38/2500\n",
      "Epoch 38/2500 - Train Accuracy: 0.8737 - Val Accuracy: 0.8294 - Test Accuracy: 0.8230\n",
      "312/312 - 122s - loss: 1.2073 - accuracy: 0.8256 - val_loss: 1.2085 - val_accuracy: 0.8294 - lr: 0.0500 - 122s/epoch - 392ms/step\n",
      "Epoch 39/2500\n",
      "Epoch 39/2500 - Train Accuracy: 0.8686 - Val Accuracy: 0.8302 - Test Accuracy: 0.8265\n",
      "312/312 - 122s - loss: 1.2012 - accuracy: 0.8310 - val_loss: 1.2295 - val_accuracy: 0.8302 - lr: 0.0500 - 122s/epoch - 391ms/step\n",
      "Epoch 40/2500\n",
      "Epoch 40/2500 - Train Accuracy: 0.8403 - Val Accuracy: 0.8024 - Test Accuracy: 0.8029\n",
      "312/312 - 122s - loss: 1.2144 - accuracy: 0.8291 - val_loss: 1.3422 - val_accuracy: 0.8024 - lr: 0.0500 - 122s/epoch - 391ms/step\n",
      "Epoch 41/2500\n",
      "Epoch 41/2500 - Train Accuracy: 0.9140 - Val Accuracy: 0.8684 - Test Accuracy: 0.8610\n",
      "312/312 - 122s - loss: 1.0967 - accuracy: 0.8637 - val_loss: 1.0693 - val_accuracy: 0.8684 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 42/2500\n",
      "Epoch 42/2500 - Train Accuracy: 0.9185 - Val Accuracy: 0.8718 - Test Accuracy: 0.8662\n",
      "312/312 - 122s - loss: 1.0159 - accuracy: 0.8739 - val_loss: 1.0194 - val_accuracy: 0.8718 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 43/2500\n",
      "Epoch 43/2500 - Train Accuracy: 0.9171 - Val Accuracy: 0.8642 - Test Accuracy: 0.8614\n",
      "312/312 - 122s - loss: 0.9790 - accuracy: 0.8749 - val_loss: 1.0189 - val_accuracy: 0.8642 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 44/2500\n",
      "Epoch 44/2500 - Train Accuracy: 0.9005 - Val Accuracy: 0.8494 - Test Accuracy: 0.8419\n",
      "312/312 - 122s - loss: 0.9626 - accuracy: 0.8735 - val_loss: 1.0688 - val_accuracy: 0.8494 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 45/2500\n",
      "Epoch 45/2500 - Train Accuracy: 0.8855 - Val Accuracy: 0.8366 - Test Accuracy: 0.8291\n",
      "312/312 - 122s - loss: 0.9501 - accuracy: 0.8761 - val_loss: 1.0908 - val_accuracy: 0.8366 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 46/2500\n",
      "Epoch 46/2500 - Train Accuracy: 0.9199 - Val Accuracy: 0.8678 - Test Accuracy: 0.8538\n",
      "312/312 - 122s - loss: 0.9488 - accuracy: 0.8758 - val_loss: 1.0056 - val_accuracy: 0.8678 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 47/2500\n",
      "Epoch 47/2500 - Train Accuracy: 0.9064 - Val Accuracy: 0.8549 - Test Accuracy: 0.8444\n",
      "312/312 - 122s - loss: 0.9432 - accuracy: 0.8766 - val_loss: 1.0398 - val_accuracy: 0.8549 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 48/2500\n",
      "Epoch 48/2500 - Train Accuracy: 0.9291 - Val Accuracy: 0.8718 - Test Accuracy: 0.8627\n",
      "312/312 - 122s - loss: 0.9497 - accuracy: 0.8751 - val_loss: 0.9842 - val_accuracy: 0.8718 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 49/2500\n",
      "Epoch 49/2500 - Train Accuracy: 0.9211 - Val Accuracy: 0.8605 - Test Accuracy: 0.8578\n",
      "312/312 - 122s - loss: 0.9525 - accuracy: 0.8781 - val_loss: 1.0308 - val_accuracy: 0.8605 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 50/2500\n",
      "Epoch 50/2500 - Train Accuracy: 0.9178 - Val Accuracy: 0.8616 - Test Accuracy: 0.8559\n",
      "312/312 - 122s - loss: 0.9567 - accuracy: 0.8754 - val_loss: 1.0411 - val_accuracy: 0.8616 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 51/2500\n",
      "Epoch 51/2500 - Train Accuracy: 0.9228 - Val Accuracy: 0.8712 - Test Accuracy: 0.8590\n",
      "312/312 - 122s - loss: 0.9620 - accuracy: 0.8777 - val_loss: 1.0265 - val_accuracy: 0.8712 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 52/2500\n",
      "Epoch 52/2500 - Train Accuracy: 0.9080 - Val Accuracy: 0.8545 - Test Accuracy: 0.8504\n",
      "312/312 - 122s - loss: 0.9695 - accuracy: 0.8769 - val_loss: 1.0776 - val_accuracy: 0.8545 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 53/2500\n",
      "Epoch 53/2500 - Train Accuracy: 0.9234 - Val Accuracy: 0.8651 - Test Accuracy: 0.8625\n",
      "312/312 - 122s - loss: 0.9682 - accuracy: 0.8804 - val_loss: 1.0443 - val_accuracy: 0.8651 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 54/2500\n",
      "Epoch 54/2500 - Train Accuracy: 0.9247 - Val Accuracy: 0.8650 - Test Accuracy: 0.8575\n",
      "312/312 - 122s - loss: 0.9687 - accuracy: 0.8811 - val_loss: 1.0426 - val_accuracy: 0.8650 - lr: 0.0250 - 122s/epoch - 392ms/step\n",
      "Epoch 55/2500\n",
      "Epoch 55/2500 - Train Accuracy: 0.9150 - Val Accuracy: 0.8539 - Test Accuracy: 0.8479\n",
      "312/312 - 122s - loss: 0.9816 - accuracy: 0.8804 - val_loss: 1.1139 - val_accuracy: 0.8539 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 56/2500\n",
      "Epoch 56/2500 - Train Accuracy: 0.8964 - Val Accuracy: 0.8397 - Test Accuracy: 0.8366\n",
      "312/312 - 122s - loss: 0.9822 - accuracy: 0.8818 - val_loss: 1.1495 - val_accuracy: 0.8397 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 57/2500\n",
      "Epoch 57/2500 - Train Accuracy: 0.9085 - Val Accuracy: 0.8474 - Test Accuracy: 0.8482\n",
      "312/312 - 122s - loss: 0.9887 - accuracy: 0.8820 - val_loss: 1.1424 - val_accuracy: 0.8474 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 58/2500\n",
      "Epoch 58/2500 - Train Accuracy: 0.9147 - Val Accuracy: 0.8608 - Test Accuracy: 0.8499\n",
      "312/312 - 122s - loss: 0.9882 - accuracy: 0.8847 - val_loss: 1.0907 - val_accuracy: 0.8608 - lr: 0.0250 - 122s/epoch - 391ms/step\n",
      "Epoch 59/2500\n",
      "Epoch 59/2500 - Train Accuracy: 0.9065 - Val Accuracy: 0.8506 - Test Accuracy: 0.8436\n",
      "312/312 - 122s - loss: 0.9922 - accuracy: 0.8847 - val_loss: 1.1262 - val_accuracy: 0.8506 - lr: 0.0250 - 122s/epoch - 392ms/step\n",
      "Epoch 60/2500\n",
      "Epoch 60/2500 - Train Accuracy: 0.9235 - Val Accuracy: 0.8643 - Test Accuracy: 0.8590\n",
      "312/312 - 122s - loss: 0.9984 - accuracy: 0.8839 - val_loss: 1.0864 - val_accuracy: 0.8643 - lr: 0.0250 - 122s/epoch - 392ms/step\n",
      "Epoch 61/2500\n",
      "Epoch 61/2500 - Train Accuracy: 0.9515 - Val Accuracy: 0.8842 - Test Accuracy: 0.8843\n",
      "312/312 - 122s - loss: 0.9081 - accuracy: 0.9127 - val_loss: 1.0019 - val_accuracy: 0.8842 - lr: 0.0125 - 122s/epoch - 391ms/step\n",
      "Epoch 62/2500\n",
      "Epoch 62/2500 - Train Accuracy: 0.9634 - Val Accuracy: 0.8918 - Test Accuracy: 0.8890\n",
      "312/312 - 123s - loss: 0.8481 - accuracy: 0.9225 - val_loss: 0.9502 - val_accuracy: 0.8918 - lr: 0.0125 - 123s/epoch - 393ms/step\n",
      "Epoch 63/2500\n",
      "Epoch 63/2500 - Train Accuracy: 0.9620 - Val Accuracy: 0.8933 - Test Accuracy: 0.8917\n",
      "312/312 - 122s - loss: 0.8148 - accuracy: 0.9261 - val_loss: 0.9245 - val_accuracy: 0.8933 - lr: 0.0125 - 122s/epoch - 392ms/step\n",
      "Epoch 64/2500\n",
      "Epoch 64/2500 - Train Accuracy: 0.9686 - Val Accuracy: 0.8975 - Test Accuracy: 0.8950\n",
      "312/312 - 122s - loss: 0.7957 - accuracy: 0.9263 - val_loss: 0.8926 - val_accuracy: 0.8975 - lr: 0.0125 - 122s/epoch - 390ms/step\n",
      "Epoch 65/2500\n",
      "Epoch 65/2500 - Train Accuracy: 0.9675 - Val Accuracy: 0.8978 - Test Accuracy: 0.8918\n",
      "312/312 - 123s - loss: 0.7758 - accuracy: 0.9275 - val_loss: 0.8846 - val_accuracy: 0.8978 - lr: 0.0125 - 123s/epoch - 395ms/step\n",
      "Epoch 66/2500\n",
      "Epoch 66/2500 - Train Accuracy: 0.9670 - Val Accuracy: 0.8951 - Test Accuracy: 0.8897\n",
      "312/312 - 124s - loss: 0.7636 - accuracy: 0.9263 - val_loss: 0.8818 - val_accuracy: 0.8951 - lr: 0.0125 - 124s/epoch - 396ms/step\n",
      "Epoch 67/2500\n",
      "Epoch 67/2500 - Train Accuracy: 0.9621 - Val Accuracy: 0.8869 - Test Accuracy: 0.8834\n",
      "312/312 - 123s - loss: 0.7511 - accuracy: 0.9271 - val_loss: 0.9061 - val_accuracy: 0.8869 - lr: 0.0125 - 123s/epoch - 393ms/step\n",
      "Epoch 68/2500\n",
      "Epoch 68/2500 - Train Accuracy: 0.9584 - Val Accuracy: 0.8815 - Test Accuracy: 0.8820\n",
      "312/312 - 123s - loss: 0.7433 - accuracy: 0.9290 - val_loss: 0.9323 - val_accuracy: 0.8815 - lr: 0.0125 - 123s/epoch - 395ms/step\n",
      "Epoch 69/2500\n",
      "Epoch 69/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8818 - Test Accuracy: 0.8813\n",
      "312/312 - 123s - loss: 0.7507 - accuracy: 0.9245 - val_loss: 0.9145 - val_accuracy: 0.8818 - lr: 0.0125 - 123s/epoch - 394ms/step\n",
      "Epoch 70/2500\n",
      "Epoch 70/2500 - Train Accuracy: 0.9708 - Val Accuracy: 0.8943 - Test Accuracy: 0.8906\n",
      "312/312 - 123s - loss: 0.7435 - accuracy: 0.9268 - val_loss: 0.8731 - val_accuracy: 0.8943 - lr: 0.0125 - 123s/epoch - 393ms/step\n",
      "Epoch 71/2500\n",
      "Epoch 71/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8799 - Test Accuracy: 0.8770\n",
      "312/312 - 123s - loss: 0.7443 - accuracy: 0.9239 - val_loss: 0.9316 - val_accuracy: 0.8799 - lr: 0.0125 - 123s/epoch - 393ms/step\n",
      "Epoch 72/2500\n",
      "Epoch 72/2500 - Train Accuracy: 0.9629 - Val Accuracy: 0.8849 - Test Accuracy: 0.8765\n",
      "312/312 - 123s - loss: 0.7455 - accuracy: 0.9238 - val_loss: 0.9027 - val_accuracy: 0.8849 - lr: 0.0125 - 123s/epoch - 395ms/step\n",
      "Epoch 73/2500\n",
      "Epoch 73/2500 - Train Accuracy: 0.9479 - Val Accuracy: 0.8727 - Test Accuracy: 0.8706\n",
      "312/312 - 124s - loss: 0.7485 - accuracy: 0.9250 - val_loss: 0.9587 - val_accuracy: 0.8727 - lr: 0.0125 - 124s/epoch - 396ms/step\n",
      "Epoch 74/2500\n",
      "Epoch 74/2500 - Train Accuracy: 0.9692 - Val Accuracy: 0.8917 - Test Accuracy: 0.8864\n",
      "312/312 - 124s - loss: 0.7500 - accuracy: 0.9242 - val_loss: 0.8914 - val_accuracy: 0.8917 - lr: 0.0125 - 124s/epoch - 397ms/step\n",
      "Epoch 75/2500\n",
      "Epoch 75/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8809 - Test Accuracy: 0.8789\n",
      "312/312 - 124s - loss: 0.7441 - accuracy: 0.9260 - val_loss: 0.9337 - val_accuracy: 0.8809 - lr: 0.0125 - 124s/epoch - 399ms/step\n",
      "Epoch 76/2500\n",
      "Epoch 76/2500 - Train Accuracy: 0.9584 - Val Accuracy: 0.8803 - Test Accuracy: 0.8750\n",
      "312/312 - 124s - loss: 0.7430 - accuracy: 0.9264 - val_loss: 0.9364 - val_accuracy: 0.8803 - lr: 0.0125 - 124s/epoch - 397ms/step\n",
      "Epoch 77/2500\n",
      "Epoch 77/2500 - Train Accuracy: 0.9543 - Val Accuracy: 0.8803 - Test Accuracy: 0.8699\n",
      "312/312 - 125s - loss: 0.7493 - accuracy: 0.9242 - val_loss: 0.9483 - val_accuracy: 0.8803 - lr: 0.0125 - 125s/epoch - 401ms/step\n",
      "Epoch 78/2500\n",
      "Epoch 78/2500 - Train Accuracy: 0.9680 - Val Accuracy: 0.8896 - Test Accuracy: 0.8821\n",
      "312/312 - 123s - loss: 0.7514 - accuracy: 0.9255 - val_loss: 0.9139 - val_accuracy: 0.8896 - lr: 0.0125 - 123s/epoch - 395ms/step\n",
      "Epoch 79/2500\n",
      "Epoch 79/2500 - Train Accuracy: 0.9657 - Val Accuracy: 0.8914 - Test Accuracy: 0.8854\n",
      "312/312 - 123s - loss: 0.7529 - accuracy: 0.9270 - val_loss: 0.9167 - val_accuracy: 0.8914 - lr: 0.0125 - 123s/epoch - 393ms/step\n",
      "Epoch 80/2500\n",
      "Epoch 80/2500 - Train Accuracy: 0.9320 - Val Accuracy: 0.8558 - Test Accuracy: 0.8497\n",
      "312/312 - 123s - loss: 0.7531 - accuracy: 0.9290 - val_loss: 1.0416 - val_accuracy: 0.8558 - lr: 0.0125 - 123s/epoch - 393ms/step\n",
      "Epoch 81/2500\n",
      "Epoch 81/2500 - Train Accuracy: 0.9820 - Val Accuracy: 0.9049 - Test Accuracy: 0.8999\n",
      "312/312 - 122s - loss: 0.7048 - accuracy: 0.9441 - val_loss: 0.8575 - val_accuracy: 0.9049 - lr: 0.0063 - 122s/epoch - 392ms/step\n",
      "Epoch 82/2500\n",
      "Epoch 82/2500 - Train Accuracy: 0.9829 - Val Accuracy: 0.9051 - Test Accuracy: 0.8977\n",
      "312/312 - 122s - loss: 0.6616 - accuracy: 0.9547 - val_loss: 0.8415 - val_accuracy: 0.9051 - lr: 0.0063 - 122s/epoch - 392ms/step\n",
      "Epoch 83/2500\n",
      "Epoch 83/2500 - Train Accuracy: 0.9827 - Val Accuracy: 0.9044 - Test Accuracy: 0.9019\n",
      "312/312 - 123s - loss: 0.6422 - accuracy: 0.9579 - val_loss: 0.8348 - val_accuracy: 0.9044 - lr: 0.0063 - 123s/epoch - 394ms/step\n",
      "Epoch 84/2500\n",
      "Epoch 84/2500 - Train Accuracy: 0.9904 - Val Accuracy: 0.9080 - Test Accuracy: 0.9083\n",
      "312/312 - 123s - loss: 0.6247 - accuracy: 0.9593 - val_loss: 0.8054 - val_accuracy: 0.9080 - lr: 0.0063 - 123s/epoch - 394ms/step\n",
      "Epoch 85/2500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 162\u001b[0m\n\u001b[0;32m    158\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m    159\u001b[0m                                     decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, momentum\u001b[38;5;241m=\u001b[39mmomentum, nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 162\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEpochEndCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1624\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m     }\n\u001b[0;32m   1622\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[1;32m-> 1624\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1625\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:448\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    446\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m--> 448\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 48\u001b[0m, in \u001b[0;36mEpochEndCallback.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 48\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data[\u001b[38;5;241m1\u001b[39m], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     50\u001b[0m     test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data[\u001b[38;5;241m1\u001b[39m], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df0dfcba-4368-48d1-8aac-c2ccbe0e39c9",
   "metadata": {},
   "source": [
    "4.맥스풀링 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbf08689-bcc6-4194-b11f-bd95bd5a6b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "2.10.0\n",
      "Epoch 1/2500 - Train Accuracy: 0.3354 - Val Accuracy: 0.3359 - Test Accuracy: 0.3361\n",
      "Epoch 2/2500 - Train Accuracy: 0.2933 - Val Accuracy: 0.2985 - Test Accuracy: 0.2952\n",
      "Epoch 3/2500 - Train Accuracy: 0.4087 - Val Accuracy: 0.4081 - Test Accuracy: 0.4089\n",
      "Epoch 4/2500 - Train Accuracy: 0.2959 - Val Accuracy: 0.2961 - Test Accuracy: 0.2861\n",
      "Epoch 5/2500 - Train Accuracy: 0.5599 - Val Accuracy: 0.5509 - Test Accuracy: 0.5485\n",
      "Epoch 6/2500 - Train Accuracy: 0.6143 - Val Accuracy: 0.5982 - Test Accuracy: 0.6027\n",
      "Epoch 7/2500 - Train Accuracy: 0.6537 - Val Accuracy: 0.6437 - Test Accuracy: 0.6416\n",
      "Epoch 8/2500 - Train Accuracy: 0.6789 - Val Accuracy: 0.6676 - Test Accuracy: 0.6582\n",
      "Epoch 9/2500 - Train Accuracy: 0.6982 - Val Accuracy: 0.6851 - Test Accuracy: 0.6794\n",
      "Epoch 10/2500 - Train Accuracy: 0.7179 - Val Accuracy: 0.7013 - Test Accuracy: 0.7005\n",
      "Epoch 11/2500 - Train Accuracy: 0.7179 - Val Accuracy: 0.7083 - Test Accuracy: 0.7016\n",
      "Epoch 12/2500 - Train Accuracy: 0.7047 - Val Accuracy: 0.6878 - Test Accuracy: 0.6872\n",
      "Epoch 13/2500 - Train Accuracy: 0.7329 - Val Accuracy: 0.7160 - Test Accuracy: 0.7099\n",
      "Epoch 14/2500 - Train Accuracy: 0.7513 - Val Accuracy: 0.7296 - Test Accuracy: 0.7338\n",
      "Epoch 15/2500 - Train Accuracy: 0.6658 - Val Accuracy: 0.6516 - Test Accuracy: 0.6471\n",
      "Epoch 16/2500 - Train Accuracy: 0.7509 - Val Accuracy: 0.7325 - Test Accuracy: 0.7279\n",
      "Epoch 17/2500 - Train Accuracy: 0.7576 - Val Accuracy: 0.7366 - Test Accuracy: 0.7381\n",
      "Epoch 18/2500 - Train Accuracy: 0.7278 - Val Accuracy: 0.7092 - Test Accuracy: 0.7012\n",
      "Epoch 19/2500 - Train Accuracy: 0.7529 - Val Accuracy: 0.7278 - Test Accuracy: 0.7300\n",
      "Epoch 20/2500 - Train Accuracy: 0.7616 - Val Accuracy: 0.7436 - Test Accuracy: 0.7391\n",
      "Epoch 21/2500 - Train Accuracy: 0.8221 - Val Accuracy: 0.7967 - Test Accuracy: 0.7963\n",
      "Epoch 22/2500 - Train Accuracy: 0.8441 - Val Accuracy: 0.8112 - Test Accuracy: 0.8093\n",
      "Epoch 23/2500 - Train Accuracy: 0.8504 - Val Accuracy: 0.8131 - Test Accuracy: 0.8114\n",
      "Epoch 24/2500 - Train Accuracy: 0.8521 - Val Accuracy: 0.8184 - Test Accuracy: 0.8079\n",
      "Epoch 25/2500 - Train Accuracy: 0.8413 - Val Accuracy: 0.8069 - Test Accuracy: 0.8027\n",
      "Epoch 26/2500 - Train Accuracy: 0.8395 - Val Accuracy: 0.8046 - Test Accuracy: 0.8003\n",
      "Epoch 27/2500 - Train Accuracy: 0.6999 - Val Accuracy: 0.6804 - Test Accuracy: 0.6714\n",
      "Epoch 28/2500 - Train Accuracy: 0.8355 - Val Accuracy: 0.8018 - Test Accuracy: 0.8051\n",
      "Epoch 29/2500 - Train Accuracy: 0.8237 - Val Accuracy: 0.7927 - Test Accuracy: 0.7883\n",
      "Epoch 30/2500 - Train Accuracy: 0.8429 - Val Accuracy: 0.8071 - Test Accuracy: 0.8038\n",
      "Epoch 31/2500 - Train Accuracy: 0.8487 - Val Accuracy: 0.8166 - Test Accuracy: 0.8044\n",
      "Epoch 32/2500 - Train Accuracy: 0.8268 - Val Accuracy: 0.7950 - Test Accuracy: 0.7831\n",
      "Epoch 33/2500 - Train Accuracy: 0.8394 - Val Accuracy: 0.8045 - Test Accuracy: 0.8003\n",
      "Epoch 34/2500 - Train Accuracy: 0.8342 - Val Accuracy: 0.8017 - Test Accuracy: 0.7877\n",
      "Epoch 35/2500 - Train Accuracy: 0.7983 - Val Accuracy: 0.7626 - Test Accuracy: 0.7612\n",
      "Epoch 36/2500 - Train Accuracy: 0.8403 - Val Accuracy: 0.8040 - Test Accuracy: 0.7992\n",
      "Epoch 37/2500 - Train Accuracy: 0.8478 - Val Accuracy: 0.8132 - Test Accuracy: 0.8035\n",
      "Epoch 38/2500 - Train Accuracy: 0.8708 - Val Accuracy: 0.8322 - Test Accuracy: 0.8261\n",
      "Epoch 39/2500 - Train Accuracy: 0.8482 - Val Accuracy: 0.8123 - Test Accuracy: 0.8022\n",
      "Epoch 40/2500 - Train Accuracy: 0.8293 - Val Accuracy: 0.7976 - Test Accuracy: 0.7861\n",
      "Epoch 41/2500 - Train Accuracy: 0.9040 - Val Accuracy: 0.8565 - Test Accuracy: 0.8520\n",
      "Epoch 42/2500 - Train Accuracy: 0.9174 - Val Accuracy: 0.8661 - Test Accuracy: 0.8642\n",
      "Epoch 43/2500 - Train Accuracy: 0.9101 - Val Accuracy: 0.8606 - Test Accuracy: 0.8489\n",
      "Epoch 44/2500 - Train Accuracy: 0.9094 - Val Accuracy: 0.8573 - Test Accuracy: 0.8522\n",
      "Epoch 45/2500 - Train Accuracy: 0.9052 - Val Accuracy: 0.8484 - Test Accuracy: 0.8470\n",
      "Epoch 46/2500 - Train Accuracy: 0.9198 - Val Accuracy: 0.8655 - Test Accuracy: 0.8576\n",
      "Epoch 47/2500 - Train Accuracy: 0.9119 - Val Accuracy: 0.8574 - Test Accuracy: 0.8536\n",
      "Epoch 48/2500 - Train Accuracy: 0.8706 - Val Accuracy: 0.8183 - Test Accuracy: 0.8054\n",
      "Epoch 49/2500 - Train Accuracy: 0.9164 - Val Accuracy: 0.8638 - Test Accuracy: 0.8535\n",
      "Epoch 50/2500 - Train Accuracy: 0.9147 - Val Accuracy: 0.8544 - Test Accuracy: 0.8485\n",
      "Epoch 51/2500 - Train Accuracy: 0.9228 - Val Accuracy: 0.8618 - Test Accuracy: 0.8555\n",
      "Epoch 52/2500 - Train Accuracy: 0.9328 - Val Accuracy: 0.8717 - Test Accuracy: 0.8637\n",
      "Epoch 53/2500 - Train Accuracy: 0.9168 - Val Accuracy: 0.8599 - Test Accuracy: 0.8467\n",
      "Epoch 54/2500 - Train Accuracy: 0.8717 - Val Accuracy: 0.8198 - Test Accuracy: 0.8070\n",
      "Epoch 55/2500 - Train Accuracy: 0.9224 - Val Accuracy: 0.8652 - Test Accuracy: 0.8587\n",
      "Epoch 56/2500 - Train Accuracy: 0.9117 - Val Accuracy: 0.8537 - Test Accuracy: 0.8465\n",
      "Epoch 57/2500 - Train Accuracy: 0.9143 - Val Accuracy: 0.8559 - Test Accuracy: 0.8448\n",
      "Epoch 58/2500 - Train Accuracy: 0.9347 - Val Accuracy: 0.8746 - Test Accuracy: 0.8600\n",
      "Epoch 59/2500 - Train Accuracy: 0.9087 - Val Accuracy: 0.8499 - Test Accuracy: 0.8393\n",
      "Epoch 60/2500 - Train Accuracy: 0.9060 - Val Accuracy: 0.8457 - Test Accuracy: 0.8415\n",
      "Epoch 61/2500 - Train Accuracy: 0.9557 - Val Accuracy: 0.8879 - Test Accuracy: 0.8826\n",
      "Epoch 62/2500 - Train Accuracy: 0.9639 - Val Accuracy: 0.8960 - Test Accuracy: 0.8845\n",
      "Epoch 63/2500 - Train Accuracy: 0.9642 - Val Accuracy: 0.8883 - Test Accuracy: 0.8812\n",
      "Epoch 64/2500 - Train Accuracy: 0.9634 - Val Accuracy: 0.8861 - Test Accuracy: 0.8781\n",
      "Epoch 65/2500 - Train Accuracy: 0.9675 - Val Accuracy: 0.8934 - Test Accuracy: 0.8845\n",
      "Epoch 66/2500 - Train Accuracy: 0.9651 - Val Accuracy: 0.8866 - Test Accuracy: 0.8786\n",
      "Epoch 67/2500 - Train Accuracy: 0.9684 - Val Accuracy: 0.8938 - Test Accuracy: 0.8851\n",
      "Epoch 68/2500 - Train Accuracy: 0.9611 - Val Accuracy: 0.8796 - Test Accuracy: 0.8775\n",
      "Epoch 69/2500 - Train Accuracy: 0.9675 - Val Accuracy: 0.8877 - Test Accuracy: 0.8813\n",
      "Epoch 70/2500 - Train Accuracy: 0.9671 - Val Accuracy: 0.8847 - Test Accuracy: 0.8814\n",
      "Epoch 71/2500 - Train Accuracy: 0.9632 - Val Accuracy: 0.8858 - Test Accuracy: 0.8780\n",
      "Epoch 72/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8809 - Test Accuracy: 0.8753\n",
      "Epoch 73/2500 - Train Accuracy: 0.9585 - Val Accuracy: 0.8781 - Test Accuracy: 0.8746\n",
      "Epoch 74/2500 - Train Accuracy: 0.9639 - Val Accuracy: 0.8799 - Test Accuracy: 0.8702\n",
      "Epoch 75/2500 - Train Accuracy: 0.9539 - Val Accuracy: 0.8693 - Test Accuracy: 0.8650\n",
      "Epoch 76/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8821 - Test Accuracy: 0.8747\n",
      "Epoch 77/2500 - Train Accuracy: 0.9532 - Val Accuracy: 0.8691 - Test Accuracy: 0.8643\n",
      "Epoch 78/2500 - Train Accuracy: 0.9657 - Val Accuracy: 0.8829 - Test Accuracy: 0.8753\n",
      "Epoch 79/2500 - Train Accuracy: 0.9574 - Val Accuracy: 0.8742 - Test Accuracy: 0.8699\n",
      "Epoch 80/2500 - Train Accuracy: 0.9630 - Val Accuracy: 0.8817 - Test Accuracy: 0.8724\n",
      "Epoch 81/2500 - Train Accuracy: 0.9869 - Val Accuracy: 0.9076 - Test Accuracy: 0.9009\n",
      "Epoch 82/2500 - Train Accuracy: 0.9810 - Val Accuracy: 0.8997 - Test Accuracy: 0.8900\n",
      "Epoch 83/2500 - Train Accuracy: 0.9890 - Val Accuracy: 0.9087 - Test Accuracy: 0.9014\n",
      "Epoch 84/2500 - Train Accuracy: 0.9921 - Val Accuracy: 0.9108 - Test Accuracy: 0.9080\n",
      "Epoch 85/2500 - Train Accuracy: 0.9927 - Val Accuracy: 0.9093 - Test Accuracy: 0.9057\n",
      "Epoch 86/2500 - Train Accuracy: 0.9893 - Val Accuracy: 0.9079 - Test Accuracy: 0.9023\n",
      "Epoch 87/2500 - Train Accuracy: 0.9913 - Val Accuracy: 0.9094 - Test Accuracy: 0.8989\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 162\u001b[0m\n\u001b[0;32m    158\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m    159\u001b[0m                                     decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, momentum\u001b[38;5;241m=\u001b[39mmomentum, nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 162\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 출력 숨기기\u001b[39;49;00m\n\u001b[0;32m    166\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEpochEndCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1555\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   1552\u001b[0m     data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;241m=\u001b[39m data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1553\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_load_initial_step_from_ckpt()\n\u001b[0;32m   1554\u001b[0m     )\n\u001b[1;32m-> 1555\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1556\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m         ):\n\u001b[0;32m   1563\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1374\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1374\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1375\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1376\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1379\u001b[0m )\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def normalization(train_images, test_images):\n",
    "    mean = np.mean(train_images, axis=(0, 1, 2, 3))\n",
    "    std = np.std(train_images, axis=(0, 1, 2, 3))\n",
    "    train_images = (train_images - mean) / (std + 1e-7)\n",
    "    test_images = (test_images - mean) / (std + 1e-7)\n",
    "    return train_images, test_images\n",
    "\n",
    "\n",
    "def load_images():\n",
    "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "    train_images = train_images.astype(np.float32)\n",
    "    test_images = test_images.astype(np.float32)\n",
    "\n",
    "    (train_images, test_images) = normalization(train_images, test_images)\n",
    "\n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "    # Randomly select 20% of the training data as validation data\n",
    "    validation_split = 0.2\n",
    "    split_index = int(train_images.shape[0] * (1 - validation_split))\n",
    "    train_images, val_images = train_images[:split_index], train_images[split_index:]\n",
    "    train_labels, val_labels = train_labels[:split_index], train_labels[split_index:]\n",
    "\n",
    "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
    "\n",
    "class EpochEndCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_data, val_data, test_data):\n",
    "        super(EpochEndCallback, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_loss, train_accuracy = self.model.evaluate(self.train_data[0], self.train_data[1], verbose=0)\n",
    "        val_loss, val_accuracy = self.model.evaluate(self.val_data[0], self.val_data[1], verbose=0)\n",
    "        test_loss, test_accuracy = self.model.evaluate(self.test_data[0], self.test_data[1], verbose=0)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{training_epochs} - '\n",
    "              f'Train Accuracy: {train_accuracy:.4f} - '\n",
    "              f'Val Accuracy: {val_accuracy:.4f} - '\n",
    "              f'Test Accuracy: {test_accuracy:.4f}')\n",
    "class ConvBNRelu(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size=3, strides=1, padding='SAME', weight_decay=0.0005, rate=0.4, drop=True):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.drop = drop\n",
    "        self.conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                                        padding=padding, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dropOut = keras.layers.Dropout(rate=rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        layer = self.conv(inputs)\n",
    "        layer = tf.nn.relu(layer)\n",
    "        layer = self.batchnorm(layer)\n",
    "        if self.drop:\n",
    "            layer = self.dropOut(layer)\n",
    "\n",
    "        return layer\n",
    "\n",
    "class VGG16Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16Model, self).__init__()\n",
    "        self.conv1 = ConvBNRelu(filters=64, kernel_size=[3, 3], rate=0.3)\n",
    "        self.conv2 = ConvBNRelu(filters=64, kernel_size=[3, 3], drop=False)\n",
    "        self.conv3 = ConvBNRelu(filters=128, kernel_size=[3, 3])\n",
    "        self.conv4 = ConvBNRelu(filters=128, kernel_size=[3, 3], drop=False)\n",
    "        self.conv5 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv6 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv7 = ConvBNRelu(filters=256, kernel_size=[3, 3], drop=False)\n",
    "        self.conv11 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv12 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv13 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.conv14 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv15 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv16 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.flat = keras.layers.Flatten()\n",
    "        self.dropOut = keras.layers.Dropout(rate=0.5)\n",
    "        self.dense1 = keras.layers.Dense(units=512,\n",
    "                                         activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dense2 = keras.layers.Dense(units=10)\n",
    "        self.softmax = keras.layers.Activation('softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs, training=training)\n",
    "        net = self.conv2(net, training=training)\n",
    "        net = self.conv3(net, training=training)\n",
    "        net = self.conv4(net, training=training)\n",
    "        net = self.conv5(net, training=training)\n",
    "        net = self.conv6(net, training=training)\n",
    "        net = self.conv7(net, training=training)\n",
    "        net = self.conv11(net, training=training)\n",
    "        net = self.conv12(net, training=training)\n",
    "        net = self.conv13(net, training=training)\n",
    "        net = self.conv14(net, training=training)\n",
    "        net = self.conv15(net, training=training)\n",
    "        net = self.conv16(net, training=training)\n",
    "        net = self.flat(net)\n",
    "        net = self.dropOut(net)\n",
    "        net = self.dense1(net)\n",
    "        net = self.batchnorm(net)\n",
    "        net = self.dense2(net)\n",
    "        net = self.softmax(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(tf.__version__)\n",
    "    print(keras.__version__)\n",
    "\n",
    "    training_epochs = 2500\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.9\n",
    "    lr_decay = 1e-6\n",
    "    lr_drop = 20\n",
    " \n",
    "    tf.random.set_seed(777)\n",
    "\n",
    "    def lr_scheduler(epoch):\n",
    "        return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "\n",
    "    reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    train_images, train_labels, val_images, val_labels, test_images, test_labels = load_images()\n",
    "\n",
    "    # data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model = VGG16Model()\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,\n",
    "                                        decay=1e-6, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.fit(datagen.flow(train_images, train_labels,\n",
    "                        batch_size=batch_size), \n",
    "          epochs=training_epochs, \n",
    "          verbose=0,  # 출력 숨기기\n",
    "          callbacks=[reduce_lr, EpochEndCallback((train_images, train_labels), (val_images, val_labels), (test_images, test_labels))],\n",
    "          steps_per_epoch=train_images.shape[0] // batch_size,\n",
    "          validation_data=(val_images, val_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c5615-f796-4be0-9312-62fb0e7baaf4",
   "metadata": {},
   "source": [
    "5. 레이어 2개씩으로 맞춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f415a11-09b5-4d9c-bfda-badb72d2c607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "2.10.0\n",
      "Epoch 1/2500 - Train Accuracy: 0.1357 - Val Accuracy: 0.1305 - Test Accuracy: 0.1372\n",
      "Epoch 2/2500 - Train Accuracy: 0.2082 - Val Accuracy: 0.2012 - Test Accuracy: 0.2109\n",
      "Epoch 3/2500 - Train Accuracy: 0.2591 - Val Accuracy: 0.2576 - Test Accuracy: 0.2601\n",
      "Epoch 4/2500 - Train Accuracy: 0.5395 - Val Accuracy: 0.5292 - Test Accuracy: 0.5278\n",
      "Epoch 5/2500 - Train Accuracy: 0.4752 - Val Accuracy: 0.4709 - Test Accuracy: 0.4743\n",
      "Epoch 6/2500 - Train Accuracy: 0.6534 - Val Accuracy: 0.6476 - Test Accuracy: 0.6474\n",
      "Epoch 7/2500 - Train Accuracy: 0.6302 - Val Accuracy: 0.6244 - Test Accuracy: 0.6185\n",
      "Epoch 8/2500 - Train Accuracy: 0.6758 - Val Accuracy: 0.6705 - Test Accuracy: 0.6607\n",
      "Epoch 9/2500 - Train Accuracy: 0.6760 - Val Accuracy: 0.6728 - Test Accuracy: 0.6662\n",
      "Epoch 10/2500 - Train Accuracy: 0.7306 - Val Accuracy: 0.7173 - Test Accuracy: 0.7110\n",
      "Epoch 11/2500 - Train Accuracy: 0.7047 - Val Accuracy: 0.6958 - Test Accuracy: 0.6876\n",
      "Epoch 12/2500 - Train Accuracy: 0.7510 - Val Accuracy: 0.7407 - Test Accuracy: 0.7252\n",
      "Epoch 13/2500 - Train Accuracy: 0.7786 - Val Accuracy: 0.7726 - Test Accuracy: 0.7667\n",
      "Epoch 14/2500 - Train Accuracy: 0.7612 - Val Accuracy: 0.7515 - Test Accuracy: 0.7403\n",
      "Epoch 15/2500 - Train Accuracy: 0.6446 - Val Accuracy: 0.6315 - Test Accuracy: 0.6328\n",
      "Epoch 16/2500 - Train Accuracy: 0.7503 - Val Accuracy: 0.7348 - Test Accuracy: 0.7380\n",
      "Epoch 17/2500 - Train Accuracy: 0.7096 - Val Accuracy: 0.6935 - Test Accuracy: 0.6961\n",
      "Epoch 18/2500 - Train Accuracy: 0.7532 - Val Accuracy: 0.7358 - Test Accuracy: 0.7332\n",
      "Epoch 19/2500 - Train Accuracy: 0.7806 - Val Accuracy: 0.7667 - Test Accuracy: 0.7678\n",
      "Epoch 20/2500 - Train Accuracy: 0.7941 - Val Accuracy: 0.7865 - Test Accuracy: 0.7770\n",
      "Epoch 21/2500 - Train Accuracy: 0.7503 - Val Accuracy: 0.7300 - Test Accuracy: 0.7327\n",
      "Epoch 22/2500 - Train Accuracy: 0.7711 - Val Accuracy: 0.7545 - Test Accuracy: 0.7518\n",
      "Epoch 23/2500 - Train Accuracy: 0.8209 - Val Accuracy: 0.7994 - Test Accuracy: 0.7994\n",
      "Epoch 24/2500 - Train Accuracy: 0.8480 - Val Accuracy: 0.8280 - Test Accuracy: 0.8251\n",
      "Epoch 25/2500 - Train Accuracy: 0.7771 - Val Accuracy: 0.7605 - Test Accuracy: 0.7607\n",
      "Epoch 26/2500 - Train Accuracy: 0.8518 - Val Accuracy: 0.8307 - Test Accuracy: 0.8328\n",
      "Epoch 27/2500 - Train Accuracy: 0.8178 - Val Accuracy: 0.8008 - Test Accuracy: 0.7996\n",
      "Epoch 28/2500 - Train Accuracy: 0.7888 - Val Accuracy: 0.7693 - Test Accuracy: 0.7691\n",
      "Epoch 29/2500 - Train Accuracy: 0.7491 - Val Accuracy: 0.7291 - Test Accuracy: 0.7256\n",
      "Epoch 30/2500 - Train Accuracy: 0.7912 - Val Accuracy: 0.7733 - Test Accuracy: 0.7657\n",
      "Epoch 31/2500 - Train Accuracy: 0.8035 - Val Accuracy: 0.7855 - Test Accuracy: 0.7808\n",
      "Epoch 32/2500 - Train Accuracy: 0.8030 - Val Accuracy: 0.7875 - Test Accuracy: 0.7777\n",
      "Epoch 33/2500 - Train Accuracy: 0.8176 - Val Accuracy: 0.7990 - Test Accuracy: 0.7964\n",
      "Epoch 34/2500 - Train Accuracy: 0.7237 - Val Accuracy: 0.7082 - Test Accuracy: 0.7025\n",
      "Epoch 35/2500 - Train Accuracy: 0.8414 - Val Accuracy: 0.8189 - Test Accuracy: 0.8154\n",
      "Epoch 36/2500 - Train Accuracy: 0.8042 - Val Accuracy: 0.7828 - Test Accuracy: 0.7817\n",
      "Epoch 37/2500 - Train Accuracy: 0.8117 - Val Accuracy: 0.7881 - Test Accuracy: 0.7883\n",
      "Epoch 38/2500 - Train Accuracy: 0.8486 - Val Accuracy: 0.8275 - Test Accuracy: 0.8226\n",
      "Epoch 39/2500 - Train Accuracy: 0.8125 - Val Accuracy: 0.7901 - Test Accuracy: 0.7926\n",
      "Epoch 40/2500 - Train Accuracy: 0.8209 - Val Accuracy: 0.7984 - Test Accuracy: 0.7965\n",
      "Epoch 41/2500 - Train Accuracy: 0.8528 - Val Accuracy: 0.8269 - Test Accuracy: 0.8248\n",
      "Epoch 42/2500 - Train Accuracy: 0.8279 - Val Accuracy: 0.8034 - Test Accuracy: 0.7978\n",
      "Epoch 43/2500 - Train Accuracy: 0.8914 - Val Accuracy: 0.8604 - Test Accuracy: 0.8577\n",
      "Epoch 44/2500 - Train Accuracy: 0.8786 - Val Accuracy: 0.8485 - Test Accuracy: 0.8481\n",
      "Epoch 45/2500 - Train Accuracy: 0.8451 - Val Accuracy: 0.8180 - Test Accuracy: 0.8148\n",
      "Epoch 46/2500 - Train Accuracy: 0.8329 - Val Accuracy: 0.8043 - Test Accuracy: 0.8068\n",
      "Epoch 47/2500 - Train Accuracy: 0.8597 - Val Accuracy: 0.8340 - Test Accuracy: 0.8263\n",
      "Epoch 48/2500 - Train Accuracy: 0.8484 - Val Accuracy: 0.8201 - Test Accuracy: 0.8187\n",
      "Epoch 49/2500 - Train Accuracy: 0.8644 - Val Accuracy: 0.8369 - Test Accuracy: 0.8318\n",
      "Epoch 50/2500 - Train Accuracy: 0.8826 - Val Accuracy: 0.8562 - Test Accuracy: 0.8540\n",
      "Epoch 51/2500 - Train Accuracy: 0.8346 - Val Accuracy: 0.8044 - Test Accuracy: 0.8013\n",
      "Epoch 52/2500 - Train Accuracy: 0.8263 - Val Accuracy: 0.8023 - Test Accuracy: 0.7922\n",
      "Epoch 53/2500 - Train Accuracy: 0.8621 - Val Accuracy: 0.8333 - Test Accuracy: 0.8314\n",
      "Epoch 54/2500 - Train Accuracy: 0.7977 - Val Accuracy: 0.7722 - Test Accuracy: 0.7640\n",
      "Epoch 55/2500 - Train Accuracy: 0.8552 - Val Accuracy: 0.8315 - Test Accuracy: 0.8207\n",
      "Epoch 56/2500 - Train Accuracy: 0.8208 - Val Accuracy: 0.7921 - Test Accuracy: 0.7866\n",
      "Epoch 57/2500 - Train Accuracy: 0.7908 - Val Accuracy: 0.7657 - Test Accuracy: 0.7618\n",
      "Epoch 58/2500 - Train Accuracy: 0.8401 - Val Accuracy: 0.8059 - Test Accuracy: 0.8015\n",
      "Epoch 59/2500 - Train Accuracy: 0.8289 - Val Accuracy: 0.7954 - Test Accuracy: 0.8000\n",
      "Epoch 60/2500 - Train Accuracy: 0.8569 - Val Accuracy: 0.8321 - Test Accuracy: 0.8172\n",
      "Epoch 61/2500 - Train Accuracy: 0.8882 - Val Accuracy: 0.8522 - Test Accuracy: 0.8506\n",
      "Epoch 62/2500 - Train Accuracy: 0.8991 - Val Accuracy: 0.8637 - Test Accuracy: 0.8581\n",
      "Epoch 63/2500 - Train Accuracy: 0.8864 - Val Accuracy: 0.8531 - Test Accuracy: 0.8484\n",
      "Epoch 64/2500 - Train Accuracy: 0.8952 - Val Accuracy: 0.8607 - Test Accuracy: 0.8553\n",
      "Epoch 65/2500 - Train Accuracy: 0.8454 - Val Accuracy: 0.8109 - Test Accuracy: 0.8053\n",
      "Epoch 66/2500 - Train Accuracy: 0.8513 - Val Accuracy: 0.8206 - Test Accuracy: 0.8111\n",
      "Epoch 67/2500 - Train Accuracy: 0.8888 - Val Accuracy: 0.8555 - Test Accuracy: 0.8477\n",
      "Epoch 68/2500 - Train Accuracy: 0.9028 - Val Accuracy: 0.8689 - Test Accuracy: 0.8567\n",
      "Epoch 69/2500 - Train Accuracy: 0.9009 - Val Accuracy: 0.8582 - Test Accuracy: 0.8512\n",
      "Epoch 70/2500 - Train Accuracy: 0.8827 - Val Accuracy: 0.8461 - Test Accuracy: 0.8425\n",
      "Epoch 71/2500 - Train Accuracy: 0.8707 - Val Accuracy: 0.8379 - Test Accuracy: 0.8293\n",
      "Epoch 72/2500 - Train Accuracy: 0.8765 - Val Accuracy: 0.8402 - Test Accuracy: 0.8305\n",
      "Epoch 73/2500 - Train Accuracy: 0.9061 - Val Accuracy: 0.8657 - Test Accuracy: 0.8597\n",
      "Epoch 74/2500 - Train Accuracy: 0.8860 - Val Accuracy: 0.8469 - Test Accuracy: 0.8406\n",
      "Epoch 75/2500 - Train Accuracy: 0.9023 - Val Accuracy: 0.8611 - Test Accuracy: 0.8539\n",
      "Epoch 76/2500 - Train Accuracy: 0.9065 - Val Accuracy: 0.8683 - Test Accuracy: 0.8557\n",
      "Epoch 77/2500 - Train Accuracy: 0.9000 - Val Accuracy: 0.8572 - Test Accuracy: 0.8558\n",
      "Epoch 78/2500 - Train Accuracy: 0.9011 - Val Accuracy: 0.8610 - Test Accuracy: 0.8582\n",
      "Epoch 79/2500 - Train Accuracy: 0.8825 - Val Accuracy: 0.8420 - Test Accuracy: 0.8354\n",
      "Epoch 80/2500 - Train Accuracy: 0.8989 - Val Accuracy: 0.8614 - Test Accuracy: 0.8511\n",
      "Epoch 81/2500 - Train Accuracy: 0.9020 - Val Accuracy: 0.8660 - Test Accuracy: 0.8553\n",
      "Epoch 82/2500 - Train Accuracy: 0.9249 - Val Accuracy: 0.8793 - Test Accuracy: 0.8731\n",
      "Epoch 83/2500 - Train Accuracy: 0.9278 - Val Accuracy: 0.8825 - Test Accuracy: 0.8755\n",
      "Epoch 84/2500 - Train Accuracy: 0.9219 - Val Accuracy: 0.8792 - Test Accuracy: 0.8676\n",
      "Epoch 85/2500 - Train Accuracy: 0.9254 - Val Accuracy: 0.8783 - Test Accuracy: 0.8726\n",
      "Epoch 86/2500 - Train Accuracy: 0.8976 - Val Accuracy: 0.8534 - Test Accuracy: 0.8474\n",
      "Epoch 87/2500 - Train Accuracy: 0.8902 - Val Accuracy: 0.8468 - Test Accuracy: 0.8389\n",
      "Epoch 88/2500 - Train Accuracy: 0.8955 - Val Accuracy: 0.8521 - Test Accuracy: 0.8435\n",
      "Epoch 89/2500 - Train Accuracy: 0.9037 - Val Accuracy: 0.8561 - Test Accuracy: 0.8489\n",
      "Epoch 90/2500 - Train Accuracy: 0.9096 - Val Accuracy: 0.8626 - Test Accuracy: 0.8587\n",
      "Epoch 91/2500 - Train Accuracy: 0.9053 - Val Accuracy: 0.8601 - Test Accuracy: 0.8539\n",
      "Epoch 92/2500 - Train Accuracy: 0.9292 - Val Accuracy: 0.8850 - Test Accuracy: 0.8736\n",
      "Epoch 93/2500 - Train Accuracy: 0.9254 - Val Accuracy: 0.8758 - Test Accuracy: 0.8713\n",
      "Epoch 94/2500 - Train Accuracy: 0.9009 - Val Accuracy: 0.8546 - Test Accuracy: 0.8474\n",
      "Epoch 95/2500 - Train Accuracy: 0.9052 - Val Accuracy: 0.8580 - Test Accuracy: 0.8489\n",
      "Epoch 96/2500 - Train Accuracy: 0.9112 - Val Accuracy: 0.8647 - Test Accuracy: 0.8552\n",
      "Epoch 97/2500 - Train Accuracy: 0.9112 - Val Accuracy: 0.8632 - Test Accuracy: 0.8554\n",
      "Epoch 98/2500 - Train Accuracy: 0.9246 - Val Accuracy: 0.8775 - Test Accuracy: 0.8683\n",
      "Epoch 99/2500 - Train Accuracy: 0.9316 - Val Accuracy: 0.8811 - Test Accuracy: 0.8760\n",
      "Epoch 100/2500 - Train Accuracy: 0.8870 - Val Accuracy: 0.8436 - Test Accuracy: 0.8349\n",
      "Epoch 101/2500 - Train Accuracy: 0.9184 - Val Accuracy: 0.8686 - Test Accuracy: 0.8588\n",
      "Epoch 102/2500 - Train Accuracy: 0.9355 - Val Accuracy: 0.8849 - Test Accuracy: 0.8732\n",
      "Epoch 103/2500 - Train Accuracy: 0.9184 - Val Accuracy: 0.8682 - Test Accuracy: 0.8602\n",
      "Epoch 104/2500 - Train Accuracy: 0.9226 - Val Accuracy: 0.8717 - Test Accuracy: 0.8605\n",
      "Epoch 105/2500 - Train Accuracy: 0.9271 - Val Accuracy: 0.8745 - Test Accuracy: 0.8635\n",
      "Epoch 106/2500 - Train Accuracy: 0.9460 - Val Accuracy: 0.8885 - Test Accuracy: 0.8832\n",
      "Epoch 107/2500 - Train Accuracy: 0.9287 - Val Accuracy: 0.8759 - Test Accuracy: 0.8675\n",
      "Epoch 108/2500 - Train Accuracy: 0.9414 - Val Accuracy: 0.8885 - Test Accuracy: 0.8777\n",
      "Epoch 109/2500 - Train Accuracy: 0.9335 - Val Accuracy: 0.8772 - Test Accuracy: 0.8673\n",
      "Epoch 110/2500 - Train Accuracy: 0.9374 - Val Accuracy: 0.8790 - Test Accuracy: 0.8716\n",
      "Epoch 111/2500 - Train Accuracy: 0.9336 - Val Accuracy: 0.8795 - Test Accuracy: 0.8741\n",
      "Epoch 112/2500 - Train Accuracy: 0.9272 - Val Accuracy: 0.8707 - Test Accuracy: 0.8641\n",
      "Epoch 113/2500 - Train Accuracy: 0.9555 - Val Accuracy: 0.9003 - Test Accuracy: 0.8905\n",
      "Epoch 114/2500 - Train Accuracy: 0.9384 - Val Accuracy: 0.8842 - Test Accuracy: 0.8718\n",
      "Epoch 115/2500 - Train Accuracy: 0.9161 - Val Accuracy: 0.8600 - Test Accuracy: 0.8507\n",
      "Epoch 116/2500 - Train Accuracy: 0.9287 - Val Accuracy: 0.8686 - Test Accuracy: 0.8615\n",
      "Epoch 117/2500 - Train Accuracy: 0.9193 - Val Accuracy: 0.8626 - Test Accuracy: 0.8582\n",
      "Epoch 118/2500 - Train Accuracy: 0.9218 - Val Accuracy: 0.8660 - Test Accuracy: 0.8595\n",
      "Epoch 119/2500 - Train Accuracy: 0.9348 - Val Accuracy: 0.8795 - Test Accuracy: 0.8680\n",
      "Epoch 120/2500 - Train Accuracy: 0.9395 - Val Accuracy: 0.8823 - Test Accuracy: 0.8713\n",
      "Epoch 121/2500 - Train Accuracy: 0.9391 - Val Accuracy: 0.8828 - Test Accuracy: 0.8719\n",
      "Epoch 122/2500 - Train Accuracy: 0.9401 - Val Accuracy: 0.8781 - Test Accuracy: 0.8712\n",
      "Epoch 123/2500 - Train Accuracy: 0.9473 - Val Accuracy: 0.8877 - Test Accuracy: 0.8772\n",
      "Epoch 124/2500 - Train Accuracy: 0.9431 - Val Accuracy: 0.8825 - Test Accuracy: 0.8732\n",
      "Epoch 125/2500 - Train Accuracy: 0.9255 - Val Accuracy: 0.8651 - Test Accuracy: 0.8538\n",
      "Epoch 126/2500 - Train Accuracy: 0.9457 - Val Accuracy: 0.8877 - Test Accuracy: 0.8769\n",
      "Epoch 127/2500 - Train Accuracy: 0.9257 - Val Accuracy: 0.8666 - Test Accuracy: 0.8578\n",
      "Epoch 128/2500 - Train Accuracy: 0.9354 - Val Accuracy: 0.8744 - Test Accuracy: 0.8643\n",
      "Epoch 129/2500 - Train Accuracy: 0.9309 - Val Accuracy: 0.8676 - Test Accuracy: 0.8589\n",
      "Epoch 130/2500 - Train Accuracy: 0.9408 - Val Accuracy: 0.8793 - Test Accuracy: 0.8707\n",
      "Epoch 131/2500 - Train Accuracy: 0.9391 - Val Accuracy: 0.8753 - Test Accuracy: 0.8684\n",
      "Epoch 132/2500 - Train Accuracy: 0.9453 - Val Accuracy: 0.8816 - Test Accuracy: 0.8757\n",
      "Epoch 133/2500 - Train Accuracy: 0.9333 - Val Accuracy: 0.8737 - Test Accuracy: 0.8620\n",
      "Epoch 134/2500 - Train Accuracy: 0.9299 - Val Accuracy: 0.8709 - Test Accuracy: 0.8601\n",
      "Epoch 135/2500 - Train Accuracy: 0.9355 - Val Accuracy: 0.8735 - Test Accuracy: 0.8667\n",
      "Epoch 136/2500 - Train Accuracy: 0.9499 - Val Accuracy: 0.8857 - Test Accuracy: 0.8777\n",
      "Epoch 137/2500 - Train Accuracy: 0.9411 - Val Accuracy: 0.8774 - Test Accuracy: 0.8681\n",
      "Epoch 138/2500 - Train Accuracy: 0.9546 - Val Accuracy: 0.8916 - Test Accuracy: 0.8840\n",
      "Epoch 139/2500 - Train Accuracy: 0.9548 - Val Accuracy: 0.8906 - Test Accuracy: 0.8828\n",
      "Epoch 140/2500 - Train Accuracy: 0.9401 - Val Accuracy: 0.8808 - Test Accuracy: 0.8713\n",
      "Epoch 141/2500 - Train Accuracy: 0.9447 - Val Accuracy: 0.8844 - Test Accuracy: 0.8714\n",
      "Epoch 142/2500 - Train Accuracy: 0.9444 - Val Accuracy: 0.8840 - Test Accuracy: 0.8741\n",
      "Epoch 143/2500 - Train Accuracy: 0.9503 - Val Accuracy: 0.8880 - Test Accuracy: 0.8805\n",
      "Epoch 144/2500 - Train Accuracy: 0.9456 - Val Accuracy: 0.8842 - Test Accuracy: 0.8743\n",
      "Epoch 145/2500 - Train Accuracy: 0.9486 - Val Accuracy: 0.8842 - Test Accuracy: 0.8770\n",
      "Epoch 146/2500 - Train Accuracy: 0.9533 - Val Accuracy: 0.8891 - Test Accuracy: 0.8808\n",
      "Epoch 147/2500 - Train Accuracy: 0.9493 - Val Accuracy: 0.8855 - Test Accuracy: 0.8768\n",
      "Epoch 148/2500 - Train Accuracy: 0.9460 - Val Accuracy: 0.8818 - Test Accuracy: 0.8728\n",
      "Epoch 149/2500 - Train Accuracy: 0.9488 - Val Accuracy: 0.8871 - Test Accuracy: 0.8768\n",
      "Epoch 150/2500 - Train Accuracy: 0.9509 - Val Accuracy: 0.8850 - Test Accuracy: 0.8757\n",
      "Epoch 151/2500 - Train Accuracy: 0.9547 - Val Accuracy: 0.8902 - Test Accuracy: 0.8804\n",
      "Epoch 152/2500 - Train Accuracy: 0.9459 - Val Accuracy: 0.8800 - Test Accuracy: 0.8718\n",
      "Epoch 153/2500 - Train Accuracy: 0.9485 - Val Accuracy: 0.8818 - Test Accuracy: 0.8747\n",
      "Epoch 154/2500 - Train Accuracy: 0.9561 - Val Accuracy: 0.8907 - Test Accuracy: 0.8848\n",
      "Epoch 155/2500 - Train Accuracy: 0.9405 - Val Accuracy: 0.8758 - Test Accuracy: 0.8650\n",
      "Epoch 156/2500 - Train Accuracy: 0.9497 - Val Accuracy: 0.8807 - Test Accuracy: 0.8726\n",
      "Epoch 157/2500 - Train Accuracy: 0.9454 - Val Accuracy: 0.8782 - Test Accuracy: 0.8686\n",
      "Epoch 158/2500 - Train Accuracy: 0.9549 - Val Accuracy: 0.8874 - Test Accuracy: 0.8788\n",
      "Epoch 159/2500 - Train Accuracy: 0.9481 - Val Accuracy: 0.8832 - Test Accuracy: 0.8724\n",
      "Epoch 160/2500 - Train Accuracy: 0.9590 - Val Accuracy: 0.8905 - Test Accuracy: 0.8832\n",
      "Epoch 161/2500 - Train Accuracy: 0.9552 - Val Accuracy: 0.8880 - Test Accuracy: 0.8790\n",
      "Epoch 162/2500 - Train Accuracy: 0.9546 - Val Accuracy: 0.8880 - Test Accuracy: 0.8786\n",
      "Epoch 163/2500 - Train Accuracy: 0.9542 - Val Accuracy: 0.8885 - Test Accuracy: 0.8770\n",
      "Epoch 164/2500 - Train Accuracy: 0.9533 - Val Accuracy: 0.8873 - Test Accuracy: 0.8768\n",
      "Epoch 165/2500 - Train Accuracy: 0.9484 - Val Accuracy: 0.8825 - Test Accuracy: 0.8716\n",
      "Epoch 166/2500 - Train Accuracy: 0.9517 - Val Accuracy: 0.8855 - Test Accuracy: 0.8756\n",
      "Epoch 167/2500 - Train Accuracy: 0.9545 - Val Accuracy: 0.8884 - Test Accuracy: 0.8792\n",
      "Epoch 168/2500 - Train Accuracy: 0.9534 - Val Accuracy: 0.8864 - Test Accuracy: 0.8757\n",
      "Epoch 169/2500 - Train Accuracy: 0.9537 - Val Accuracy: 0.8868 - Test Accuracy: 0.8768\n",
      "Epoch 170/2500 - Train Accuracy: 0.9578 - Val Accuracy: 0.8905 - Test Accuracy: 0.8804\n",
      "Epoch 171/2500 - Train Accuracy: 0.9576 - Val Accuracy: 0.8892 - Test Accuracy: 0.8809\n",
      "Epoch 172/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8926 - Test Accuracy: 0.8841\n",
      "Epoch 173/2500 - Train Accuracy: 0.9574 - Val Accuracy: 0.8899 - Test Accuracy: 0.8814\n",
      "Epoch 174/2500 - Train Accuracy: 0.9584 - Val Accuracy: 0.8892 - Test Accuracy: 0.8824\n",
      "Epoch 175/2500 - Train Accuracy: 0.9563 - Val Accuracy: 0.8887 - Test Accuracy: 0.8795\n",
      "Epoch 176/2500 - Train Accuracy: 0.9545 - Val Accuracy: 0.8887 - Test Accuracy: 0.8795\n",
      "Epoch 177/2500 - Train Accuracy: 0.9589 - Val Accuracy: 0.8925 - Test Accuracy: 0.8832\n",
      "Epoch 178/2500 - Train Accuracy: 0.9497 - Val Accuracy: 0.8824 - Test Accuracy: 0.8719\n",
      "Epoch 179/2500 - Train Accuracy: 0.9510 - Val Accuracy: 0.8831 - Test Accuracy: 0.8745\n",
      "Epoch 180/2500 - Train Accuracy: 0.9567 - Val Accuracy: 0.8891 - Test Accuracy: 0.8825\n",
      "Epoch 181/2500 - Train Accuracy: 0.9582 - Val Accuracy: 0.8915 - Test Accuracy: 0.8804\n",
      "Epoch 182/2500 - Train Accuracy: 0.9571 - Val Accuracy: 0.8893 - Test Accuracy: 0.8775\n",
      "Epoch 183/2500 - Train Accuracy: 0.9554 - Val Accuracy: 0.8880 - Test Accuracy: 0.8778\n",
      "Epoch 184/2500 - Train Accuracy: 0.9591 - Val Accuracy: 0.8910 - Test Accuracy: 0.8808\n",
      "Epoch 185/2500 - Train Accuracy: 0.9618 - Val Accuracy: 0.8936 - Test Accuracy: 0.8842\n",
      "Epoch 186/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8897 - Test Accuracy: 0.8822\n",
      "Epoch 187/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8921 - Test Accuracy: 0.8856\n",
      "Epoch 188/2500 - Train Accuracy: 0.9573 - Val Accuracy: 0.8894 - Test Accuracy: 0.8811\n",
      "Epoch 189/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8912 - Test Accuracy: 0.8837\n",
      "Epoch 190/2500 - Train Accuracy: 0.9578 - Val Accuracy: 0.8875 - Test Accuracy: 0.8800\n",
      "Epoch 191/2500 - Train Accuracy: 0.9574 - Val Accuracy: 0.8882 - Test Accuracy: 0.8801\n",
      "Epoch 192/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8916 - Test Accuracy: 0.8828\n",
      "Epoch 193/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8923 - Test Accuracy: 0.8835\n",
      "Epoch 194/2500 - Train Accuracy: 0.9577 - Val Accuracy: 0.8906 - Test Accuracy: 0.8808\n",
      "Epoch 195/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8909 - Test Accuracy: 0.8853\n",
      "Epoch 196/2500 - Train Accuracy: 0.9581 - Val Accuracy: 0.8898 - Test Accuracy: 0.8815\n",
      "Epoch 197/2500 - Train Accuracy: 0.9565 - Val Accuracy: 0.8878 - Test Accuracy: 0.8785\n",
      "Epoch 198/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8911 - Test Accuracy: 0.8825\n",
      "Epoch 199/2500 - Train Accuracy: 0.9586 - Val Accuracy: 0.8899 - Test Accuracy: 0.8807\n",
      "Epoch 200/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8927 - Test Accuracy: 0.8846\n",
      "Epoch 201/2500 - Train Accuracy: 0.9584 - Val Accuracy: 0.8911 - Test Accuracy: 0.8825\n",
      "Epoch 202/2500 - Train Accuracy: 0.9576 - Val Accuracy: 0.8908 - Test Accuracy: 0.8808\n",
      "Epoch 203/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8925 - Test Accuracy: 0.8830\n",
      "Epoch 204/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8916 - Test Accuracy: 0.8833\n",
      "Epoch 205/2500 - Train Accuracy: 0.9614 - Val Accuracy: 0.8931 - Test Accuracy: 0.8847\n",
      "Epoch 206/2500 - Train Accuracy: 0.9618 - Val Accuracy: 0.8937 - Test Accuracy: 0.8866\n",
      "Epoch 207/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8927 - Test Accuracy: 0.8849\n",
      "Epoch 208/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8920 - Test Accuracy: 0.8840\n",
      "Epoch 209/2500 - Train Accuracy: 0.9585 - Val Accuracy: 0.8909 - Test Accuracy: 0.8811\n",
      "Epoch 210/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8918 - Test Accuracy: 0.8825\n",
      "Epoch 211/2500 - Train Accuracy: 0.9578 - Val Accuracy: 0.8891 - Test Accuracy: 0.8812\n",
      "Epoch 212/2500 - Train Accuracy: 0.9582 - Val Accuracy: 0.8899 - Test Accuracy: 0.8819\n",
      "Epoch 213/2500 - Train Accuracy: 0.9586 - Val Accuracy: 0.8898 - Test Accuracy: 0.8821\n",
      "Epoch 214/2500 - Train Accuracy: 0.9588 - Val Accuracy: 0.8909 - Test Accuracy: 0.8823\n",
      "Epoch 215/2500 - Train Accuracy: 0.9581 - Val Accuracy: 0.8906 - Test Accuracy: 0.8820\n",
      "Epoch 216/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8913 - Test Accuracy: 0.8834\n",
      "Epoch 217/2500 - Train Accuracy: 0.9592 - Val Accuracy: 0.8916 - Test Accuracy: 0.8838\n",
      "Epoch 218/2500 - Train Accuracy: 0.9588 - Val Accuracy: 0.8903 - Test Accuracy: 0.8828\n",
      "Epoch 219/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8914 - Test Accuracy: 0.8825\n",
      "Epoch 220/2500 - Train Accuracy: 0.9587 - Val Accuracy: 0.8897 - Test Accuracy: 0.8818\n",
      "Epoch 221/2500 - Train Accuracy: 0.9578 - Val Accuracy: 0.8897 - Test Accuracy: 0.8811\n",
      "Epoch 222/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8915 - Test Accuracy: 0.8828\n",
      "Epoch 223/2500 - Train Accuracy: 0.9588 - Val Accuracy: 0.8902 - Test Accuracy: 0.8815\n",
      "Epoch 224/2500 - Train Accuracy: 0.9577 - Val Accuracy: 0.8896 - Test Accuracy: 0.8809\n",
      "Epoch 225/2500 - Train Accuracy: 0.9582 - Val Accuracy: 0.8902 - Test Accuracy: 0.8819\n",
      "Epoch 226/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8916 - Test Accuracy: 0.8830\n",
      "Epoch 227/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8913 - Test Accuracy: 0.8831\n",
      "Epoch 228/2500 - Train Accuracy: 0.9594 - Val Accuracy: 0.8904 - Test Accuracy: 0.8836\n",
      "Epoch 229/2500 - Train Accuracy: 0.9594 - Val Accuracy: 0.8916 - Test Accuracy: 0.8828\n",
      "Epoch 230/2500 - Train Accuracy: 0.9590 - Val Accuracy: 0.8907 - Test Accuracy: 0.8828\n",
      "Epoch 231/2500 - Train Accuracy: 0.9587 - Val Accuracy: 0.8902 - Test Accuracy: 0.8828\n",
      "Epoch 232/2500 - Train Accuracy: 0.9589 - Val Accuracy: 0.8904 - Test Accuracy: 0.8828\n",
      "Epoch 233/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8924 - Test Accuracy: 0.8846\n",
      "Epoch 234/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8925 - Test Accuracy: 0.8841\n",
      "Epoch 235/2500 - Train Accuracy: 0.9614 - Val Accuracy: 0.8939 - Test Accuracy: 0.8855\n",
      "Epoch 236/2500 - Train Accuracy: 0.9612 - Val Accuracy: 0.8930 - Test Accuracy: 0.8854\n",
      "Epoch 237/2500 - Train Accuracy: 0.9613 - Val Accuracy: 0.8935 - Test Accuracy: 0.8849\n",
      "Epoch 238/2500 - Train Accuracy: 0.9612 - Val Accuracy: 0.8935 - Test Accuracy: 0.8851\n",
      "Epoch 239/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8926 - Test Accuracy: 0.8840\n",
      "Epoch 240/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8924 - Test Accuracy: 0.8833\n",
      "Epoch 241/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8924 - Test Accuracy: 0.8834\n",
      "Epoch 242/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8925 - Test Accuracy: 0.8836\n",
      "Epoch 243/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8928 - Test Accuracy: 0.8832\n",
      "Epoch 244/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8931 - Test Accuracy: 0.8845\n",
      "Epoch 245/2500 - Train Accuracy: 0.9594 - Val Accuracy: 0.8906 - Test Accuracy: 0.8824\n",
      "Epoch 246/2500 - Train Accuracy: 0.9611 - Val Accuracy: 0.8929 - Test Accuracy: 0.8851\n",
      "Epoch 247/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8921 - Test Accuracy: 0.8843\n",
      "Epoch 248/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8914 - Test Accuracy: 0.8832\n",
      "Epoch 249/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8908 - Test Accuracy: 0.8828\n",
      "Epoch 250/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8923 - Test Accuracy: 0.8844\n",
      "Epoch 251/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8914 - Test Accuracy: 0.8835\n",
      "Epoch 252/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8911 - Test Accuracy: 0.8844\n",
      "Epoch 253/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8930 - Test Accuracy: 0.8839\n",
      "Epoch 254/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8915 - Test Accuracy: 0.8834\n",
      "Epoch 255/2500 - Train Accuracy: 0.9612 - Val Accuracy: 0.8925 - Test Accuracy: 0.8846\n",
      "Epoch 256/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8918 - Test Accuracy: 0.8844\n",
      "Epoch 257/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8912 - Test Accuracy: 0.8837\n",
      "Epoch 258/2500 - Train Accuracy: 0.9619 - Val Accuracy: 0.8928 - Test Accuracy: 0.8858\n",
      "Epoch 259/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8919 - Test Accuracy: 0.8838\n",
      "Epoch 260/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8919 - Test Accuracy: 0.8836\n",
      "Epoch 261/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8918 - Test Accuracy: 0.8835\n",
      "Epoch 262/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8915 - Test Accuracy: 0.8833\n",
      "Epoch 263/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8922 - Test Accuracy: 0.8834\n",
      "Epoch 264/2500 - Train Accuracy: 0.9611 - Val Accuracy: 0.8924 - Test Accuracy: 0.8842\n",
      "Epoch 265/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8917 - Test Accuracy: 0.8841\n",
      "Epoch 266/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8913 - Test Accuracy: 0.8832\n",
      "Epoch 267/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8925 - Test Accuracy: 0.8839\n",
      "Epoch 268/2500 - Train Accuracy: 0.9614 - Val Accuracy: 0.8924 - Test Accuracy: 0.8844\n",
      "Epoch 269/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8916 - Test Accuracy: 0.8839\n",
      "Epoch 270/2500 - Train Accuracy: 0.9614 - Val Accuracy: 0.8925 - Test Accuracy: 0.8846\n",
      "Epoch 271/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8917 - Test Accuracy: 0.8836\n",
      "Epoch 272/2500 - Train Accuracy: 0.9611 - Val Accuracy: 0.8928 - Test Accuracy: 0.8841\n",
      "Epoch 273/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8914 - Test Accuracy: 0.8836\n",
      "Epoch 274/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8920 - Test Accuracy: 0.8847\n",
      "Epoch 275/2500 - Train Accuracy: 0.9612 - Val Accuracy: 0.8925 - Test Accuracy: 0.8846\n",
      "Epoch 276/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8914 - Test Accuracy: 0.8826\n",
      "Epoch 277/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8916 - Test Accuracy: 0.8831\n",
      "Epoch 278/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8917 - Test Accuracy: 0.8839\n",
      "Epoch 279/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8917 - Test Accuracy: 0.8839\n",
      "Epoch 280/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8924 - Test Accuracy: 0.8847\n",
      "Epoch 281/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8918 - Test Accuracy: 0.8836\n",
      "Epoch 282/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8912 - Test Accuracy: 0.8828\n",
      "Epoch 283/2500 - Train Accuracy: 0.9611 - Val Accuracy: 0.8925 - Test Accuracy: 0.8847\n",
      "Epoch 284/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8921 - Test Accuracy: 0.8842\n",
      "Epoch 285/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8912 - Test Accuracy: 0.8835\n",
      "Epoch 286/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8925 - Test Accuracy: 0.8846\n",
      "Epoch 287/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8916 - Test Accuracy: 0.8840\n",
      "Epoch 288/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8918 - Test Accuracy: 0.8835\n",
      "Epoch 289/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8918 - Test Accuracy: 0.8839\n",
      "Epoch 290/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8919 - Test Accuracy: 0.8839\n",
      "Epoch 291/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8916 - Test Accuracy: 0.8839\n",
      "Epoch 292/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8919 - Test Accuracy: 0.8848\n",
      "Epoch 293/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8913 - Test Accuracy: 0.8835\n",
      "Epoch 294/2500 - Train Accuracy: 0.9613 - Val Accuracy: 0.8919 - Test Accuracy: 0.8852\n",
      "Epoch 295/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8922 - Test Accuracy: 0.8848\n",
      "Epoch 296/2500 - Train Accuracy: 0.9611 - Val Accuracy: 0.8927 - Test Accuracy: 0.8851\n",
      "Epoch 297/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8919 - Test Accuracy: 0.8841\n",
      "Epoch 298/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8911 - Test Accuracy: 0.8839\n",
      "Epoch 299/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8912 - Test Accuracy: 0.8827\n",
      "Epoch 300/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8915 - Test Accuracy: 0.8835\n",
      "Epoch 301/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8906 - Test Accuracy: 0.8830\n",
      "Epoch 302/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8916 - Test Accuracy: 0.8846\n",
      "Epoch 303/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8920 - Test Accuracy: 0.8849\n",
      "Epoch 304/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8917 - Test Accuracy: 0.8844\n",
      "Epoch 305/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8911 - Test Accuracy: 0.8823\n",
      "Epoch 306/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8921 - Test Accuracy: 0.8835\n",
      "Epoch 307/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8924 - Test Accuracy: 0.8855\n",
      "Epoch 308/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8912 - Test Accuracy: 0.8827\n",
      "Epoch 309/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8910 - Test Accuracy: 0.8827\n",
      "Epoch 310/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8912 - Test Accuracy: 0.8831\n",
      "Epoch 311/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8920 - Test Accuracy: 0.8841\n",
      "Epoch 312/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8926 - Test Accuracy: 0.8846\n",
      "Epoch 313/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8918 - Test Accuracy: 0.8841\n",
      "Epoch 314/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8911 - Test Accuracy: 0.8830\n",
      "Epoch 315/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8912 - Test Accuracy: 0.8827\n",
      "Epoch 316/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8918 - Test Accuracy: 0.8841\n",
      "Epoch 317/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8920 - Test Accuracy: 0.8839\n",
      "Epoch 318/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8913 - Test Accuracy: 0.8832\n",
      "Epoch 319/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8923 - Test Accuracy: 0.8840\n",
      "Epoch 320/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8924 - Test Accuracy: 0.8845\n",
      "Epoch 321/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8914 - Test Accuracy: 0.8820\n",
      "Epoch 322/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8920 - Test Accuracy: 0.8839\n",
      "Epoch 323/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8926 - Test Accuracy: 0.8852\n",
      "Epoch 324/2500 - Train Accuracy: 0.9591 - Val Accuracy: 0.8908 - Test Accuracy: 0.8827\n",
      "Epoch 325/2500 - Train Accuracy: 0.9611 - Val Accuracy: 0.8925 - Test Accuracy: 0.8850\n",
      "Epoch 326/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8919 - Test Accuracy: 0.8842\n",
      "Epoch 327/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8923 - Test Accuracy: 0.8844\n",
      "Epoch 328/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8916 - Test Accuracy: 0.8833\n",
      "Epoch 329/2500 - Train Accuracy: 0.9594 - Val Accuracy: 0.8910 - Test Accuracy: 0.8828\n",
      "Epoch 330/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8922 - Test Accuracy: 0.8846\n",
      "Epoch 331/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8917 - Test Accuracy: 0.8838\n",
      "Epoch 332/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8914 - Test Accuracy: 0.8832\n",
      "Epoch 333/2500 - Train Accuracy: 0.9594 - Val Accuracy: 0.8909 - Test Accuracy: 0.8824\n",
      "Epoch 334/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8920 - Test Accuracy: 0.8838\n",
      "Epoch 335/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8914 - Test Accuracy: 0.8830\n",
      "Epoch 336/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8916 - Test Accuracy: 0.8843\n",
      "Epoch 337/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8920 - Test Accuracy: 0.8831\n",
      "Epoch 338/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8919 - Test Accuracy: 0.8832\n",
      "Epoch 339/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8918 - Test Accuracy: 0.8846\n",
      "Epoch 340/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8927 - Test Accuracy: 0.8848\n",
      "Epoch 341/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8922 - Test Accuracy: 0.8838\n",
      "Epoch 342/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8912 - Test Accuracy: 0.8832\n",
      "Epoch 343/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8916 - Test Accuracy: 0.8831\n",
      "Epoch 344/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8926 - Test Accuracy: 0.8847\n",
      "Epoch 345/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8913 - Test Accuracy: 0.8832\n",
      "Epoch 346/2500 - Train Accuracy: 0.9612 - Val Accuracy: 0.8924 - Test Accuracy: 0.8854\n",
      "Epoch 347/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8920 - Test Accuracy: 0.8837\n",
      "Epoch 348/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8923 - Test Accuracy: 0.8836\n",
      "Epoch 349/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8915 - Test Accuracy: 0.8837\n",
      "Epoch 350/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8925 - Test Accuracy: 0.8847\n",
      "Epoch 351/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8918 - Test Accuracy: 0.8841\n",
      "Epoch 352/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8921 - Test Accuracy: 0.8836\n",
      "Epoch 353/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8915 - Test Accuracy: 0.8831\n",
      "Epoch 354/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8920 - Test Accuracy: 0.8847\n",
      "Epoch 355/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8914 - Test Accuracy: 0.8841\n",
      "Epoch 356/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8912 - Test Accuracy: 0.8824\n",
      "Epoch 357/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8914 - Test Accuracy: 0.8825\n",
      "Epoch 358/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8916 - Test Accuracy: 0.8831\n",
      "Epoch 359/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8913 - Test Accuracy: 0.8833\n",
      "Epoch 360/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8926 - Test Accuracy: 0.8851\n",
      "Epoch 361/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8920 - Test Accuracy: 0.8842\n",
      "Epoch 362/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8919 - Test Accuracy: 0.8833\n",
      "Epoch 363/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8917 - Test Accuracy: 0.8835\n",
      "Epoch 364/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8918 - Test Accuracy: 0.8840\n",
      "Epoch 365/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8908 - Test Accuracy: 0.8821\n",
      "Epoch 366/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8915 - Test Accuracy: 0.8831\n",
      "Epoch 367/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8917 - Test Accuracy: 0.8832\n",
      "Epoch 368/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8920 - Test Accuracy: 0.8842\n",
      "Epoch 369/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8922 - Test Accuracy: 0.8845\n",
      "Epoch 370/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8930 - Test Accuracy: 0.8842\n",
      "Epoch 371/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8910 - Test Accuracy: 0.8825\n",
      "Epoch 372/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8924 - Test Accuracy: 0.8846\n",
      "Epoch 373/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8906 - Test Accuracy: 0.8833\n",
      "Epoch 374/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8911 - Test Accuracy: 0.8827\n",
      "Epoch 375/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8918 - Test Accuracy: 0.8834\n",
      "Epoch 376/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8920 - Test Accuracy: 0.8837\n",
      "Epoch 377/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8915 - Test Accuracy: 0.8832\n",
      "Epoch 378/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8927 - Test Accuracy: 0.8848\n",
      "Epoch 379/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8923 - Test Accuracy: 0.8848\n",
      "Epoch 380/2500 - Train Accuracy: 0.9592 - Val Accuracy: 0.8907 - Test Accuracy: 0.8822\n",
      "Epoch 381/2500 - Train Accuracy: 0.9592 - Val Accuracy: 0.8911 - Test Accuracy: 0.8824\n",
      "Epoch 382/2500 - Train Accuracy: 0.9589 - Val Accuracy: 0.8910 - Test Accuracy: 0.8822\n",
      "Epoch 383/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8915 - Test Accuracy: 0.8827\n",
      "Epoch 384/2500 - Train Accuracy: 0.9594 - Val Accuracy: 0.8907 - Test Accuracy: 0.8827\n",
      "Epoch 385/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8920 - Test Accuracy: 0.8839\n",
      "Epoch 386/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8919 - Test Accuracy: 0.8831\n",
      "Epoch 387/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8922 - Test Accuracy: 0.8840\n",
      "Epoch 388/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8914 - Test Accuracy: 0.8836\n",
      "Epoch 389/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8912 - Test Accuracy: 0.8838\n",
      "Epoch 390/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8916 - Test Accuracy: 0.8836\n",
      "Epoch 391/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8921 - Test Accuracy: 0.8833\n",
      "Epoch 392/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8906 - Test Accuracy: 0.8823\n",
      "Epoch 393/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8924 - Test Accuracy: 0.8848\n",
      "Epoch 394/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8914 - Test Accuracy: 0.8830\n",
      "Epoch 395/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8915 - Test Accuracy: 0.8832\n",
      "Epoch 396/2500 - Train Accuracy: 0.9594 - Val Accuracy: 0.8919 - Test Accuracy: 0.8827\n",
      "Epoch 397/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8920 - Test Accuracy: 0.8845\n",
      "Epoch 398/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8908 - Test Accuracy: 0.8832\n",
      "Epoch 399/2500 - Train Accuracy: 0.9611 - Val Accuracy: 0.8923 - Test Accuracy: 0.8845\n",
      "Epoch 400/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8923 - Test Accuracy: 0.8836\n",
      "Epoch 401/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8913 - Test Accuracy: 0.8836\n",
      "Epoch 402/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8924 - Test Accuracy: 0.8844\n",
      "Epoch 403/2500 - Train Accuracy: 0.9594 - Val Accuracy: 0.8913 - Test Accuracy: 0.8823\n",
      "Epoch 404/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8923 - Test Accuracy: 0.8843\n",
      "Epoch 405/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8915 - Test Accuracy: 0.8831\n",
      "Epoch 406/2500 - Train Accuracy: 0.9594 - Val Accuracy: 0.8912 - Test Accuracy: 0.8824\n",
      "Epoch 407/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8914 - Test Accuracy: 0.8827\n",
      "Epoch 408/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8922 - Test Accuracy: 0.8845\n",
      "Epoch 409/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8909 - Test Accuracy: 0.8831\n",
      "Epoch 410/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8908 - Test Accuracy: 0.8831\n",
      "Epoch 411/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8922 - Test Accuracy: 0.8842\n",
      "Epoch 412/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8912 - Test Accuracy: 0.8835\n",
      "Epoch 413/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8918 - Test Accuracy: 0.8841\n",
      "Epoch 414/2500 - Train Accuracy: 0.9592 - Val Accuracy: 0.8905 - Test Accuracy: 0.8827\n",
      "Epoch 415/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8906 - Test Accuracy: 0.8824\n",
      "Epoch 416/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8916 - Test Accuracy: 0.8833\n",
      "Epoch 417/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8927 - Test Accuracy: 0.8839\n",
      "Epoch 418/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8922 - Test Accuracy: 0.8837\n",
      "Epoch 419/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8913 - Test Accuracy: 0.8820\n",
      "Epoch 420/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8924 - Test Accuracy: 0.8840\n",
      "Epoch 421/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8921 - Test Accuracy: 0.8848\n",
      "Epoch 422/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8922 - Test Accuracy: 0.8844\n",
      "Epoch 423/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8919 - Test Accuracy: 0.8835\n",
      "Epoch 424/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8908 - Test Accuracy: 0.8821\n",
      "Epoch 425/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8909 - Test Accuracy: 0.8827\n",
      "Epoch 426/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8911 - Test Accuracy: 0.8832\n",
      "Epoch 427/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8914 - Test Accuracy: 0.8832\n",
      "Epoch 428/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8914 - Test Accuracy: 0.8833\n",
      "Epoch 429/2500 - Train Accuracy: 0.9592 - Val Accuracy: 0.8914 - Test Accuracy: 0.8828\n",
      "Epoch 430/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8917 - Test Accuracy: 0.8833\n",
      "Epoch 431/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8922 - Test Accuracy: 0.8841\n",
      "Epoch 432/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8924 - Test Accuracy: 0.8837\n",
      "Epoch 433/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8917 - Test Accuracy: 0.8840\n",
      "Epoch 434/2500 - Train Accuracy: 0.9594 - Val Accuracy: 0.8907 - Test Accuracy: 0.8825\n",
      "Epoch 435/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8916 - Test Accuracy: 0.8846\n",
      "Epoch 436/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8914 - Test Accuracy: 0.8834\n",
      "Epoch 437/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8915 - Test Accuracy: 0.8830\n",
      "Epoch 438/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8906 - Test Accuracy: 0.8824\n",
      "Epoch 439/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8925 - Test Accuracy: 0.8844\n",
      "Epoch 440/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8927 - Test Accuracy: 0.8842\n",
      "Epoch 441/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8913 - Test Accuracy: 0.8829\n",
      "Epoch 442/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8923 - Test Accuracy: 0.8848\n",
      "Epoch 443/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8911 - Test Accuracy: 0.8829\n",
      "Epoch 444/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8911 - Test Accuracy: 0.8832\n",
      "Epoch 445/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8916 - Test Accuracy: 0.8828\n",
      "Epoch 446/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8925 - Test Accuracy: 0.8850\n",
      "Epoch 447/2500 - Train Accuracy: 0.9594 - Val Accuracy: 0.8909 - Test Accuracy: 0.8827\n",
      "Epoch 448/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8911 - Test Accuracy: 0.8833\n",
      "Epoch 449/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8925 - Test Accuracy: 0.8847\n",
      "Epoch 450/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8914 - Test Accuracy: 0.8824\n",
      "Epoch 451/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8915 - Test Accuracy: 0.8835\n",
      "Epoch 452/2500 - Train Accuracy: 0.9611 - Val Accuracy: 0.8927 - Test Accuracy: 0.8851\n",
      "Epoch 453/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8917 - Test Accuracy: 0.8833\n",
      "Epoch 454/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8911 - Test Accuracy: 0.8831\n",
      "Epoch 455/2500 - Train Accuracy: 0.9590 - Val Accuracy: 0.8904 - Test Accuracy: 0.8819\n",
      "Epoch 456/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8925 - Test Accuracy: 0.8842\n",
      "Epoch 457/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8913 - Test Accuracy: 0.8831\n",
      "Epoch 458/2500 - Train Accuracy: 0.9612 - Val Accuracy: 0.8923 - Test Accuracy: 0.8842\n",
      "Epoch 459/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8918 - Test Accuracy: 0.8836\n",
      "Epoch 460/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8921 - Test Accuracy: 0.8844\n",
      "Epoch 461/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8914 - Test Accuracy: 0.8831\n",
      "Epoch 462/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8918 - Test Accuracy: 0.8841\n",
      "Epoch 463/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8915 - Test Accuracy: 0.8831\n",
      "Epoch 464/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8926 - Test Accuracy: 0.8841\n",
      "Epoch 465/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8917 - Test Accuracy: 0.8838\n",
      "Epoch 466/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8923 - Test Accuracy: 0.8841\n",
      "Epoch 467/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8923 - Test Accuracy: 0.8843\n",
      "Epoch 468/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8923 - Test Accuracy: 0.8838\n",
      "Epoch 469/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8912 - Test Accuracy: 0.8833\n",
      "Epoch 470/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8919 - Test Accuracy: 0.8838\n",
      "Epoch 471/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8920 - Test Accuracy: 0.8837\n",
      "Epoch 472/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8921 - Test Accuracy: 0.8842\n",
      "Epoch 473/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8920 - Test Accuracy: 0.8842\n",
      "Epoch 474/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8923 - Test Accuracy: 0.8836\n",
      "Epoch 475/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8920 - Test Accuracy: 0.8834\n",
      "Epoch 476/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8919 - Test Accuracy: 0.8843\n",
      "Epoch 477/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8921 - Test Accuracy: 0.8840\n",
      "Epoch 478/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8919 - Test Accuracy: 0.8837\n",
      "Epoch 479/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8911 - Test Accuracy: 0.8835\n",
      "Epoch 480/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8913 - Test Accuracy: 0.8830\n",
      "Epoch 481/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8924 - Test Accuracy: 0.8844\n",
      "Epoch 482/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8924 - Test Accuracy: 0.8836\n",
      "Epoch 483/2500 - Train Accuracy: 0.9613 - Val Accuracy: 0.8929 - Test Accuracy: 0.8855\n",
      "Epoch 484/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8915 - Test Accuracy: 0.8837\n",
      "Epoch 485/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8924 - Test Accuracy: 0.8842\n",
      "Epoch 486/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8922 - Test Accuracy: 0.8848\n",
      "Epoch 487/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8919 - Test Accuracy: 0.8842\n",
      "Epoch 488/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8911 - Test Accuracy: 0.8830\n",
      "Epoch 489/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8929 - Test Accuracy: 0.8849\n",
      "Epoch 490/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8921 - Test Accuracy: 0.8847\n",
      "Epoch 491/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8919 - Test Accuracy: 0.8833\n",
      "Epoch 492/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8918 - Test Accuracy: 0.8836\n",
      "Epoch 493/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8910 - Test Accuracy: 0.8832\n",
      "Epoch 494/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8918 - Test Accuracy: 0.8829\n",
      "Epoch 495/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8918 - Test Accuracy: 0.8839\n",
      "Epoch 496/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8926 - Test Accuracy: 0.8848\n",
      "Epoch 497/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8920 - Test Accuracy: 0.8831\n",
      "Epoch 498/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8917 - Test Accuracy: 0.8833\n",
      "Epoch 499/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8906 - Test Accuracy: 0.8827\n",
      "Epoch 500/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8924 - Test Accuracy: 0.8842\n",
      "Epoch 501/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8915 - Test Accuracy: 0.8837\n",
      "Epoch 502/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8918 - Test Accuracy: 0.8846\n",
      "Epoch 503/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8928 - Test Accuracy: 0.8849\n",
      "Epoch 504/2500 - Train Accuracy: 0.9592 - Val Accuracy: 0.8907 - Test Accuracy: 0.8821\n",
      "Epoch 505/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8910 - Test Accuracy: 0.8828\n",
      "Epoch 506/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8910 - Test Accuracy: 0.8820\n",
      "Epoch 507/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8921 - Test Accuracy: 0.8836\n",
      "Epoch 508/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8925 - Test Accuracy: 0.8841\n",
      "Epoch 509/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8920 - Test Accuracy: 0.8838\n",
      "Epoch 510/2500 - Train Accuracy: 0.9615 - Val Accuracy: 0.8929 - Test Accuracy: 0.8852\n",
      "Epoch 511/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8921 - Test Accuracy: 0.8836\n",
      "Epoch 512/2500 - Train Accuracy: 0.9592 - Val Accuracy: 0.8907 - Test Accuracy: 0.8816\n",
      "Epoch 513/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8917 - Test Accuracy: 0.8838\n",
      "Epoch 514/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8915 - Test Accuracy: 0.8837\n",
      "Epoch 515/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8919 - Test Accuracy: 0.8834\n",
      "Epoch 516/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8922 - Test Accuracy: 0.8841\n",
      "Epoch 517/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8930 - Test Accuracy: 0.8849\n",
      "Epoch 518/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8928 - Test Accuracy: 0.8846\n",
      "Epoch 519/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8917 - Test Accuracy: 0.8837\n",
      "Epoch 520/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8924 - Test Accuracy: 0.8841\n",
      "Epoch 521/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8918 - Test Accuracy: 0.8836\n",
      "Epoch 522/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8921 - Test Accuracy: 0.8840\n",
      "Epoch 523/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8916 - Test Accuracy: 0.8840\n",
      "Epoch 524/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8916 - Test Accuracy: 0.8834\n",
      "Epoch 525/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8916 - Test Accuracy: 0.8836\n",
      "Epoch 526/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8920 - Test Accuracy: 0.8839\n",
      "Epoch 527/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8914 - Test Accuracy: 0.8832\n",
      "Epoch 528/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8926 - Test Accuracy: 0.8855\n",
      "Epoch 529/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8924 - Test Accuracy: 0.8842\n",
      "Epoch 530/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8920 - Test Accuracy: 0.8838\n",
      "Epoch 531/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8919 - Test Accuracy: 0.8841\n",
      "Epoch 532/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8919 - Test Accuracy: 0.8840\n",
      "Epoch 533/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8921 - Test Accuracy: 0.8845\n",
      "Epoch 534/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8921 - Test Accuracy: 0.8840\n",
      "Epoch 535/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8912 - Test Accuracy: 0.8836\n",
      "Epoch 536/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8922 - Test Accuracy: 0.8847\n",
      "Epoch 537/2500 - Train Accuracy: 0.9612 - Val Accuracy: 0.8929 - Test Accuracy: 0.8854\n",
      "Epoch 538/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8918 - Test Accuracy: 0.8839\n",
      "Epoch 539/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8924 - Test Accuracy: 0.8844\n",
      "Epoch 540/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8926 - Test Accuracy: 0.8844\n",
      "Epoch 541/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8920 - Test Accuracy: 0.8839\n",
      "Epoch 542/2500 - Train Accuracy: 0.9613 - Val Accuracy: 0.8931 - Test Accuracy: 0.8852\n",
      "Epoch 543/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8914 - Test Accuracy: 0.8833\n",
      "Epoch 544/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8919 - Test Accuracy: 0.8837\n",
      "Epoch 545/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8923 - Test Accuracy: 0.8850\n",
      "Epoch 546/2500 - Train Accuracy: 0.9611 - Val Accuracy: 0.8926 - Test Accuracy: 0.8847\n",
      "Epoch 547/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8928 - Test Accuracy: 0.8848\n",
      "Epoch 548/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8913 - Test Accuracy: 0.8835\n",
      "Epoch 549/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8921 - Test Accuracy: 0.8842\n",
      "Epoch 550/2500 - Train Accuracy: 0.9594 - Val Accuracy: 0.8904 - Test Accuracy: 0.8825\n",
      "Epoch 551/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8919 - Test Accuracy: 0.8841\n",
      "Epoch 552/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8914 - Test Accuracy: 0.8835\n",
      "Epoch 553/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8921 - Test Accuracy: 0.8844\n",
      "Epoch 554/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8918 - Test Accuracy: 0.8836\n",
      "Epoch 555/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8916 - Test Accuracy: 0.8829\n",
      "Epoch 556/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8915 - Test Accuracy: 0.8834\n",
      "Epoch 557/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8921 - Test Accuracy: 0.8842\n",
      "Epoch 558/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8910 - Test Accuracy: 0.8834\n",
      "Epoch 559/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8912 - Test Accuracy: 0.8825\n",
      "Epoch 560/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8918 - Test Accuracy: 0.8838\n",
      "Epoch 561/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8914 - Test Accuracy: 0.8828\n",
      "Epoch 562/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8923 - Test Accuracy: 0.8846\n",
      "Epoch 563/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8916 - Test Accuracy: 0.8834\n",
      "Epoch 564/2500 - Train Accuracy: 0.9613 - Val Accuracy: 0.8927 - Test Accuracy: 0.8852\n",
      "Epoch 565/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8920 - Test Accuracy: 0.8839\n",
      "Epoch 566/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8912 - Test Accuracy: 0.8831\n",
      "Epoch 567/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8918 - Test Accuracy: 0.8835\n",
      "Epoch 568/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8925 - Test Accuracy: 0.8841\n",
      "Epoch 569/2500 - Train Accuracy: 0.9610 - Val Accuracy: 0.8927 - Test Accuracy: 0.8847\n",
      "Epoch 570/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8920 - Test Accuracy: 0.8840\n",
      "Epoch 571/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8918 - Test Accuracy: 0.8832\n",
      "Epoch 572/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8913 - Test Accuracy: 0.8831\n",
      "Epoch 573/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8918 - Test Accuracy: 0.8830\n",
      "Epoch 574/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8924 - Test Accuracy: 0.8845\n",
      "Epoch 575/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8915 - Test Accuracy: 0.8836\n",
      "Epoch 576/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8915 - Test Accuracy: 0.8828\n",
      "Epoch 577/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8915 - Test Accuracy: 0.8840\n",
      "Epoch 578/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8924 - Test Accuracy: 0.8848\n",
      "Epoch 579/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8911 - Test Accuracy: 0.8823\n",
      "Epoch 580/2500 - Train Accuracy: 0.9611 - Val Accuracy: 0.8920 - Test Accuracy: 0.8841\n",
      "Epoch 581/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8910 - Test Accuracy: 0.8828\n",
      "Epoch 582/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8914 - Test Accuracy: 0.8834\n",
      "Epoch 583/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8924 - Test Accuracy: 0.8844\n",
      "Epoch 584/2500 - Train Accuracy: 0.9617 - Val Accuracy: 0.8935 - Test Accuracy: 0.8854\n",
      "Epoch 585/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8921 - Test Accuracy: 0.8842\n",
      "Epoch 586/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8922 - Test Accuracy: 0.8841\n",
      "Epoch 587/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8920 - Test Accuracy: 0.8835\n",
      "Epoch 588/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8911 - Test Accuracy: 0.8822\n",
      "Epoch 589/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8916 - Test Accuracy: 0.8831\n",
      "Epoch 590/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8911 - Test Accuracy: 0.8833\n",
      "Epoch 591/2500 - Train Accuracy: 0.9589 - Val Accuracy: 0.8903 - Test Accuracy: 0.8823\n",
      "Epoch 592/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8917 - Test Accuracy: 0.8833\n",
      "Epoch 593/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8921 - Test Accuracy: 0.8843\n",
      "Epoch 594/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8925 - Test Accuracy: 0.8845\n",
      "Epoch 595/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8917 - Test Accuracy: 0.8839\n",
      "Epoch 596/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8924 - Test Accuracy: 0.8843\n",
      "Epoch 597/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8916 - Test Accuracy: 0.8826\n",
      "Epoch 598/2500 - Train Accuracy: 0.9611 - Val Accuracy: 0.8929 - Test Accuracy: 0.8850\n",
      "Epoch 599/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8917 - Test Accuracy: 0.8831\n",
      "Epoch 600/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8919 - Test Accuracy: 0.8842\n",
      "Epoch 601/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8914 - Test Accuracy: 0.8839\n",
      "Epoch 602/2500 - Train Accuracy: 0.9617 - Val Accuracy: 0.8931 - Test Accuracy: 0.8856\n",
      "Epoch 603/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8922 - Test Accuracy: 0.8840\n",
      "Epoch 604/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8919 - Test Accuracy: 0.8832\n",
      "Epoch 605/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8913 - Test Accuracy: 0.8836\n",
      "Epoch 606/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8911 - Test Accuracy: 0.8823\n",
      "Epoch 607/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8917 - Test Accuracy: 0.8830\n",
      "Epoch 608/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8921 - Test Accuracy: 0.8846\n",
      "Epoch 609/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8917 - Test Accuracy: 0.8833\n",
      "Epoch 610/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8915 - Test Accuracy: 0.8835\n",
      "Epoch 611/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8920 - Test Accuracy: 0.8834\n",
      "Epoch 612/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8923 - Test Accuracy: 0.8848\n",
      "Epoch 613/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8902 - Test Accuracy: 0.8819\n",
      "Epoch 614/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8912 - Test Accuracy: 0.8826\n",
      "Epoch 615/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8914 - Test Accuracy: 0.8835\n",
      "Epoch 616/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8922 - Test Accuracy: 0.8837\n",
      "Epoch 617/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8922 - Test Accuracy: 0.8843\n",
      "Epoch 618/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8911 - Test Accuracy: 0.8823\n",
      "Epoch 619/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8914 - Test Accuracy: 0.8834\n",
      "Epoch 620/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8920 - Test Accuracy: 0.8841\n",
      "Epoch 621/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8917 - Test Accuracy: 0.8835\n",
      "Epoch 622/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8917 - Test Accuracy: 0.8832\n",
      "Epoch 623/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8919 - Test Accuracy: 0.8843\n",
      "Epoch 624/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8906 - Test Accuracy: 0.8828\n",
      "Epoch 625/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8912 - Test Accuracy: 0.8828\n",
      "Epoch 626/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8918 - Test Accuracy: 0.8830\n",
      "Epoch 627/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8921 - Test Accuracy: 0.8842\n",
      "Epoch 628/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8911 - Test Accuracy: 0.8828\n",
      "Epoch 629/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8918 - Test Accuracy: 0.8843\n",
      "Epoch 630/2500 - Train Accuracy: 0.9590 - Val Accuracy: 0.8903 - Test Accuracy: 0.8821\n",
      "Epoch 631/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8917 - Test Accuracy: 0.8833\n",
      "Epoch 632/2500 - Train Accuracy: 0.9611 - Val Accuracy: 0.8922 - Test Accuracy: 0.8847\n",
      "Epoch 633/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8917 - Test Accuracy: 0.8833\n",
      "Epoch 634/2500 - Train Accuracy: 0.9592 - Val Accuracy: 0.8903 - Test Accuracy: 0.8823\n",
      "Epoch 635/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8917 - Test Accuracy: 0.8838\n",
      "Epoch 636/2500 - Train Accuracy: 0.9615 - Val Accuracy: 0.8934 - Test Accuracy: 0.8854\n",
      "Epoch 637/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8913 - Test Accuracy: 0.8831\n",
      "Epoch 638/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8907 - Test Accuracy: 0.8828\n",
      "Epoch 639/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8910 - Test Accuracy: 0.8824\n",
      "Epoch 640/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8911 - Test Accuracy: 0.8827\n",
      "Epoch 641/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8925 - Test Accuracy: 0.8844\n",
      "Epoch 642/2500 - Train Accuracy: 0.9614 - Val Accuracy: 0.8929 - Test Accuracy: 0.8854\n",
      "Epoch 643/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8918 - Test Accuracy: 0.8832\n",
      "Epoch 644/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8922 - Test Accuracy: 0.8836\n",
      "Epoch 645/2500 - Train Accuracy: 0.9593 - Val Accuracy: 0.8907 - Test Accuracy: 0.8833\n",
      "Epoch 646/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8919 - Test Accuracy: 0.8843\n",
      "Epoch 647/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8917 - Test Accuracy: 0.8845\n",
      "Epoch 648/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8916 - Test Accuracy: 0.8840\n",
      "Epoch 649/2500 - Train Accuracy: 0.9613 - Val Accuracy: 0.8927 - Test Accuracy: 0.8848\n",
      "Epoch 650/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8918 - Test Accuracy: 0.8834\n",
      "Epoch 651/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8916 - Test Accuracy: 0.8839\n",
      "Epoch 652/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8920 - Test Accuracy: 0.8835\n",
      "Epoch 653/2500 - Train Accuracy: 0.9606 - Val Accuracy: 0.8922 - Test Accuracy: 0.8845\n",
      "Epoch 654/2500 - Train Accuracy: 0.9611 - Val Accuracy: 0.8928 - Test Accuracy: 0.8851\n",
      "Epoch 655/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8916 - Test Accuracy: 0.8841\n",
      "Epoch 656/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8919 - Test Accuracy: 0.8835\n",
      "Epoch 657/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8912 - Test Accuracy: 0.8838\n",
      "Epoch 658/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8923 - Test Accuracy: 0.8844\n",
      "Epoch 659/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8918 - Test Accuracy: 0.8843\n",
      "Epoch 660/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8919 - Test Accuracy: 0.8831\n",
      "Epoch 661/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8922 - Test Accuracy: 0.8839\n",
      "Epoch 662/2500 - Train Accuracy: 0.9616 - Val Accuracy: 0.8933 - Test Accuracy: 0.8855\n",
      "Epoch 663/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8914 - Test Accuracy: 0.8826\n",
      "Epoch 664/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8922 - Test Accuracy: 0.8838\n",
      "Epoch 665/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8914 - Test Accuracy: 0.8837\n",
      "Epoch 666/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8917 - Test Accuracy: 0.8840\n",
      "Epoch 667/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8912 - Test Accuracy: 0.8831\n",
      "Epoch 668/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8917 - Test Accuracy: 0.8837\n",
      "Epoch 669/2500 - Train Accuracy: 0.9607 - Val Accuracy: 0.8928 - Test Accuracy: 0.8848\n",
      "Epoch 670/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.8912 - Test Accuracy: 0.8823\n",
      "Epoch 671/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8916 - Test Accuracy: 0.8836\n",
      "Epoch 672/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8907 - Test Accuracy: 0.8824\n",
      "Epoch 673/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8923 - Test Accuracy: 0.8843\n",
      "Epoch 674/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8931 - Test Accuracy: 0.8844\n",
      "Epoch 675/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8924 - Test Accuracy: 0.8849\n",
      "Epoch 676/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8920 - Test Accuracy: 0.8846\n",
      "Epoch 677/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8921 - Test Accuracy: 0.8841\n",
      "Epoch 678/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8919 - Test Accuracy: 0.8835\n",
      "Epoch 679/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8918 - Test Accuracy: 0.8834\n",
      "Epoch 680/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8917 - Test Accuracy: 0.8830\n",
      "Epoch 681/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8914 - Test Accuracy: 0.8829\n",
      "Epoch 682/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8926 - Test Accuracy: 0.8844\n",
      "Epoch 683/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8925 - Test Accuracy: 0.8848\n",
      "Epoch 684/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8914 - Test Accuracy: 0.8838\n",
      "Epoch 685/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8923 - Test Accuracy: 0.8842\n",
      "Epoch 686/2500 - Train Accuracy: 0.9596 - Val Accuracy: 0.8914 - Test Accuracy: 0.8831\n",
      "Epoch 687/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8910 - Test Accuracy: 0.8826\n",
      "Epoch 688/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8919 - Test Accuracy: 0.8836\n",
      "Epoch 689/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8912 - Test Accuracy: 0.8828\n",
      "Epoch 690/2500 - Train Accuracy: 0.9609 - Val Accuracy: 0.8922 - Test Accuracy: 0.8850\n",
      "Epoch 691/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8916 - Test Accuracy: 0.8834\n",
      "Epoch 692/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8924 - Test Accuracy: 0.8843\n",
      "Epoch 693/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8912 - Test Accuracy: 0.8836\n",
      "Epoch 694/2500 - Train Accuracy: 0.9600 - Val Accuracy: 0.8919 - Test Accuracy: 0.8832\n",
      "Epoch 695/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8919 - Test Accuracy: 0.8839\n",
      "Epoch 696/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8910 - Test Accuracy: 0.8834\n",
      "Epoch 697/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.8916 - Test Accuracy: 0.8830\n",
      "Epoch 698/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8921 - Test Accuracy: 0.8839\n",
      "Epoch 699/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8919 - Test Accuracy: 0.8841\n",
      "Epoch 700/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8915 - Test Accuracy: 0.8832\n",
      "Epoch 701/2500 - Train Accuracy: 0.9605 - Val Accuracy: 0.8924 - Test Accuracy: 0.8840\n",
      "Epoch 702/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.8918 - Test Accuracy: 0.8843\n",
      "Epoch 703/2500 - Train Accuracy: 0.9597 - Val Accuracy: 0.8910 - Test Accuracy: 0.8826\n",
      "Epoch 704/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8913 - Test Accuracy: 0.8834\n",
      "Epoch 705/2500 - Train Accuracy: 0.9592 - Val Accuracy: 0.8909 - Test Accuracy: 0.8821\n",
      "Epoch 706/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8920 - Test Accuracy: 0.8837\n",
      "Epoch 707/2500 - Train Accuracy: 0.9604 - Val Accuracy: 0.8922 - Test Accuracy: 0.8837\n",
      "Epoch 708/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8916 - Test Accuracy: 0.8834\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 166\u001b[0m\n\u001b[0;32m    162\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m    163\u001b[0m                                     decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, momentum\u001b[38;5;241m=\u001b[39mmomentum, nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    164\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 166\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 출력 숨기기\u001b[39;49;00m\n\u001b[0;32m    170\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEpochEndCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[14], line 50\u001b[0m, in \u001b[0;36mEpochEndCallback.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     48\u001b[0m train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data[\u001b[38;5;241m1\u001b[39m], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     49\u001b[0m val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data[\u001b[38;5;241m1\u001b[39m], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     53\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     54\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     55\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def normalization(train_images, test_images):\n",
    "    mean = np.mean(train_images, axis=(0, 1, 2, 3))\n",
    "    std = np.std(train_images, axis=(0, 1, 2, 3))\n",
    "    train_images = (train_images - mean) / (std + 1e-7)\n",
    "    test_images = (test_images - mean) / (std + 1e-7)\n",
    "    return train_images, test_images\n",
    "\n",
    "\n",
    "def load_images():\n",
    "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "    train_images = train_images.astype(np.float32)\n",
    "    test_images = test_images.astype(np.float32)\n",
    "\n",
    "    (train_images, test_images) = normalization(train_images, test_images)\n",
    "\n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "    # Randomly select 20% of the training data as validation data\n",
    "    validation_split = 0.2\n",
    "    split_index = int(train_images.shape[0] * (1 - validation_split))\n",
    "    train_images, val_images = train_images[:split_index], train_images[split_index:]\n",
    "    train_labels, val_labels = train_labels[:split_index], train_labels[split_index:]\n",
    "\n",
    "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
    "\n",
    "class EpochEndCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_data, val_data, test_data):\n",
    "        super(EpochEndCallback, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_loss, train_accuracy = self.model.evaluate(self.train_data[0], self.train_data[1], verbose=0)\n",
    "        val_loss, val_accuracy = self.model.evaluate(self.val_data[0], self.val_data[1], verbose=0)\n",
    "        test_loss, test_accuracy = self.model.evaluate(self.test_data[0], self.test_data[1], verbose=0)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{training_epochs} - '\n",
    "              f'Train Accuracy: {train_accuracy:.4f} - '\n",
    "              f'Val Accuracy: {val_accuracy:.4f} - '\n",
    "              f'Test Accuracy: {test_accuracy:.4f}')\n",
    "class ConvBNRelu(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size=3, strides=1, padding='SAME', weight_decay=0.0005, rate=0.4, drop=True):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.drop = drop\n",
    "        self.conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                                        padding=padding, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dropOut = keras.layers.Dropout(rate=rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        layer = self.conv(inputs)\n",
    "        layer = tf.nn.relu(layer)\n",
    "        layer = self.batchnorm(layer)\n",
    "        if self.drop:\n",
    "            layer = self.dropOut(layer)\n",
    "\n",
    "        return layer\n",
    "\n",
    "class VGG16Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16Model, self).__init__()\n",
    "        self.conv1 = ConvBNRelu(filters=64, kernel_size=[3, 3], rate=0.3)\n",
    "        self.conv2 = ConvBNRelu(filters=64, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling1 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv3 = ConvBNRelu(filters=128, kernel_size=[3, 3])\n",
    "        self.conv4 = ConvBNRelu(filters=128, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling2 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv5 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv6 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.maxPooling3 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv11 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv12 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.maxPooling5 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv14 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv15 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.maxPooling6 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flat = keras.layers.Flatten()\n",
    "        self.dropOut = keras.layers.Dropout(rate=0.5)\n",
    "        self.dense1 = keras.layers.Dense(units=512,\n",
    "                                         activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dense2 = keras.layers.Dense(units=10)\n",
    "        self.softmax = keras.layers.Activation('softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs, training=training)\n",
    "        net = self.conv2(net, training=training)\n",
    "        net = self.maxPooling1(net)\n",
    "        net = self.conv3(net, training=training)\n",
    "        net = self.conv4(net, training=training)\n",
    "        net = self.maxPooling2(net)\n",
    "        net = self.conv5(net, training=training)\n",
    "        net = self.conv6(net, training=training)\n",
    "        net = self.maxPooling3(net)\n",
    "        net = self.conv11(net, training=training)\n",
    "        net = self.conv12(net, training=training)\n",
    "        net = self.maxPooling5(net)\n",
    "        net = self.conv14(net, training=training)\n",
    "        net = self.conv15(net, training=training)\n",
    "        net = self.maxPooling6(net)\n",
    "        net = self.dropOut(net)\n",
    "        net = self.flat(net)\n",
    "        net = self.dense1(net)\n",
    "        net = self.batchnorm(net)\n",
    "        net = self.dense2(net)\n",
    "        net = self.softmax(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(tf.__version__)\n",
    "    print(keras.__version__)\n",
    "\n",
    "    training_epochs = 2500\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.9\n",
    "    lr_decay = 1e-6\n",
    "    lr_drop = 20\n",
    " \n",
    "    tf.random.set_seed(777)\n",
    "\n",
    "    def lr_scheduler(epoch):\n",
    "        return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "\n",
    "    reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    train_images, train_labels, val_images, val_labels, test_images, test_labels = load_images()\n",
    "\n",
    "    # data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model = VGG16Model()\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,\n",
    "                                        decay=1e-6, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.fit(datagen.flow(train_images, train_labels,\n",
    "                        batch_size=batch_size), \n",
    "          epochs=training_epochs, \n",
    "          verbose=0,  # 출력 숨기기\n",
    "          callbacks=[reduce_lr, EpochEndCallback((train_images, train_labels), (val_images, val_labels), (test_images, test_labels))],\n",
    "          steps_per_epoch=train_images.shape[0] // batch_size,\n",
    "          validation_data=(val_images, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cdb22b7-00c0-490e-8163-6b82a243f76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n",
      "2.10.0\n",
      "2.10.0\n",
      "Epoch 1/2500 - Train Accuracy: 0.1546 - Val Accuracy: 0.1582 - Test Accuracy: 0.1596\n",
      "Epoch 2/2500 - Train Accuracy: 0.2333 - Val Accuracy: 0.2271 - Test Accuracy: 0.2248\n",
      "Epoch 3/2500 - Train Accuracy: 0.2483 - Val Accuracy: 0.2398 - Test Accuracy: 0.2422\n",
      "Epoch 4/2500 - Train Accuracy: 0.3700 - Val Accuracy: 0.3744 - Test Accuracy: 0.3730\n",
      "Epoch 5/2500 - Train Accuracy: 0.3952 - Val Accuracy: 0.3952 - Test Accuracy: 0.3979\n",
      "Epoch 6/2500 - Train Accuracy: 0.5253 - Val Accuracy: 0.5183 - Test Accuracy: 0.5222\n",
      "Epoch 7/2500 - Train Accuracy: 0.1270 - Val Accuracy: 0.1291 - Test Accuracy: 0.1275\n",
      "Epoch 8/2500 - Train Accuracy: 0.6590 - Val Accuracy: 0.6550 - Test Accuracy: 0.6510\n",
      "Epoch 9/2500 - Train Accuracy: 0.6557 - Val Accuracy: 0.6526 - Test Accuracy: 0.6545\n",
      "Epoch 10/2500 - Train Accuracy: 0.7061 - Val Accuracy: 0.7016 - Test Accuracy: 0.6973\n",
      "Epoch 11/2500 - Train Accuracy: 0.6145 - Val Accuracy: 0.6052 - Test Accuracy: 0.6030\n",
      "Epoch 12/2500 - Train Accuracy: 0.6182 - Val Accuracy: 0.6088 - Test Accuracy: 0.6102\n",
      "Epoch 13/2500 - Train Accuracy: 0.2869 - Val Accuracy: 0.2826 - Test Accuracy: 0.2880\n",
      "Epoch 14/2500 - Train Accuracy: 0.6894 - Val Accuracy: 0.6816 - Test Accuracy: 0.6800\n",
      "Epoch 15/2500 - Train Accuracy: 0.6658 - Val Accuracy: 0.6585 - Test Accuracy: 0.6552\n",
      "Epoch 16/2500 - Train Accuracy: 0.6605 - Val Accuracy: 0.6556 - Test Accuracy: 0.6508\n",
      "Epoch 17/2500 - Train Accuracy: 0.1873 - Val Accuracy: 0.1917 - Test Accuracy: 0.1979\n",
      "Epoch 18/2500 - Train Accuracy: 0.1894 - Val Accuracy: 0.1853 - Test Accuracy: 0.1907\n",
      "Epoch 19/2500 - Train Accuracy: 0.2024 - Val Accuracy: 0.2013 - Test Accuracy: 0.2055\n",
      "Epoch 20/2500 - Train Accuracy: 0.1619 - Val Accuracy: 0.1631 - Test Accuracy: 0.1640\n",
      "Epoch 21/2500 - Train Accuracy: 0.5162 - Val Accuracy: 0.5048 - Test Accuracy: 0.5055\n",
      "Epoch 22/2500 - Train Accuracy: 0.5462 - Val Accuracy: 0.5412 - Test Accuracy: 0.5413\n",
      "Epoch 23/2500 - Train Accuracy: 0.5621 - Val Accuracy: 0.5584 - Test Accuracy: 0.5599\n",
      "Epoch 24/2500 - Train Accuracy: 0.6147 - Val Accuracy: 0.6000 - Test Accuracy: 0.5986\n",
      "Epoch 25/2500 - Train Accuracy: 0.6310 - Val Accuracy: 0.6164 - Test Accuracy: 0.6165\n",
      "Epoch 26/2500 - Train Accuracy: 0.7008 - Val Accuracy: 0.6894 - Test Accuracy: 0.6887\n",
      "Epoch 27/2500 - Train Accuracy: 0.7035 - Val Accuracy: 0.6990 - Test Accuracy: 0.6844\n",
      "Epoch 28/2500 - Train Accuracy: 0.6705 - Val Accuracy: 0.6603 - Test Accuracy: 0.6591\n",
      "Epoch 29/2500 - Train Accuracy: 0.4168 - Val Accuracy: 0.4224 - Test Accuracy: 0.4174\n",
      "Epoch 30/2500 - Train Accuracy: 0.6969 - Val Accuracy: 0.6907 - Test Accuracy: 0.6831\n",
      "Epoch 31/2500 - Train Accuracy: 0.7074 - Val Accuracy: 0.7028 - Test Accuracy: 0.6969\n",
      "Epoch 32/2500 - Train Accuracy: 0.7569 - Val Accuracy: 0.7457 - Test Accuracy: 0.7401\n",
      "Epoch 33/2500 - Train Accuracy: 0.7290 - Val Accuracy: 0.7169 - Test Accuracy: 0.7205\n",
      "Epoch 34/2500 - Train Accuracy: 0.7254 - Val Accuracy: 0.7186 - Test Accuracy: 0.7068\n",
      "Epoch 35/2500 - Train Accuracy: 0.7886 - Val Accuracy: 0.7746 - Test Accuracy: 0.7658\n",
      "Epoch 36/2500 - Train Accuracy: 0.7474 - Val Accuracy: 0.7376 - Test Accuracy: 0.7351\n",
      "Epoch 37/2500 - Train Accuracy: 0.7737 - Val Accuracy: 0.7534 - Test Accuracy: 0.7492\n",
      "Epoch 38/2500 - Train Accuracy: 0.7997 - Val Accuracy: 0.7871 - Test Accuracy: 0.7788\n",
      "Epoch 39/2500 - Train Accuracy: 0.7739 - Val Accuracy: 0.7552 - Test Accuracy: 0.7525\n",
      "Epoch 40/2500 - Train Accuracy: 0.7849 - Val Accuracy: 0.7691 - Test Accuracy: 0.7666\n",
      "Epoch 41/2500 - Train Accuracy: 0.8511 - Val Accuracy: 0.8249 - Test Accuracy: 0.8300\n",
      "Epoch 42/2500 - Train Accuracy: 0.8552 - Val Accuracy: 0.8280 - Test Accuracy: 0.8287\n",
      "Epoch 43/2500 - Train Accuracy: 0.8415 - Val Accuracy: 0.8171 - Test Accuracy: 0.8112\n",
      "Epoch 44/2500 - Train Accuracy: 0.8336 - Val Accuracy: 0.8090 - Test Accuracy: 0.8008\n",
      "Epoch 45/2500 - Train Accuracy: 0.8533 - Val Accuracy: 0.8310 - Test Accuracy: 0.8238\n",
      "Epoch 46/2500 - Train Accuracy: 0.8638 - Val Accuracy: 0.8411 - Test Accuracy: 0.8320\n",
      "Epoch 47/2500 - Train Accuracy: 0.8471 - Val Accuracy: 0.8270 - Test Accuracy: 0.8178\n",
      "Epoch 48/2500 - Train Accuracy: 0.8730 - Val Accuracy: 0.8462 - Test Accuracy: 0.8414\n",
      "Epoch 49/2500 - Train Accuracy: 0.8652 - Val Accuracy: 0.8334 - Test Accuracy: 0.8371\n",
      "Epoch 50/2500 - Train Accuracy: 0.8575 - Val Accuracy: 0.8316 - Test Accuracy: 0.8296\n",
      "Epoch 51/2500 - Train Accuracy: 0.8793 - Val Accuracy: 0.8512 - Test Accuracy: 0.8461\n",
      "Epoch 52/2500 - Train Accuracy: 0.8710 - Val Accuracy: 0.8439 - Test Accuracy: 0.8415\n",
      "Epoch 53/2500 - Train Accuracy: 0.8672 - Val Accuracy: 0.8336 - Test Accuracy: 0.8347\n",
      "Epoch 54/2500 - Train Accuracy: 0.8778 - Val Accuracy: 0.8477 - Test Accuracy: 0.8433\n",
      "Epoch 55/2500 - Train Accuracy: 0.8809 - Val Accuracy: 0.8474 - Test Accuracy: 0.8490\n",
      "Epoch 56/2500 - Train Accuracy: 0.8749 - Val Accuracy: 0.8450 - Test Accuracy: 0.8412\n",
      "Epoch 57/2500 - Train Accuracy: 0.8640 - Val Accuracy: 0.8272 - Test Accuracy: 0.8280\n",
      "Epoch 58/2500 - Train Accuracy: 0.8842 - Val Accuracy: 0.8527 - Test Accuracy: 0.8487\n",
      "Epoch 59/2500 - Train Accuracy: 0.8763 - Val Accuracy: 0.8473 - Test Accuracy: 0.8418\n",
      "Epoch 60/2500 - Train Accuracy: 0.8728 - Val Accuracy: 0.8408 - Test Accuracy: 0.8351\n",
      "Epoch 61/2500 - Train Accuracy: 0.9079 - Val Accuracy: 0.8719 - Test Accuracy: 0.8634\n",
      "Epoch 62/2500 - Train Accuracy: 0.9137 - Val Accuracy: 0.8731 - Test Accuracy: 0.8703\n",
      "Epoch 63/2500 - Train Accuracy: 0.9212 - Val Accuracy: 0.8820 - Test Accuracy: 0.8771\n",
      "Epoch 64/2500 - Train Accuracy: 0.9101 - Val Accuracy: 0.8682 - Test Accuracy: 0.8634\n",
      "Epoch 65/2500 - Train Accuracy: 0.9263 - Val Accuracy: 0.8841 - Test Accuracy: 0.8768\n",
      "Epoch 66/2500 - Train Accuracy: 0.9275 - Val Accuracy: 0.8832 - Test Accuracy: 0.8724\n",
      "Epoch 67/2500 - Train Accuracy: 0.9163 - Val Accuracy: 0.8770 - Test Accuracy: 0.8734\n",
      "Epoch 68/2500 - Train Accuracy: 0.9233 - Val Accuracy: 0.8798 - Test Accuracy: 0.8739\n",
      "Epoch 69/2500 - Train Accuracy: 0.9151 - Val Accuracy: 0.8682 - Test Accuracy: 0.8648\n",
      "Epoch 70/2500 - Train Accuracy: 0.9286 - Val Accuracy: 0.8813 - Test Accuracy: 0.8761\n",
      "Epoch 71/2500 - Train Accuracy: 0.9222 - Val Accuracy: 0.8730 - Test Accuracy: 0.8680\n",
      "Epoch 72/2500 - Train Accuracy: 0.9202 - Val Accuracy: 0.8795 - Test Accuracy: 0.8680\n",
      "Epoch 73/2500 - Train Accuracy: 0.9256 - Val Accuracy: 0.8784 - Test Accuracy: 0.8723\n",
      "Epoch 74/2500 - Train Accuracy: 0.9290 - Val Accuracy: 0.8839 - Test Accuracy: 0.8717\n",
      "Epoch 75/2500 - Train Accuracy: 0.9133 - Val Accuracy: 0.8712 - Test Accuracy: 0.8628\n",
      "Epoch 76/2500 - Train Accuracy: 0.9362 - Val Accuracy: 0.8906 - Test Accuracy: 0.8856\n",
      "Epoch 77/2500 - Train Accuracy: 0.9191 - Val Accuracy: 0.8786 - Test Accuracy: 0.8646\n",
      "Epoch 78/2500 - Train Accuracy: 0.9220 - Val Accuracy: 0.8788 - Test Accuracy: 0.8685\n",
      "Epoch 79/2500 - Train Accuracy: 0.9372 - Val Accuracy: 0.8873 - Test Accuracy: 0.8808\n",
      "Epoch 80/2500 - Train Accuracy: 0.9372 - Val Accuracy: 0.8872 - Test Accuracy: 0.8862\n",
      "Epoch 81/2500 - Train Accuracy: 0.9406 - Val Accuracy: 0.8862 - Test Accuracy: 0.8794\n",
      "Epoch 82/2500 - Train Accuracy: 0.9505 - Val Accuracy: 0.8977 - Test Accuracy: 0.8931\n",
      "Epoch 83/2500 - Train Accuracy: 0.9534 - Val Accuracy: 0.8977 - Test Accuracy: 0.8904\n",
      "Epoch 84/2500 - Train Accuracy: 0.9587 - Val Accuracy: 0.9016 - Test Accuracy: 0.8957\n",
      "Epoch 85/2500 - Train Accuracy: 0.9582 - Val Accuracy: 0.8971 - Test Accuracy: 0.8908\n",
      "Epoch 86/2500 - Train Accuracy: 0.9475 - Val Accuracy: 0.8888 - Test Accuracy: 0.8821\n",
      "Epoch 87/2500 - Train Accuracy: 0.9594 - Val Accuracy: 0.8973 - Test Accuracy: 0.8934\n",
      "Epoch 88/2500 - Train Accuracy: 0.9670 - Val Accuracy: 0.9046 - Test Accuracy: 0.9011\n",
      "Epoch 89/2500 - Train Accuracy: 0.9602 - Val Accuracy: 0.8961 - Test Accuracy: 0.8949\n",
      "Epoch 90/2500 - Train Accuracy: 0.9562 - Val Accuracy: 0.8955 - Test Accuracy: 0.8887\n",
      "Epoch 91/2500 - Train Accuracy: 0.9505 - Val Accuracy: 0.8895 - Test Accuracy: 0.8838\n",
      "Epoch 92/2500 - Train Accuracy: 0.9598 - Val Accuracy: 0.8992 - Test Accuracy: 0.8915\n",
      "Epoch 93/2500 - Train Accuracy: 0.9561 - Val Accuracy: 0.8936 - Test Accuracy: 0.8905\n",
      "Epoch 94/2500 - Train Accuracy: 0.9587 - Val Accuracy: 0.8971 - Test Accuracy: 0.8904\n",
      "Epoch 95/2500 - Train Accuracy: 0.9608 - Val Accuracy: 0.8969 - Test Accuracy: 0.8916\n",
      "Epoch 96/2500 - Train Accuracy: 0.9550 - Val Accuracy: 0.8942 - Test Accuracy: 0.8853\n",
      "Epoch 97/2500 - Train Accuracy: 0.9601 - Val Accuracy: 0.8968 - Test Accuracy: 0.8929\n",
      "Epoch 98/2500 - Train Accuracy: 0.9664 - Val Accuracy: 0.9033 - Test Accuracy: 0.8940\n",
      "Epoch 99/2500 - Train Accuracy: 0.9625 - Val Accuracy: 0.8995 - Test Accuracy: 0.8943\n",
      "Epoch 100/2500 - Train Accuracy: 0.9577 - Val Accuracy: 0.8981 - Test Accuracy: 0.8918\n",
      "Epoch 101/2500 - Train Accuracy: 0.9731 - Val Accuracy: 0.9103 - Test Accuracy: 0.9040\n",
      "Epoch 102/2500 - Train Accuracy: 0.9713 - Val Accuracy: 0.9061 - Test Accuracy: 0.9021\n",
      "Epoch 103/2500 - Train Accuracy: 0.9733 - Val Accuracy: 0.9094 - Test Accuracy: 0.9015\n",
      "Epoch 104/2500 - Train Accuracy: 0.9798 - Val Accuracy: 0.9141 - Test Accuracy: 0.9071\n",
      "Epoch 105/2500 - Train Accuracy: 0.9781 - Val Accuracy: 0.9122 - Test Accuracy: 0.9036\n",
      "Epoch 106/2500 - Train Accuracy: 0.9750 - Val Accuracy: 0.9080 - Test Accuracy: 0.9026\n",
      "Epoch 107/2500 - Train Accuracy: 0.9783 - Val Accuracy: 0.9093 - Test Accuracy: 0.9029\n",
      "Epoch 108/2500 - Train Accuracy: 0.9792 - Val Accuracy: 0.9098 - Test Accuracy: 0.9026\n",
      "Epoch 109/2500 - Train Accuracy: 0.9720 - Val Accuracy: 0.9032 - Test Accuracy: 0.8962\n",
      "Epoch 110/2500 - Train Accuracy: 0.9753 - Val Accuracy: 0.9048 - Test Accuracy: 0.9020\n",
      "Epoch 111/2500 - Train Accuracy: 0.9823 - Val Accuracy: 0.9122 - Test Accuracy: 0.9078\n",
      "Epoch 112/2500 - Train Accuracy: 0.9776 - Val Accuracy: 0.9053 - Test Accuracy: 0.9014\n",
      "Epoch 113/2500 - Train Accuracy: 0.9793 - Val Accuracy: 0.9063 - Test Accuracy: 0.9006\n",
      "Epoch 114/2500 - Train Accuracy: 0.9822 - Val Accuracy: 0.9096 - Test Accuracy: 0.9038\n",
      "Epoch 115/2500 - Train Accuracy: 0.9790 - Val Accuracy: 0.9090 - Test Accuracy: 0.9029\n",
      "Epoch 116/2500 - Train Accuracy: 0.9806 - Val Accuracy: 0.9117 - Test Accuracy: 0.9016\n",
      "Epoch 117/2500 - Train Accuracy: 0.9841 - Val Accuracy: 0.9131 - Test Accuracy: 0.9051\n",
      "Epoch 118/2500 - Train Accuracy: 0.9679 - Val Accuracy: 0.8980 - Test Accuracy: 0.8951\n",
      "Epoch 119/2500 - Train Accuracy: 0.9850 - Val Accuracy: 0.9143 - Test Accuracy: 0.9068\n",
      "Epoch 120/2500 - Train Accuracy: 0.9812 - Val Accuracy: 0.9085 - Test Accuracy: 0.9040\n",
      "Epoch 121/2500 - Train Accuracy: 0.9876 - Val Accuracy: 0.9152 - Test Accuracy: 0.9089\n",
      "Epoch 122/2500 - Train Accuracy: 0.9892 - Val Accuracy: 0.9185 - Test Accuracy: 0.9122\n",
      "Epoch 123/2500 - Train Accuracy: 0.9872 - Val Accuracy: 0.9156 - Test Accuracy: 0.9074\n",
      "Epoch 124/2500 - Train Accuracy: 0.9840 - Val Accuracy: 0.9111 - Test Accuracy: 0.9046\n",
      "Epoch 125/2500 - Train Accuracy: 0.9875 - Val Accuracy: 0.9150 - Test Accuracy: 0.9074\n",
      "Epoch 126/2500 - Train Accuracy: 0.9880 - Val Accuracy: 0.9182 - Test Accuracy: 0.9066\n",
      "Epoch 127/2500 - Train Accuracy: 0.9913 - Val Accuracy: 0.9205 - Test Accuracy: 0.9101\n",
      "Epoch 128/2500 - Train Accuracy: 0.9893 - Val Accuracy: 0.9146 - Test Accuracy: 0.9096\n",
      "Epoch 129/2500 - Train Accuracy: 0.9901 - Val Accuracy: 0.9159 - Test Accuracy: 0.9089\n",
      "Epoch 130/2500 - Train Accuracy: 0.9888 - Val Accuracy: 0.9146 - Test Accuracy: 0.9093\n",
      "Epoch 131/2500 - Train Accuracy: 0.9914 - Val Accuracy: 0.9191 - Test Accuracy: 0.9105\n",
      "Epoch 132/2500 - Train Accuracy: 0.9862 - Val Accuracy: 0.9095 - Test Accuracy: 0.9018\n",
      "Epoch 133/2500 - Train Accuracy: 0.9893 - Val Accuracy: 0.9163 - Test Accuracy: 0.9091\n",
      "Epoch 134/2500 - Train Accuracy: 0.9896 - Val Accuracy: 0.9141 - Test Accuracy: 0.9094\n",
      "Epoch 135/2500 - Train Accuracy: 0.9862 - Val Accuracy: 0.9122 - Test Accuracy: 0.9053\n",
      "Epoch 136/2500 - Train Accuracy: 0.9927 - Val Accuracy: 0.9209 - Test Accuracy: 0.9117\n",
      "Epoch 137/2500 - Train Accuracy: 0.9909 - Val Accuracy: 0.9176 - Test Accuracy: 0.9115\n",
      "Epoch 138/2500 - Train Accuracy: 0.9920 - Val Accuracy: 0.9192 - Test Accuracy: 0.9091\n",
      "Epoch 139/2500 - Train Accuracy: 0.9916 - Val Accuracy: 0.9170 - Test Accuracy: 0.9084\n",
      "Epoch 140/2500 - Train Accuracy: 0.9906 - Val Accuracy: 0.9161 - Test Accuracy: 0.9106\n",
      "Epoch 141/2500 - Train Accuracy: 0.9910 - Val Accuracy: 0.9146 - Test Accuracy: 0.9122\n",
      "Epoch 142/2500 - Train Accuracy: 0.9932 - Val Accuracy: 0.9192 - Test Accuracy: 0.9146\n",
      "Epoch 143/2500 - Train Accuracy: 0.9910 - Val Accuracy: 0.9157 - Test Accuracy: 0.9098\n",
      "Epoch 144/2500 - Train Accuracy: 0.9908 - Val Accuracy: 0.9150 - Test Accuracy: 0.9100\n",
      "Epoch 145/2500 - Train Accuracy: 0.9938 - Val Accuracy: 0.9181 - Test Accuracy: 0.9155\n",
      "Epoch 146/2500 - Train Accuracy: 0.9938 - Val Accuracy: 0.9202 - Test Accuracy: 0.9152\n",
      "Epoch 147/2500 - Train Accuracy: 0.9932 - Val Accuracy: 0.9210 - Test Accuracy: 0.9143\n",
      "Epoch 148/2500 - Train Accuracy: 0.9934 - Val Accuracy: 0.9209 - Test Accuracy: 0.9162\n",
      "Epoch 149/2500 - Train Accuracy: 0.9925 - Val Accuracy: 0.9196 - Test Accuracy: 0.9140\n",
      "Epoch 150/2500 - Train Accuracy: 0.9936 - Val Accuracy: 0.9206 - Test Accuracy: 0.9139\n",
      "Epoch 151/2500 - Train Accuracy: 0.9930 - Val Accuracy: 0.9205 - Test Accuracy: 0.9140\n",
      "Epoch 152/2500 - Train Accuracy: 0.9950 - Val Accuracy: 0.9224 - Test Accuracy: 0.9138\n",
      "Epoch 153/2500 - Train Accuracy: 0.9919 - Val Accuracy: 0.9166 - Test Accuracy: 0.9124\n",
      "Epoch 154/2500 - Train Accuracy: 0.9940 - Val Accuracy: 0.9175 - Test Accuracy: 0.9124\n",
      "Epoch 155/2500 - Train Accuracy: 0.9929 - Val Accuracy: 0.9166 - Test Accuracy: 0.9095\n",
      "Epoch 156/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9242 - Test Accuracy: 0.9166\n",
      "Epoch 157/2500 - Train Accuracy: 0.9955 - Val Accuracy: 0.9216 - Test Accuracy: 0.9155\n",
      "Epoch 158/2500 - Train Accuracy: 0.9949 - Val Accuracy: 0.9210 - Test Accuracy: 0.9127\n",
      "Epoch 159/2500 - Train Accuracy: 0.9943 - Val Accuracy: 0.9197 - Test Accuracy: 0.9153\n",
      "Epoch 160/2500 - Train Accuracy: 0.9948 - Val Accuracy: 0.9225 - Test Accuracy: 0.9163\n",
      "Epoch 161/2500 - Train Accuracy: 0.9929 - Val Accuracy: 0.9188 - Test Accuracy: 0.9136\n",
      "Epoch 162/2500 - Train Accuracy: 0.9948 - Val Accuracy: 0.9207 - Test Accuracy: 0.9154\n",
      "Epoch 163/2500 - Train Accuracy: 0.9961 - Val Accuracy: 0.9251 - Test Accuracy: 0.9170\n",
      "Epoch 164/2500 - Train Accuracy: 0.9952 - Val Accuracy: 0.9198 - Test Accuracy: 0.9133\n",
      "Epoch 165/2500 - Train Accuracy: 0.9949 - Val Accuracy: 0.9209 - Test Accuracy: 0.9135\n",
      "Epoch 166/2500 - Train Accuracy: 0.9944 - Val Accuracy: 0.9211 - Test Accuracy: 0.9130\n",
      "Epoch 167/2500 - Train Accuracy: 0.9957 - Val Accuracy: 0.9220 - Test Accuracy: 0.9136\n",
      "Epoch 168/2500 - Train Accuracy: 0.9958 - Val Accuracy: 0.9221 - Test Accuracy: 0.9138\n",
      "Epoch 169/2500 - Train Accuracy: 0.9945 - Val Accuracy: 0.9195 - Test Accuracy: 0.9124\n",
      "Epoch 170/2500 - Train Accuracy: 0.9930 - Val Accuracy: 0.9174 - Test Accuracy: 0.9112\n",
      "Epoch 171/2500 - Train Accuracy: 0.9956 - Val Accuracy: 0.9214 - Test Accuracy: 0.9126\n",
      "Epoch 172/2500 - Train Accuracy: 0.9960 - Val Accuracy: 0.9207 - Test Accuracy: 0.9151\n",
      "Epoch 173/2500 - Train Accuracy: 0.9955 - Val Accuracy: 0.9220 - Test Accuracy: 0.9146\n",
      "Epoch 174/2500 - Train Accuracy: 0.9957 - Val Accuracy: 0.9215 - Test Accuracy: 0.9123\n",
      "Epoch 175/2500 - Train Accuracy: 0.9948 - Val Accuracy: 0.9211 - Test Accuracy: 0.9117\n",
      "Epoch 176/2500 - Train Accuracy: 0.9955 - Val Accuracy: 0.9212 - Test Accuracy: 0.9126\n",
      "Epoch 177/2500 - Train Accuracy: 0.9951 - Val Accuracy: 0.9200 - Test Accuracy: 0.9126\n",
      "Epoch 178/2500 - Train Accuracy: 0.9945 - Val Accuracy: 0.9194 - Test Accuracy: 0.9110\n",
      "Epoch 179/2500 - Train Accuracy: 0.9955 - Val Accuracy: 0.9210 - Test Accuracy: 0.9125\n",
      "Epoch 180/2500 - Train Accuracy: 0.9962 - Val Accuracy: 0.9216 - Test Accuracy: 0.9148\n",
      "Epoch 181/2500 - Train Accuracy: 0.9957 - Val Accuracy: 0.9199 - Test Accuracy: 0.9143\n",
      "Epoch 182/2500 - Train Accuracy: 0.9961 - Val Accuracy: 0.9210 - Test Accuracy: 0.9140\n",
      "Epoch 183/2500 - Train Accuracy: 0.9964 - Val Accuracy: 0.9223 - Test Accuracy: 0.9152\n",
      "Epoch 184/2500 - Train Accuracy: 0.9962 - Val Accuracy: 0.9215 - Test Accuracy: 0.9155\n",
      "Epoch 185/2500 - Train Accuracy: 0.9958 - Val Accuracy: 0.9201 - Test Accuracy: 0.9131\n",
      "Epoch 186/2500 - Train Accuracy: 0.9962 - Val Accuracy: 0.9214 - Test Accuracy: 0.9138\n",
      "Epoch 187/2500 - Train Accuracy: 0.9965 - Val Accuracy: 0.9226 - Test Accuracy: 0.9144\n",
      "Epoch 188/2500 - Train Accuracy: 0.9960 - Val Accuracy: 0.9216 - Test Accuracy: 0.9144\n",
      "Epoch 189/2500 - Train Accuracy: 0.9959 - Val Accuracy: 0.9224 - Test Accuracy: 0.9143\n",
      "Epoch 190/2500 - Train Accuracy: 0.9963 - Val Accuracy: 0.9228 - Test Accuracy: 0.9152\n",
      "Epoch 191/2500 - Train Accuracy: 0.9962 - Val Accuracy: 0.9238 - Test Accuracy: 0.9159\n",
      "Epoch 192/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9217 - Test Accuracy: 0.9157\n",
      "Epoch 193/2500 - Train Accuracy: 0.9962 - Val Accuracy: 0.9214 - Test Accuracy: 0.9154\n",
      "Epoch 194/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9233 - Test Accuracy: 0.9156\n",
      "Epoch 195/2500 - Train Accuracy: 0.9962 - Val Accuracy: 0.9216 - Test Accuracy: 0.9130\n",
      "Epoch 196/2500 - Train Accuracy: 0.9963 - Val Accuracy: 0.9217 - Test Accuracy: 0.9148\n",
      "Epoch 197/2500 - Train Accuracy: 0.9956 - Val Accuracy: 0.9197 - Test Accuracy: 0.9124\n",
      "Epoch 198/2500 - Train Accuracy: 0.9971 - Val Accuracy: 0.9227 - Test Accuracy: 0.9151\n",
      "Epoch 199/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9156\n",
      "Epoch 200/2500 - Train Accuracy: 0.9962 - Val Accuracy: 0.9208 - Test Accuracy: 0.9142\n",
      "Epoch 201/2500 - Train Accuracy: 0.9960 - Val Accuracy: 0.9204 - Test Accuracy: 0.9138\n",
      "Epoch 202/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9217 - Test Accuracy: 0.9155\n",
      "Epoch 203/2500 - Train Accuracy: 0.9965 - Val Accuracy: 0.9216 - Test Accuracy: 0.9147\n",
      "Epoch 204/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9220 - Test Accuracy: 0.9145\n",
      "Epoch 205/2500 - Train Accuracy: 0.9967 - Val Accuracy: 0.9224 - Test Accuracy: 0.9159\n",
      "Epoch 206/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9220 - Test Accuracy: 0.9144\n",
      "Epoch 207/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9226 - Test Accuracy: 0.9162\n",
      "Epoch 208/2500 - Train Accuracy: 0.9965 - Val Accuracy: 0.9207 - Test Accuracy: 0.9143\n",
      "Epoch 209/2500 - Train Accuracy: 0.9965 - Val Accuracy: 0.9216 - Test Accuracy: 0.9145\n",
      "Epoch 210/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9224 - Test Accuracy: 0.9143\n",
      "Epoch 211/2500 - Train Accuracy: 0.9965 - Val Accuracy: 0.9214 - Test Accuracy: 0.9160\n",
      "Epoch 212/2500 - Train Accuracy: 0.9963 - Val Accuracy: 0.9211 - Test Accuracy: 0.9144\n",
      "Epoch 213/2500 - Train Accuracy: 0.9964 - Val Accuracy: 0.9222 - Test Accuracy: 0.9147\n",
      "Epoch 214/2500 - Train Accuracy: 0.9963 - Val Accuracy: 0.9217 - Test Accuracy: 0.9151\n",
      "Epoch 215/2500 - Train Accuracy: 0.9964 - Val Accuracy: 0.9219 - Test Accuracy: 0.9163\n",
      "Epoch 216/2500 - Train Accuracy: 0.9965 - Val Accuracy: 0.9221 - Test Accuracy: 0.9159\n",
      "Epoch 217/2500 - Train Accuracy: 0.9964 - Val Accuracy: 0.9220 - Test Accuracy: 0.9154\n",
      "Epoch 218/2500 - Train Accuracy: 0.9965 - Val Accuracy: 0.9214 - Test Accuracy: 0.9149\n",
      "Epoch 219/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9220 - Test Accuracy: 0.9150\n",
      "Epoch 220/2500 - Train Accuracy: 0.9964 - Val Accuracy: 0.9217 - Test Accuracy: 0.9148\n",
      "Epoch 221/2500 - Train Accuracy: 0.9961 - Val Accuracy: 0.9220 - Test Accuracy: 0.9147\n",
      "Epoch 222/2500 - Train Accuracy: 0.9962 - Val Accuracy: 0.9216 - Test Accuracy: 0.9162\n",
      "Epoch 223/2500 - Train Accuracy: 0.9964 - Val Accuracy: 0.9217 - Test Accuracy: 0.9158\n",
      "Epoch 224/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9165\n",
      "Epoch 225/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9217 - Test Accuracy: 0.9162\n",
      "Epoch 226/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9217 - Test Accuracy: 0.9162\n",
      "Epoch 227/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9220 - Test Accuracy: 0.9160\n",
      "Epoch 228/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9159\n",
      "Epoch 229/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9219 - Test Accuracy: 0.9158\n",
      "Epoch 230/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9227 - Test Accuracy: 0.9166\n",
      "Epoch 231/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9211 - Test Accuracy: 0.9159\n",
      "Epoch 232/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9173\n",
      "Epoch 233/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9210 - Test Accuracy: 0.9173\n",
      "Epoch 234/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9209 - Test Accuracy: 0.9159\n",
      "Epoch 235/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9208 - Test Accuracy: 0.9160\n",
      "Epoch 236/2500 - Train Accuracy: 0.9967 - Val Accuracy: 0.9218 - Test Accuracy: 0.9164\n",
      "Epoch 237/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9217 - Test Accuracy: 0.9167\n",
      "Epoch 238/2500 - Train Accuracy: 0.9967 - Val Accuracy: 0.9208 - Test Accuracy: 0.9165\n",
      "Epoch 239/2500 - Train Accuracy: 0.9966 - Val Accuracy: 0.9209 - Test Accuracy: 0.9159\n",
      "Epoch 240/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9198 - Test Accuracy: 0.9152\n",
      "Epoch 241/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9200 - Test Accuracy: 0.9152\n",
      "Epoch 242/2500 - Train Accuracy: 0.9967 - Val Accuracy: 0.9202 - Test Accuracy: 0.9152\n",
      "Epoch 243/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9210 - Test Accuracy: 0.9153\n",
      "Epoch 244/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9212 - Test Accuracy: 0.9156\n",
      "Epoch 245/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9211 - Test Accuracy: 0.9156\n",
      "Epoch 246/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9157\n",
      "Epoch 247/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9217 - Test Accuracy: 0.9155\n",
      "Epoch 248/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9152\n",
      "Epoch 249/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9155\n",
      "Epoch 250/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9154\n",
      "Epoch 251/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9215 - Test Accuracy: 0.9156\n",
      "Epoch 252/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9205 - Test Accuracy: 0.9160\n",
      "Epoch 253/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9218 - Test Accuracy: 0.9158\n",
      "Epoch 254/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9215 - Test Accuracy: 0.9159\n",
      "Epoch 255/2500 - Train Accuracy: 0.9972 - Val Accuracy: 0.9220 - Test Accuracy: 0.9163\n",
      "Epoch 256/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9157\n",
      "Epoch 257/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9221 - Test Accuracy: 0.9153\n",
      "Epoch 258/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9218 - Test Accuracy: 0.9148\n",
      "Epoch 259/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9150\n",
      "Epoch 260/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9225 - Test Accuracy: 0.9144\n",
      "Epoch 261/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9231 - Test Accuracy: 0.9151\n",
      "Epoch 262/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9223 - Test Accuracy: 0.9148\n",
      "Epoch 263/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9224 - Test Accuracy: 0.9157\n",
      "Epoch 264/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9226 - Test Accuracy: 0.9153\n",
      "Epoch 265/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9226 - Test Accuracy: 0.9151\n",
      "Epoch 266/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9151\n",
      "Epoch 267/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9154\n",
      "Epoch 268/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9223 - Test Accuracy: 0.9155\n",
      "Epoch 269/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9225 - Test Accuracy: 0.9152\n",
      "Epoch 270/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9154\n",
      "Epoch 271/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9230 - Test Accuracy: 0.9148\n",
      "Epoch 272/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9148\n",
      "Epoch 273/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9225 - Test Accuracy: 0.9152\n",
      "Epoch 274/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9223 - Test Accuracy: 0.9150\n",
      "Epoch 275/2500 - Train Accuracy: 0.9967 - Val Accuracy: 0.9218 - Test Accuracy: 0.9151\n",
      "Epoch 276/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9156\n",
      "Epoch 277/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9221 - Test Accuracy: 0.9151\n",
      "Epoch 278/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9221 - Test Accuracy: 0.9157\n",
      "Epoch 279/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9157\n",
      "Epoch 280/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9224 - Test Accuracy: 0.9159\n",
      "Epoch 281/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9221 - Test Accuracy: 0.9159\n",
      "Epoch 282/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9154\n",
      "Epoch 283/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9227 - Test Accuracy: 0.9155\n",
      "Epoch 284/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9154\n",
      "Epoch 285/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9152\n",
      "Epoch 286/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9150\n",
      "Epoch 287/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9152\n",
      "Epoch 288/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9221 - Test Accuracy: 0.9153\n",
      "Epoch 289/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9224 - Test Accuracy: 0.9151\n",
      "Epoch 290/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9148\n",
      "Epoch 291/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9157\n",
      "Epoch 292/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9160\n",
      "Epoch 293/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9155\n",
      "Epoch 294/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9221 - Test Accuracy: 0.9154\n",
      "Epoch 295/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9153\n",
      "Epoch 296/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9154\n",
      "Epoch 297/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9154\n",
      "Epoch 298/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9157\n",
      "Epoch 299/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9155\n",
      "Epoch 300/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9222 - Test Accuracy: 0.9150\n",
      "Epoch 301/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9156\n",
      "Epoch 302/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9155\n",
      "Epoch 303/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9153\n",
      "Epoch 304/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9148\n",
      "Epoch 305/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9154\n",
      "Epoch 306/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9153\n",
      "Epoch 307/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9154\n",
      "Epoch 308/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9150\n",
      "Epoch 309/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9216 - Test Accuracy: 0.9154\n",
      "Epoch 310/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9154\n",
      "Epoch 311/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9156\n",
      "Epoch 312/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9155\n",
      "Epoch 313/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9157\n",
      "Epoch 314/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9156\n",
      "Epoch 315/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9156\n",
      "Epoch 316/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9151\n",
      "Epoch 317/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9155\n",
      "Epoch 318/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9157\n",
      "Epoch 319/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9152\n",
      "Epoch 320/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9155\n",
      "Epoch 321/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9154\n",
      "Epoch 322/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9217 - Test Accuracy: 0.9152\n",
      "Epoch 323/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9214 - Test Accuracy: 0.9151\n",
      "Epoch 324/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9214 - Test Accuracy: 0.9152\n",
      "Epoch 325/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9226 - Test Accuracy: 0.9152\n",
      "Epoch 326/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9217 - Test Accuracy: 0.9153\n",
      "Epoch 327/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9214 - Test Accuracy: 0.9155\n",
      "Epoch 328/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9150\n",
      "Epoch 329/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9153\n",
      "Epoch 330/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9154\n",
      "Epoch 331/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9217 - Test Accuracy: 0.9154\n",
      "Epoch 332/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9151\n",
      "Epoch 333/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9224 - Test Accuracy: 0.9155\n",
      "Epoch 334/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9151\n",
      "Epoch 335/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9149\n",
      "Epoch 336/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9153\n",
      "Epoch 337/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9224 - Test Accuracy: 0.9153\n",
      "Epoch 338/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9152\n",
      "Epoch 339/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9151\n",
      "Epoch 340/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9224 - Test Accuracy: 0.9156\n",
      "Epoch 341/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9217 - Test Accuracy: 0.9151\n",
      "Epoch 342/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9153\n",
      "Epoch 343/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9153\n",
      "Epoch 344/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9151\n",
      "Epoch 345/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9222 - Test Accuracy: 0.9155\n",
      "Epoch 346/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9212 - Test Accuracy: 0.9155\n",
      "Epoch 347/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9151\n",
      "Epoch 348/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9214 - Test Accuracy: 0.9152\n",
      "Epoch 349/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9151\n",
      "Epoch 350/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9150\n",
      "Epoch 351/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9219 - Test Accuracy: 0.9156\n",
      "Epoch 352/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9216 - Test Accuracy: 0.9154\n",
      "Epoch 353/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9150\n",
      "Epoch 354/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9151\n",
      "Epoch 355/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9151\n",
      "Epoch 356/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9152\n",
      "Epoch 357/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9151\n",
      "Epoch 358/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9151\n",
      "Epoch 359/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9216 - Test Accuracy: 0.9153\n",
      "Epoch 360/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9223 - Test Accuracy: 0.9157\n",
      "Epoch 361/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9151\n",
      "Epoch 362/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9214 - Test Accuracy: 0.9147\n",
      "Epoch 363/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9213 - Test Accuracy: 0.9151\n",
      "Epoch 364/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9152\n",
      "Epoch 365/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9152\n",
      "Epoch 366/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9152\n",
      "Epoch 367/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9151\n",
      "Epoch 368/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9153\n",
      "Epoch 369/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9152\n",
      "Epoch 370/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9146\n",
      "Epoch 371/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9153\n",
      "Epoch 372/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9150\n",
      "Epoch 373/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9149\n",
      "Epoch 374/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9151\n",
      "Epoch 375/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9152\n",
      "Epoch 376/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9155\n",
      "Epoch 377/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9151\n",
      "Epoch 378/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9150\n",
      "Epoch 379/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9223 - Test Accuracy: 0.9151\n",
      "Epoch 380/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9148\n",
      "Epoch 381/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9148\n",
      "Epoch 382/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9151\n",
      "Epoch 383/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9152\n",
      "Epoch 384/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9214 - Test Accuracy: 0.9149\n",
      "Epoch 385/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9218 - Test Accuracy: 0.9152\n",
      "Epoch 386/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9223 - Test Accuracy: 0.9154\n",
      "Epoch 387/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9211 - Test Accuracy: 0.9151\n",
      "Epoch 388/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9154\n",
      "Epoch 389/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9154\n",
      "Epoch 390/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9156\n",
      "Epoch 391/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9218 - Test Accuracy: 0.9156\n",
      "Epoch 392/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9152\n",
      "Epoch 393/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9152\n",
      "Epoch 394/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9154\n",
      "Epoch 395/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9222 - Test Accuracy: 0.9150\n",
      "Epoch 396/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9150\n",
      "Epoch 397/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9152\n",
      "Epoch 398/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9217 - Test Accuracy: 0.9151\n",
      "Epoch 399/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9151\n",
      "Epoch 400/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9152\n",
      "Epoch 401/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9220 - Test Accuracy: 0.9160\n",
      "Epoch 402/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9150\n",
      "Epoch 403/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9154\n",
      "Epoch 404/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9155\n",
      "Epoch 405/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9152\n",
      "Epoch 406/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9150\n",
      "Epoch 407/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9220 - Test Accuracy: 0.9151\n",
      "Epoch 408/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9151\n",
      "Epoch 409/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9154\n",
      "Epoch 410/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9215 - Test Accuracy: 0.9153\n",
      "Epoch 411/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9154\n",
      "Epoch 412/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9148\n",
      "Epoch 413/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9148\n",
      "Epoch 414/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9155\n",
      "Epoch 415/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9154\n",
      "Epoch 416/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9151\n",
      "Epoch 417/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9154\n",
      "Epoch 418/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9152\n",
      "Epoch 419/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9152\n",
      "Epoch 420/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9219 - Test Accuracy: 0.9155\n",
      "Epoch 421/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9220 - Test Accuracy: 0.9151\n",
      "Epoch 422/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9151\n",
      "Epoch 423/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9214 - Test Accuracy: 0.9151\n",
      "Epoch 424/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9154\n",
      "Epoch 425/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9223 - Test Accuracy: 0.9149\n",
      "Epoch 426/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9153\n",
      "Epoch 427/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9215 - Test Accuracy: 0.9149\n",
      "Epoch 428/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9223 - Test Accuracy: 0.9157\n",
      "Epoch 429/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9153\n",
      "Epoch 430/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9150\n",
      "Epoch 431/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9150\n",
      "Epoch 432/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9152\n",
      "Epoch 433/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9213 - Test Accuracy: 0.9153\n",
      "Epoch 434/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9148\n",
      "Epoch 435/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9152\n",
      "Epoch 436/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9145\n",
      "Epoch 437/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9152\n",
      "Epoch 438/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9155\n",
      "Epoch 439/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9151\n",
      "Epoch 440/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9151\n",
      "Epoch 441/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9224 - Test Accuracy: 0.9152\n",
      "Epoch 442/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9146\n",
      "Epoch 443/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9153\n",
      "Epoch 444/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9221 - Test Accuracy: 0.9151\n",
      "Epoch 445/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9219 - Test Accuracy: 0.9154\n",
      "Epoch 446/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9148\n",
      "Epoch 447/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9154\n",
      "Epoch 448/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9147\n",
      "Epoch 449/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9153\n",
      "Epoch 450/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9151\n",
      "Epoch 451/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9153\n",
      "Epoch 452/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9153\n",
      "Epoch 453/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9152\n",
      "Epoch 454/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9153\n",
      "Epoch 455/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9153\n",
      "Epoch 456/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9224 - Test Accuracy: 0.9155\n",
      "Epoch 457/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9225 - Test Accuracy: 0.9156\n",
      "Epoch 458/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9151\n",
      "Epoch 459/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9152\n",
      "Epoch 460/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9151\n",
      "Epoch 461/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9153\n",
      "Epoch 462/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9224 - Test Accuracy: 0.9150\n",
      "Epoch 463/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9155\n",
      "Epoch 464/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9224 - Test Accuracy: 0.9152\n",
      "Epoch 465/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9224 - Test Accuracy: 0.9151\n",
      "Epoch 466/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9153\n",
      "Epoch 467/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9151\n",
      "Epoch 468/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9152\n",
      "Epoch 469/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9152\n",
      "Epoch 470/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9151\n",
      "Epoch 471/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9148\n",
      "Epoch 472/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9150\n",
      "Epoch 473/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9153\n",
      "Epoch 474/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9149\n",
      "Epoch 475/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9224 - Test Accuracy: 0.9154\n",
      "Epoch 476/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9157\n",
      "Epoch 477/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9151\n",
      "Epoch 478/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9213 - Test Accuracy: 0.9150\n",
      "Epoch 479/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9153\n",
      "Epoch 480/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9154\n",
      "Epoch 481/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9216 - Test Accuracy: 0.9148\n",
      "Epoch 482/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9219 - Test Accuracy: 0.9153\n",
      "Epoch 483/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9215 - Test Accuracy: 0.9153\n",
      "Epoch 484/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9214 - Test Accuracy: 0.9152\n",
      "Epoch 485/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9151\n",
      "Epoch 486/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9151\n",
      "Epoch 487/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9154\n",
      "Epoch 488/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9219 - Test Accuracy: 0.9155\n",
      "Epoch 489/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9153\n",
      "Epoch 490/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9155\n",
      "Epoch 491/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9216 - Test Accuracy: 0.9152\n",
      "Epoch 492/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9153\n",
      "Epoch 493/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9149\n",
      "Epoch 494/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9214 - Test Accuracy: 0.9151\n",
      "Epoch 495/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9220 - Test Accuracy: 0.9155\n",
      "Epoch 496/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9223 - Test Accuracy: 0.9158\n",
      "Epoch 497/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9151\n",
      "Epoch 498/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9154\n",
      "Epoch 499/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9154\n",
      "Epoch 500/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9150\n",
      "Epoch 501/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9214 - Test Accuracy: 0.9158\n",
      "Epoch 502/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9150\n",
      "Epoch 503/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9147\n",
      "Epoch 504/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9149\n",
      "Epoch 505/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9153\n",
      "Epoch 506/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9213 - Test Accuracy: 0.9154\n",
      "Epoch 507/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9153\n",
      "Epoch 508/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9149\n",
      "Epoch 509/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9154\n",
      "Epoch 510/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9149\n",
      "Epoch 511/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9155\n",
      "Epoch 512/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9153\n",
      "Epoch 513/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9153\n",
      "Epoch 514/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9151\n",
      "Epoch 515/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9149\n",
      "Epoch 516/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9152\n",
      "Epoch 517/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9154\n",
      "Epoch 518/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9156\n",
      "Epoch 519/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9223 - Test Accuracy: 0.9152\n",
      "Epoch 520/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9155\n",
      "Epoch 521/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9149\n",
      "Epoch 522/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9154\n",
      "Epoch 523/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9224 - Test Accuracy: 0.9156\n",
      "Epoch 524/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9150\n",
      "Epoch 525/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9151\n",
      "Epoch 526/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9151\n",
      "Epoch 527/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9152\n",
      "Epoch 528/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9225 - Test Accuracy: 0.9155\n",
      "Epoch 529/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9153\n",
      "Epoch 530/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9151\n",
      "Epoch 531/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9147\n",
      "Epoch 532/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9218 - Test Accuracy: 0.9152\n",
      "Epoch 533/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9155\n",
      "Epoch 534/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9151\n",
      "Epoch 535/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9149\n",
      "Epoch 536/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9152\n",
      "Epoch 537/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9216 - Test Accuracy: 0.9151\n",
      "Epoch 538/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9152\n",
      "Epoch 539/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9153\n",
      "Epoch 540/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9154\n",
      "Epoch 541/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9218 - Test Accuracy: 0.9154\n",
      "Epoch 542/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9150\n",
      "Epoch 543/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9152\n",
      "Epoch 544/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9157\n",
      "Epoch 545/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9154\n",
      "Epoch 546/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9153\n",
      "Epoch 547/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9152\n",
      "Epoch 548/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9149\n",
      "Epoch 549/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9152\n",
      "Epoch 550/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9214 - Test Accuracy: 0.9152\n",
      "Epoch 551/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9153\n",
      "Epoch 552/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9151\n",
      "Epoch 553/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9153\n",
      "Epoch 554/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9153\n",
      "Epoch 555/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9154\n",
      "Epoch 556/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9215 - Test Accuracy: 0.9154\n",
      "Epoch 557/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9154\n",
      "Epoch 558/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9148\n",
      "Epoch 559/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9151\n",
      "Epoch 560/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9151\n",
      "Epoch 561/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9156\n",
      "Epoch 562/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9150\n",
      "Epoch 563/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9150\n",
      "Epoch 564/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9152\n",
      "Epoch 565/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9154\n",
      "Epoch 566/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9223 - Test Accuracy: 0.9153\n",
      "Epoch 567/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9150\n",
      "Epoch 568/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9218 - Test Accuracy: 0.9150\n",
      "Epoch 569/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9154\n",
      "Epoch 570/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9151\n",
      "Epoch 571/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9152\n",
      "Epoch 572/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9152\n",
      "Epoch 573/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9150\n",
      "Epoch 574/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9222 - Test Accuracy: 0.9155\n",
      "Epoch 575/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9151\n",
      "Epoch 576/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9155\n",
      "Epoch 577/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9223 - Test Accuracy: 0.9151\n",
      "Epoch 578/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9155\n",
      "Epoch 579/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9151\n",
      "Epoch 580/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9153\n",
      "Epoch 581/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9151\n",
      "Epoch 582/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9214 - Test Accuracy: 0.9150\n",
      "Epoch 583/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9226 - Test Accuracy: 0.9149\n",
      "Epoch 584/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9151\n",
      "Epoch 585/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9154\n",
      "Epoch 586/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9217 - Test Accuracy: 0.9148\n",
      "Epoch 587/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9156\n",
      "Epoch 588/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9151\n",
      "Epoch 589/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9151\n",
      "Epoch 590/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9154\n",
      "Epoch 591/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9152\n",
      "Epoch 592/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9153\n",
      "Epoch 593/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9152\n",
      "Epoch 594/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9223 - Test Accuracy: 0.9154\n",
      "Epoch 595/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9223 - Test Accuracy: 0.9148\n",
      "Epoch 596/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9149\n",
      "Epoch 597/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9154\n",
      "Epoch 598/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9159\n",
      "Epoch 599/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9148\n",
      "Epoch 600/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9150\n",
      "Epoch 601/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9152\n",
      "Epoch 602/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9214 - Test Accuracy: 0.9153\n",
      "Epoch 603/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9151\n",
      "Epoch 604/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9152\n",
      "Epoch 605/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9218 - Test Accuracy: 0.9152\n",
      "Epoch 606/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9149\n",
      "Epoch 607/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9153\n",
      "Epoch 608/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9153\n",
      "Epoch 609/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9148\n",
      "Epoch 610/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9215 - Test Accuracy: 0.9152\n",
      "Epoch 611/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9220 - Test Accuracy: 0.9152\n",
      "Epoch 612/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9151\n",
      "Epoch 613/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9156\n",
      "Epoch 614/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9222 - Test Accuracy: 0.9151\n",
      "Epoch 615/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9224 - Test Accuracy: 0.9153\n",
      "Epoch 616/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9218 - Test Accuracy: 0.9151\n",
      "Epoch 617/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9220 - Test Accuracy: 0.9155\n",
      "Epoch 618/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9217 - Test Accuracy: 0.9152\n",
      "Epoch 619/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9218 - Test Accuracy: 0.9152\n",
      "Epoch 620/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9223 - Test Accuracy: 0.9154\n",
      "Epoch 621/2500 - Train Accuracy: 0.9968 - Val Accuracy: 0.9219 - Test Accuracy: 0.9152\n",
      "Epoch 622/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9216 - Test Accuracy: 0.9146\n",
      "Epoch 623/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9225 - Test Accuracy: 0.9151\n",
      "Epoch 624/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9221 - Test Accuracy: 0.9151\n",
      "Epoch 625/2500 - Train Accuracy: 0.9970 - Val Accuracy: 0.9218 - Test Accuracy: 0.9149\n",
      "Epoch 626/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9223 - Test Accuracy: 0.9151\n",
      "Epoch 627/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9149\n",
      "Epoch 628/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9216 - Test Accuracy: 0.9154\n",
      "Epoch 629/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9153\n",
      "Epoch 630/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9223 - Test Accuracy: 0.9154\n",
      "Epoch 631/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9223 - Test Accuracy: 0.9155\n",
      "Epoch 632/2500 - Train Accuracy: 0.9969 - Val Accuracy: 0.9219 - Test Accuracy: 0.9152\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 176\u001b[0m\n\u001b[0;32m    172\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m    173\u001b[0m                                     decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, momentum\u001b[38;5;241m=\u001b[39mmomentum, nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    174\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 176\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 출력 숨기기\u001b[39;49;00m\n\u001b[0;32m    180\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEpochEndCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[23], line 58\u001b[0m, in \u001b[0;36mEpochEndCallback.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     56\u001b[0m train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data[\u001b[38;5;241m1\u001b[39m], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     57\u001b[0m val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data[\u001b[38;5;241m1\u001b[39m], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     61\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     62\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     63\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        # GPU 메모리 즉시 사용 설정\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        print('GPU 메모리 즉시 사용이 활성화되었습니다.')\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 실행 중 에러 발생 시\n",
    "        print(e)\n",
    "\n",
    "def normalization(train_images, test_images):\n",
    "    mean = np.mean(train_images, axis=(0, 1, 2, 3))\n",
    "    std = np.std(train_images, axis=(0, 1, 2, 3))\n",
    "    train_images = (train_images - mean) / (std + 1e-7)\n",
    "    test_images = (test_images - mean) / (std + 1e-7)\n",
    "    return train_images, test_images\n",
    "\n",
    "\n",
    "def load_images():\n",
    "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "    train_images = train_images.astype(np.float32)\n",
    "    test_images = test_images.astype(np.float32)\n",
    "\n",
    "    (train_images, test_images) = normalization(train_images, test_images)\n",
    "\n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "    # Randomly select 20% of the training data as validation data\n",
    "    validation_split = 0.2\n",
    "    split_index = int(train_images.shape[0] * (1 - validation_split))\n",
    "    train_images, val_images = train_images[:split_index], train_images[split_index:]\n",
    "    train_labels, val_labels = train_labels[:split_index], train_labels[split_index:]\n",
    "\n",
    "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
    "\n",
    "class EpochEndCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_data, val_data, test_data):\n",
    "        super(EpochEndCallback, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_loss, train_accuracy = self.model.evaluate(self.train_data[0], self.train_data[1], verbose=0)\n",
    "        val_loss, val_accuracy = self.model.evaluate(self.val_data[0], self.val_data[1], verbose=0)\n",
    "        test_loss, test_accuracy = self.model.evaluate(self.test_data[0], self.test_data[1], verbose=0)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{training_epochs} - '\n",
    "              f'Train Accuracy: {train_accuracy:.4f} - '\n",
    "              f'Val Accuracy: {val_accuracy:.4f} - '\n",
    "              f'Test Accuracy: {test_accuracy:.4f}')\n",
    "class ConvBNRelu(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size=3, strides=1, padding='SAME', weight_decay=0.0005, rate=0.4, drop=True):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.drop = drop\n",
    "        self.conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                                        padding=padding, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dropOut = keras.layers.Dropout(rate=rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        layer = self.conv(inputs)\n",
    "        layer = tf.nn.relu(layer)\n",
    "        layer = self.batchnorm(layer)\n",
    "        if self.drop:\n",
    "            layer = self.dropOut(layer)\n",
    "\n",
    "        return layer\n",
    "\n",
    "class VGG16Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16Model, self).__init__()\n",
    "        self.conv1 = ConvBNRelu(filters=64, kernel_size=[3, 3], rate=0.3)\n",
    "        self.conv2 = ConvBNRelu(filters=64, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling1 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv3 = ConvBNRelu(filters=128, kernel_size=[3, 3])\n",
    "        self.conv4 = ConvBNRelu(filters=128, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling2 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv6 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv7 = ConvBNRelu(filters=256, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling3 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv11 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv12 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv13 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling5 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv14 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv15 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv16 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling6 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flat = keras.layers.Flatten()\n",
    "        self.dropOut = keras.layers.Dropout(rate=0.5)\n",
    "        self.dense1 = keras.layers.Dense(units=512,\n",
    "                                         activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "        self.dense3 = keras.layers.Dense(units=10)  # 변경된 부분: units=10\n",
    "        self.softmax = keras.layers.Activation('softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs, training=training)\n",
    "        net = self.conv2(net, training=training)\n",
    "        net = self.maxPooling1(net)\n",
    "        net = self.conv3(net, training=training)\n",
    "        net = self.conv4(net, training=training)\n",
    "        net = self.maxPooling2(net)\n",
    "        net = self.conv6(net, training=training)\n",
    "        net = self.conv7(net, training=training)\n",
    "        net = self.maxPooling3(net)\n",
    "        net = self.conv11(net, training=training)\n",
    "        net = self.conv12(net, training=training)\n",
    "        net = self.conv13(net, training=training)\n",
    "        net = self.maxPooling5(net)\n",
    "        net = self.conv14(net, training=training)\n",
    "        net = self.conv15(net, training=training)\n",
    "        net = self.conv16(net, training=training)\n",
    "        net = self.maxPooling6(net)\n",
    "        net = self.dropOut(net)\n",
    "        net = self.flat(net)\n",
    "        net = self.dense1(net)\n",
    "        net = self.dense3(net)\n",
    "        net = self.softmax(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(tf.__version__)\n",
    "    print(keras.__version__)\n",
    "\n",
    "    training_epochs = 2500\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.9\n",
    "    lr_decay = 1e-6\n",
    "    lr_drop = 20\n",
    "\n",
    "    tf.random.set_seed(777)\n",
    "\n",
    "    def lr_scheduler(epoch):\n",
    "        return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "\n",
    "    reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    train_images, train_labels, val_images, val_labels, test_images, test_labels = load_images()\n",
    "\n",
    "    # data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model = VGG16Model()\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,\n",
    "                                        decay=1e-6, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.fit(datagen.flow(train_images, train_labels,\n",
    "                        batch_size=batch_size), \n",
    "          epochs=training_epochs, \n",
    "          verbose=0,  # 출력 숨기기\n",
    "          callbacks=[reduce_lr, EpochEndCallback((train_images, train_labels), (val_images, val_labels), (test_images, test_labels))],\n",
    "          steps_per_epoch=train_images.shape[0] // batch_size,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e360fec-4a90-4b9f-9df0-63b691a00a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n",
      "2.10.0\n",
      "2.10.0\n",
      "Epoch 1/2500 - Train Accuracy: 0.1477 - Val Accuracy: 0.1476 - Test Accuracy: 0.1448\n",
      "Epoch 2/2500 - Train Accuracy: 0.3149 - Val Accuracy: 0.3169 - Test Accuracy: 0.3108\n",
      "Epoch 3/2500 - Train Accuracy: 0.4530 - Val Accuracy: 0.4480 - Test Accuracy: 0.4466\n",
      "Epoch 4/2500 - Train Accuracy: 0.4403 - Val Accuracy: 0.4389 - Test Accuracy: 0.4376\n",
      "Epoch 5/2500 - Train Accuracy: 0.5944 - Val Accuracy: 0.5923 - Test Accuracy: 0.5890\n",
      "Epoch 6/2500 - Train Accuracy: 0.6265 - Val Accuracy: 0.6202 - Test Accuracy: 0.6203\n",
      "Epoch 7/2500 - Train Accuracy: 0.6974 - Val Accuracy: 0.6903 - Test Accuracy: 0.6834\n",
      "Epoch 8/2500 - Train Accuracy: 0.6967 - Val Accuracy: 0.6886 - Test Accuracy: 0.6854\n",
      "Epoch 9/2500 - Train Accuracy: 0.7329 - Val Accuracy: 0.7289 - Test Accuracy: 0.7294\n",
      "Epoch 10/2500 - Train Accuracy: 0.7638 - Val Accuracy: 0.7623 - Test Accuracy: 0.7538\n",
      "Epoch 11/2500 - Train Accuracy: 0.7857 - Val Accuracy: 0.7782 - Test Accuracy: 0.7718\n",
      "Epoch 12/2500 - Train Accuracy: 0.7389 - Val Accuracy: 0.7289 - Test Accuracy: 0.7208\n",
      "Epoch 13/2500 - Train Accuracy: 0.7727 - Val Accuracy: 0.7648 - Test Accuracy: 0.7602\n",
      "Epoch 14/2500 - Train Accuracy: 0.7692 - Val Accuracy: 0.7596 - Test Accuracy: 0.7526\n",
      "Epoch 15/2500 - Train Accuracy: 0.7255 - Val Accuracy: 0.7213 - Test Accuracy: 0.7143\n",
      "Epoch 16/2500 - Train Accuracy: 0.7877 - Val Accuracy: 0.7745 - Test Accuracy: 0.7721\n",
      "Epoch 17/2500 - Train Accuracy: 0.7600 - Val Accuracy: 0.7498 - Test Accuracy: 0.7417\n",
      "Epoch 18/2500 - Train Accuracy: 0.7584 - Val Accuracy: 0.7515 - Test Accuracy: 0.7477\n",
      "Epoch 19/2500 - Train Accuracy: 0.7479 - Val Accuracy: 0.7380 - Test Accuracy: 0.7319\n",
      "Epoch 20/2500 - Train Accuracy: 0.7999 - Val Accuracy: 0.7854 - Test Accuracy: 0.7815\n",
      "Epoch 21/2500 - Train Accuracy: 0.8346 - Val Accuracy: 0.8177 - Test Accuracy: 0.8155\n",
      "Epoch 22/2500 - Train Accuracy: 0.8207 - Val Accuracy: 0.8048 - Test Accuracy: 0.7978\n",
      "Epoch 23/2500 - Train Accuracy: 0.8127 - Val Accuracy: 0.7946 - Test Accuracy: 0.7892\n",
      "Epoch 24/2500 - Train Accuracy: 0.8364 - Val Accuracy: 0.8197 - Test Accuracy: 0.8133\n",
      "Epoch 25/2500 - Train Accuracy: 0.8283 - Val Accuracy: 0.8159 - Test Accuracy: 0.8074\n",
      "Epoch 26/2500 - Train Accuracy: 0.8315 - Val Accuracy: 0.8126 - Test Accuracy: 0.8099\n",
      "Epoch 27/2500 - Train Accuracy: 0.8284 - Val Accuracy: 0.8084 - Test Accuracy: 0.8065\n",
      "Epoch 28/2500 - Train Accuracy: 0.8379 - Val Accuracy: 0.8164 - Test Accuracy: 0.8150\n",
      "Epoch 29/2500 - Train Accuracy: 0.8167 - Val Accuracy: 0.8008 - Test Accuracy: 0.7945\n",
      "Epoch 30/2500 - Train Accuracy: 0.8319 - Val Accuracy: 0.8118 - Test Accuracy: 0.8038\n",
      "Epoch 31/2500 - Train Accuracy: 0.8070 - Val Accuracy: 0.7957 - Test Accuracy: 0.7820\n",
      "Epoch 32/2500 - Train Accuracy: 0.8632 - Val Accuracy: 0.8401 - Test Accuracy: 0.8347\n",
      "Epoch 33/2500 - Train Accuracy: 0.8457 - Val Accuracy: 0.8278 - Test Accuracy: 0.8199\n",
      "Epoch 34/2500 - Train Accuracy: 0.8478 - Val Accuracy: 0.8196 - Test Accuracy: 0.8214\n",
      "Epoch 35/2500 - Train Accuracy: 0.8468 - Val Accuracy: 0.8253 - Test Accuracy: 0.8216\n",
      "Epoch 36/2500 - Train Accuracy: 0.8654 - Val Accuracy: 0.8479 - Test Accuracy: 0.8326\n",
      "Epoch 37/2500 - Train Accuracy: 0.8209 - Val Accuracy: 0.8052 - Test Accuracy: 0.7965\n",
      "Epoch 38/2500 - Train Accuracy: 0.8519 - Val Accuracy: 0.8325 - Test Accuracy: 0.8251\n",
      "Epoch 39/2500 - Train Accuracy: 0.8562 - Val Accuracy: 0.8410 - Test Accuracy: 0.8315\n",
      "Epoch 40/2500 - Train Accuracy: 0.8535 - Val Accuracy: 0.8336 - Test Accuracy: 0.8269\n",
      "Epoch 41/2500 - Train Accuracy: 0.8860 - Val Accuracy: 0.8641 - Test Accuracy: 0.8529\n",
      "Epoch 42/2500 - Train Accuracy: 0.8978 - Val Accuracy: 0.8696 - Test Accuracy: 0.8618\n",
      "Epoch 43/2500 - Train Accuracy: 0.8920 - Val Accuracy: 0.8635 - Test Accuracy: 0.8533\n",
      "Epoch 44/2500 - Train Accuracy: 0.8856 - Val Accuracy: 0.8545 - Test Accuracy: 0.8540\n",
      "Epoch 45/2500 - Train Accuracy: 0.9038 - Val Accuracy: 0.8775 - Test Accuracy: 0.8679\n",
      "Epoch 46/2500 - Train Accuracy: 0.8894 - Val Accuracy: 0.8610 - Test Accuracy: 0.8532\n",
      "Epoch 47/2500 - Train Accuracy: 0.8995 - Val Accuracy: 0.8689 - Test Accuracy: 0.8642\n",
      "Epoch 48/2500 - Train Accuracy: 0.8998 - Val Accuracy: 0.8725 - Test Accuracy: 0.8640\n",
      "Epoch 49/2500 - Train Accuracy: 0.8885 - Val Accuracy: 0.8597 - Test Accuracy: 0.8528\n",
      "Epoch 50/2500 - Train Accuracy: 0.8723 - Val Accuracy: 0.8470 - Test Accuracy: 0.8374\n",
      "Epoch 51/2500 - Train Accuracy: 0.9075 - Val Accuracy: 0.8780 - Test Accuracy: 0.8713\n",
      "Epoch 52/2500 - Train Accuracy: 0.9005 - Val Accuracy: 0.8711 - Test Accuracy: 0.8642\n",
      "Epoch 53/2500 - Train Accuracy: 0.8984 - Val Accuracy: 0.8645 - Test Accuracy: 0.8553\n",
      "Epoch 54/2500 - Train Accuracy: 0.8996 - Val Accuracy: 0.8680 - Test Accuracy: 0.8590\n",
      "Epoch 55/2500 - Train Accuracy: 0.8957 - Val Accuracy: 0.8631 - Test Accuracy: 0.8612\n",
      "Epoch 56/2500 - Train Accuracy: 0.8982 - Val Accuracy: 0.8674 - Test Accuracy: 0.8635\n",
      "Epoch 57/2500 - Train Accuracy: 0.9079 - Val Accuracy: 0.8734 - Test Accuracy: 0.8648\n",
      "Epoch 58/2500 - Train Accuracy: 0.9066 - Val Accuracy: 0.8750 - Test Accuracy: 0.8678\n",
      "Epoch 59/2500 - Train Accuracy: 0.8980 - Val Accuracy: 0.8681 - Test Accuracy: 0.8595\n",
      "Epoch 60/2500 - Train Accuracy: 0.8856 - Val Accuracy: 0.8535 - Test Accuracy: 0.8487\n",
      "Epoch 61/2500 - Train Accuracy: 0.9301 - Val Accuracy: 0.8944 - Test Accuracy: 0.8880\n",
      "Epoch 62/2500 - Train Accuracy: 0.9323 - Val Accuracy: 0.8923 - Test Accuracy: 0.8871\n",
      "Epoch 63/2500 - Train Accuracy: 0.9390 - Val Accuracy: 0.8988 - Test Accuracy: 0.8915\n",
      "Epoch 64/2500 - Train Accuracy: 0.9323 - Val Accuracy: 0.8932 - Test Accuracy: 0.8906\n",
      "Epoch 65/2500 - Train Accuracy: 0.9474 - Val Accuracy: 0.9035 - Test Accuracy: 0.9009\n",
      "Epoch 66/2500 - Train Accuracy: 0.9370 - Val Accuracy: 0.8919 - Test Accuracy: 0.8874\n",
      "Epoch 67/2500 - Train Accuracy: 0.9221 - Val Accuracy: 0.8791 - Test Accuracy: 0.8755\n",
      "Epoch 68/2500 - Train Accuracy: 0.9401 - Val Accuracy: 0.8950 - Test Accuracy: 0.8927\n",
      "Epoch 69/2500 - Train Accuracy: 0.9390 - Val Accuracy: 0.8958 - Test Accuracy: 0.8910\n",
      "Epoch 70/2500 - Train Accuracy: 0.9331 - Val Accuracy: 0.8913 - Test Accuracy: 0.8815\n",
      "Epoch 71/2500 - Train Accuracy: 0.9424 - Val Accuracy: 0.8982 - Test Accuracy: 0.8906\n",
      "Epoch 72/2500 - Train Accuracy: 0.9396 - Val Accuracy: 0.8951 - Test Accuracy: 0.8925\n",
      "Epoch 73/2500 - Train Accuracy: 0.9416 - Val Accuracy: 0.8997 - Test Accuracy: 0.8920\n",
      "Epoch 74/2500 - Train Accuracy: 0.9262 - Val Accuracy: 0.8817 - Test Accuracy: 0.8704\n",
      "Epoch 75/2500 - Train Accuracy: 0.9337 - Val Accuracy: 0.8883 - Test Accuracy: 0.8826\n",
      "Epoch 76/2500 - Train Accuracy: 0.9460 - Val Accuracy: 0.8985 - Test Accuracy: 0.8960\n",
      "Epoch 77/2500 - Train Accuracy: 0.9424 - Val Accuracy: 0.8926 - Test Accuracy: 0.8894\n",
      "Epoch 78/2500 - Train Accuracy: 0.9273 - Val Accuracy: 0.8854 - Test Accuracy: 0.8783\n",
      "Epoch 79/2500 - Train Accuracy: 0.9390 - Val Accuracy: 0.8943 - Test Accuracy: 0.8898\n",
      "Epoch 80/2500 - Train Accuracy: 0.9307 - Val Accuracy: 0.8857 - Test Accuracy: 0.8818\n",
      "Epoch 81/2500 - Train Accuracy: 0.9566 - Val Accuracy: 0.9094 - Test Accuracy: 0.9053\n",
      "Epoch 82/2500 - Train Accuracy: 0.9616 - Val Accuracy: 0.9155 - Test Accuracy: 0.9074\n",
      "Epoch 83/2500 - Train Accuracy: 0.9595 - Val Accuracy: 0.9100 - Test Accuracy: 0.9039\n",
      "Epoch 84/2500 - Train Accuracy: 0.9599 - Val Accuracy: 0.9076 - Test Accuracy: 0.9024\n",
      "Epoch 85/2500 - Train Accuracy: 0.9557 - Val Accuracy: 0.9000 - Test Accuracy: 0.8971\n",
      "Epoch 86/2500 - Train Accuracy: 0.9641 - Val Accuracy: 0.9088 - Test Accuracy: 0.9049\n",
      "Epoch 87/2500 - Train Accuracy: 0.9631 - Val Accuracy: 0.9081 - Test Accuracy: 0.9042\n",
      "Epoch 88/2500 - Train Accuracy: 0.9672 - Val Accuracy: 0.9125 - Test Accuracy: 0.9048\n",
      "Epoch 89/2500 - Train Accuracy: 0.9658 - Val Accuracy: 0.9092 - Test Accuracy: 0.9045\n",
      "Epoch 90/2500 - Train Accuracy: 0.9650 - Val Accuracy: 0.9084 - Test Accuracy: 0.9018\n",
      "Epoch 91/2500 - Train Accuracy: 0.9689 - Val Accuracy: 0.9146 - Test Accuracy: 0.9070\n",
      "Epoch 92/2500 - Train Accuracy: 0.9706 - Val Accuracy: 0.9168 - Test Accuracy: 0.9115\n",
      "Epoch 93/2500 - Train Accuracy: 0.9630 - Val Accuracy: 0.9054 - Test Accuracy: 0.8987\n",
      "Epoch 94/2500 - Train Accuracy: 0.9681 - Val Accuracy: 0.9113 - Test Accuracy: 0.9056\n",
      "Epoch 95/2500 - Train Accuracy: 0.9674 - Val Accuracy: 0.9090 - Test Accuracy: 0.9078\n",
      "Epoch 96/2500 - Train Accuracy: 0.9666 - Val Accuracy: 0.9083 - Test Accuracy: 0.9031\n",
      "Epoch 97/2500 - Train Accuracy: 0.9678 - Val Accuracy: 0.9097 - Test Accuracy: 0.9072\n",
      "Epoch 98/2500 - Train Accuracy: 0.9750 - Val Accuracy: 0.9173 - Test Accuracy: 0.9106\n",
      "Epoch 99/2500 - Train Accuracy: 0.9664 - Val Accuracy: 0.9097 - Test Accuracy: 0.9040\n",
      "Epoch 100/2500 - Train Accuracy: 0.9603 - Val Accuracy: 0.9018 - Test Accuracy: 0.8960\n",
      "Epoch 101/2500 - Train Accuracy: 0.9769 - Val Accuracy: 0.9192 - Test Accuracy: 0.9123\n",
      "Epoch 102/2500 - Train Accuracy: 0.9765 - Val Accuracy: 0.9164 - Test Accuracy: 0.9106\n",
      "Epoch 103/2500 - Train Accuracy: 0.9809 - Val Accuracy: 0.9182 - Test Accuracy: 0.9162\n",
      "Epoch 104/2500 - Train Accuracy: 0.9822 - Val Accuracy: 0.9224 - Test Accuracy: 0.9191\n",
      "Epoch 105/2500 - Train Accuracy: 0.9801 - Val Accuracy: 0.9179 - Test Accuracy: 0.9144\n",
      "Epoch 106/2500 - Train Accuracy: 0.9801 - Val Accuracy: 0.9160 - Test Accuracy: 0.9127\n",
      "Epoch 107/2500 - Train Accuracy: 0.9817 - Val Accuracy: 0.9179 - Test Accuracy: 0.9126\n",
      "Epoch 108/2500 - Train Accuracy: 0.9842 - Val Accuracy: 0.9203 - Test Accuracy: 0.9179\n",
      "Epoch 109/2500 - Train Accuracy: 0.9850 - Val Accuracy: 0.9219 - Test Accuracy: 0.9195\n",
      "Epoch 110/2500 - Train Accuracy: 0.9851 - Val Accuracy: 0.9204 - Test Accuracy: 0.9168\n",
      "Epoch 111/2500 - Train Accuracy: 0.9828 - Val Accuracy: 0.9200 - Test Accuracy: 0.9149\n",
      "Epoch 112/2500 - Train Accuracy: 0.9817 - Val Accuracy: 0.9185 - Test Accuracy: 0.9156\n",
      "Epoch 113/2500 - Train Accuracy: 0.9821 - Val Accuracy: 0.9155 - Test Accuracy: 0.9152\n",
      "Epoch 114/2500 - Train Accuracy: 0.9856 - Val Accuracy: 0.9222 - Test Accuracy: 0.9156\n",
      "Epoch 115/2500 - Train Accuracy: 0.9838 - Val Accuracy: 0.9167 - Test Accuracy: 0.9138\n",
      "Epoch 116/2500 - Train Accuracy: 0.9853 - Val Accuracy: 0.9210 - Test Accuracy: 0.9162\n",
      "Epoch 117/2500 - Train Accuracy: 0.9818 - Val Accuracy: 0.9151 - Test Accuracy: 0.9112\n",
      "Epoch 118/2500 - Train Accuracy: 0.9851 - Val Accuracy: 0.9188 - Test Accuracy: 0.9136\n",
      "Epoch 119/2500 - Train Accuracy: 0.9843 - Val Accuracy: 0.9192 - Test Accuracy: 0.9129\n",
      "Epoch 120/2500 - Train Accuracy: 0.9866 - Val Accuracy: 0.9203 - Test Accuracy: 0.9159\n",
      "Epoch 121/2500 - Train Accuracy: 0.9876 - Val Accuracy: 0.9233 - Test Accuracy: 0.9178\n",
      "Epoch 122/2500 - Train Accuracy: 0.9886 - Val Accuracy: 0.9209 - Test Accuracy: 0.9168\n",
      "Epoch 123/2500 - Train Accuracy: 0.9898 - Val Accuracy: 0.9269 - Test Accuracy: 0.9184\n",
      "Epoch 124/2500 - Train Accuracy: 0.9898 - Val Accuracy: 0.9252 - Test Accuracy: 0.9166\n",
      "Epoch 125/2500 - Train Accuracy: 0.9907 - Val Accuracy: 0.9241 - Test Accuracy: 0.9180\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 177\u001b[0m\n\u001b[0;32m    173\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m    174\u001b[0m                                     decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, momentum\u001b[38;5;241m=\u001b[39mmomentum, nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    175\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 177\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 출력 숨기기\u001b[39;49;00m\n\u001b[0;32m    181\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEpochEndCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# GPU 메모리 즉시 사용 활성화\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        # GPU 메모리 즉시 사용 설정\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        print('GPU 메모리 즉시 사용이 활성화되었습니다.')\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 실행 중 에러 발생 시\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def normalization(train_images, test_images):\n",
    "    mean = np.mean(train_images, axis=(0, 1, 2, 3))\n",
    "    std = np.std(train_images, axis=(0, 1, 2, 3))\n",
    "    train_images = (train_images - mean) / (std + 1e-7)\n",
    "    test_images = (test_images - mean) / (std + 1e-7)\n",
    "    return train_images, test_images\n",
    "\n",
    "\n",
    "def load_images():\n",
    "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "    train_images = train_images.astype(np.float32)\n",
    "    test_images = test_images.astype(np.float32)\n",
    "\n",
    "    (train_images, test_images) = normalization(train_images, test_images)\n",
    "\n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "    # Randomly select 20% of the training data as validation data\n",
    "    validation_split = 0.2\n",
    "    split_index = int(train_images.shape[0] * (1 - validation_split))\n",
    "    train_images, val_images = train_images[:split_index], train_images[split_index:]\n",
    "    train_labels, val_labels = train_labels[:split_index], train_labels[split_index:]\n",
    "\n",
    "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
    "class EpochEndCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_data, val_data, test_data):\n",
    "        super(EpochEndCallback, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_loss, train_accuracy = self.model.evaluate(self.train_data[0], self.train_data[1], verbose=0)\n",
    "        val_loss, val_accuracy = self.model.evaluate(self.val_data[0], self.val_data[1], verbose=0)\n",
    "        test_loss, test_accuracy = self.model.evaluate(self.test_data[0], self.test_data[1], verbose=0)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{training_epochs} - '\n",
    "              f'Train Accuracy: {train_accuracy:.4f} - '\n",
    "              f'Val Accuracy: {val_accuracy:.4f} - '\n",
    "              f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "class ConvBNRelu(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size=3, strides=1, padding='SAME', weight_decay=0.0005, rate=0.4, drop=True):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.drop = drop\n",
    "        self.conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                                        padding=padding, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dropOut = keras.layers.Dropout(rate=rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        layer = self.conv(inputs)\n",
    "        layer = tf.nn.relu(layer)\n",
    "        layer = self.batchnorm(layer)\n",
    "        if self.drop:\n",
    "            layer = self.dropOut(layer)\n",
    "\n",
    "        return layer\n",
    "\n",
    "class VGG16Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16Model, self).__init__()\n",
    "        self.conv1 = ConvBNRelu(filters=64, kernel_size=[3, 3], rate=0.3)\n",
    "        self.conv2 = ConvBNRelu(filters=64, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling1 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv3 = ConvBNRelu(filters=128, kernel_size=[3, 3])\n",
    "        self.conv4 = ConvBNRelu(filters=128, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling2 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv5 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv6 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv7 = ConvBNRelu(filters=256, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling3 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv11 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv12 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv13 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling5 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv14 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv15 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.maxPooling6 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flat = keras.layers.Flatten()\n",
    "        self.dropOut = keras.layers.Dropout(rate=0.5)\n",
    "        self.dense1 = keras.layers.Dense(units=512,\n",
    "                                         activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dense2 = keras.layers.Dense(units=10)\n",
    "        self.softmax = keras.layers.Activation('softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs, training=training)\n",
    "        net = self.conv2(net, training=training)\n",
    "        net = self.maxPooling1(net)\n",
    "        net = self.conv3(net, training=training)\n",
    "        net = self.conv4(net, training=training)\n",
    "        net = self.maxPooling2(net)\n",
    "        net = self.conv5(net, training=training)\n",
    "        net = self.conv6(net, training=training)\n",
    "        net = self.conv7(net, training=training)\n",
    "        net = self.maxPooling3(net)\n",
    "        net = self.conv11(net, training=training)\n",
    "        net = self.conv12(net, training=training)\n",
    "        net = self.conv13(net, training=training)\n",
    "        net = self.maxPooling5(net)\n",
    "        net = self.conv14(net, training=training)\n",
    "        net = self.conv15(net, training=training)\n",
    "        net = self.maxPooling6(net)\n",
    "        net = self.dropOut(net)\n",
    "        net = self.flat(net)\n",
    "        net = self.dense1(net)\n",
    "        net = self.batchnorm(net)\n",
    "        net = self.dense2(net)\n",
    "        net = self.softmax(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(tf.__version__)\n",
    "    print(keras.__version__)\n",
    "\n",
    "    training_epochs = 2500\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.9\n",
    "    lr_decay = 1e-6\n",
    "    lr_drop = 20\n",
    "\n",
    "    tf.random.set_seed(777)\n",
    "\n",
    "    def lr_scheduler(epoch):\n",
    "        return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "\n",
    "    reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    train_images, train_labels, val_images, val_labels, test_images, test_labels = load_images()\n",
    "\n",
    "\n",
    "    # data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model = VGG16Model()\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,\n",
    "                                        decay=1e-6, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.fit(datagen.flow(train_images, train_labels,\n",
    "                        batch_size=batch_size), \n",
    "          epochs=training_epochs, \n",
    "          verbose=0,  # 출력 숨기기\n",
    "          callbacks=[reduce_lr, EpochEndCallback((train_images, train_labels), (val_images, val_labels), (test_images, test_labels))],\n",
    "          steps_per_epoch=train_images.shape[0] // batch_size,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f83346-28ff-4758-b6b2-a6ddf2896a1c",
   "metadata": {},
   "source": [
    "layer 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a765b3cd-9e9b-4cc4-ad30-e70416dff2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n",
      "2.10.0\n",
      "2.10.0\n",
      "Epoch 1/2500 - Train Accuracy: 0.1619 - Val Accuracy: 0.1603 - Test Accuracy: 0.1665\n",
      "Epoch 2/2500 - Train Accuracy: 0.1510 - Val Accuracy: 0.1460 - Test Accuracy: 0.1502\n",
      "Epoch 3/2500 - Train Accuracy: 0.2246 - Val Accuracy: 0.2215 - Test Accuracy: 0.2264\n",
      "Epoch 4/2500 - Train Accuracy: 0.4171 - Val Accuracy: 0.4123 - Test Accuracy: 0.4147\n",
      "Epoch 5/2500 - Train Accuracy: 0.5199 - Val Accuracy: 0.5127 - Test Accuracy: 0.5104\n",
      "Epoch 6/2500 - Train Accuracy: 0.6073 - Val Accuracy: 0.6071 - Test Accuracy: 0.5931\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 179\u001b[0m\n\u001b[0;32m    175\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m    176\u001b[0m                                     decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, momentum\u001b[38;5;241m=\u001b[39mmomentum, nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    177\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 179\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 출력 숨기기\u001b[39;49;00m\n\u001b[0;32m    183\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEpochEndCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1624\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m     }\n\u001b[0;32m   1622\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[1;32m-> 1624\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1625\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:448\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    446\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m--> 448\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 58\u001b[0m, in \u001b[0;36mEpochEndCallback.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 58\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data[\u001b[38;5;241m1\u001b[39m], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     60\u001b[0m     test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data[\u001b[38;5;241m1\u001b[39m], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# GPU 메모리 즉시 사용 활성화\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        # GPU 메모리 즉시 사용 설정\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        print('GPU 메모리 즉시 사용이 활성화되었습니다.')\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 실행 중 에러 발생 시\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def normalization(train_images, test_images):\n",
    "    mean = np.mean(train_images, axis=(0, 1, 2, 3))\n",
    "    std = np.std(train_images, axis=(0, 1, 2, 3))\n",
    "    train_images = (train_images - mean) / (std + 1e-7)\n",
    "    test_images = (test_images - mean) / (std + 1e-7)\n",
    "    return train_images, test_images\n",
    "\n",
    "\n",
    "def load_images():\n",
    "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "    train_images = train_images.astype(np.float32)\n",
    "    test_images = test_images.astype(np.float32)\n",
    "\n",
    "    (train_images, test_images) = normalization(train_images, test_images)\n",
    "\n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "    # Randomly select 20% of the training data as validation data\n",
    "    validation_split = 0.2\n",
    "    split_index = int(train_images.shape[0] * (1 - validation_split))\n",
    "    train_images, val_images = train_images[:split_index], train_images[split_index:]\n",
    "    train_labels, val_labels = train_labels[:split_index], train_labels[split_index:]\n",
    "\n",
    "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
    "class EpochEndCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_data, val_data, test_data):\n",
    "        super(EpochEndCallback, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_loss, train_accuracy = self.model.evaluate(self.train_data[0], self.train_data[1], verbose=0)\n",
    "        val_loss, val_accuracy = self.model.evaluate(self.val_data[0], self.val_data[1], verbose=0)\n",
    "        test_loss, test_accuracy = self.model.evaluate(self.test_data[0], self.test_data[1], verbose=0)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{training_epochs} - '\n",
    "              f'Train Accuracy: {train_accuracy:.4f} - '\n",
    "              f'Val Accuracy: {val_accuracy:.4f} - '\n",
    "              f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "class ConvBNRelu(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size=3, strides=1, padding='SAME', weight_decay=0.0005, rate=0.4, drop=True):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.drop = drop\n",
    "        self.conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                                        padding=padding, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dropOut = keras.layers.Dropout(rate=rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        layer = self.conv(inputs)\n",
    "        layer = tf.nn.relu(layer)\n",
    "        layer = self.batchnorm(layer)\n",
    "        if self.drop:\n",
    "            layer = self.dropOut(layer)\n",
    "\n",
    "        return layer\n",
    "\n",
    "class VGG16Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16Model, self).__init__()\n",
    "        self.conv0 = ConvBNRelu(filters=64, kernel_size=[3, 3], rate=0.3)\n",
    "        self.conv1 = ConvBNRelu(filters=64, kernel_size=[3, 3])\n",
    "        self.conv2 = ConvBNRelu(filters=64, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling1 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv3 = ConvBNRelu(filters=128, kernel_size=[3, 3])\n",
    "        self.conv4 = ConvBNRelu(filters=128, kernel_size=[3, 3])\n",
    "        self.conv5 = ConvBNRelu(filters=128, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling2 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv6 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv7 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv8 = ConvBNRelu(filters=256, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling3 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv9 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv11 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling5 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv12 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv13 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.maxPooling6 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flat = keras.layers.Flatten()\n",
    "        self.dropOut = keras.layers.Dropout(rate=0.5)\n",
    "        self.dense1 = keras.layers.Dense(units=512,\n",
    "                                         activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dense2 = keras.layers.Dense(units=10)\n",
    "        self.softmax = keras.layers.Activation('softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv0(inputs, training=training)\n",
    "        net = self.conv1(net, training=training)\n",
    "        net = self.conv2(net, training=training)\n",
    "        net = self.maxPooling1(net)\n",
    "        net = self.conv3(net, training=training)\n",
    "        net = self.conv4(net, training=training)\n",
    "        net = self.conv5(net, training=training)\n",
    "        net = self.maxPooling2(net)\n",
    "        net = self.conv6(net, training=training)\n",
    "        net = self.conv7(net, training=training)\n",
    "        net = self.conv8(net, training=training)\n",
    "        net = self.maxPooling3(net)\n",
    "        net = self.conv9(net, training=training)\n",
    "        net = self.conv11(net, training=training)\n",
    "        net = self.maxPooling5(net)\n",
    "        net = self.conv12(net, training=training)\n",
    "        net = self.conv13(net, training=training)\n",
    "        net = self.maxPooling6(net)\n",
    "        net = self.dropOut(net)\n",
    "        net = self.flat(net)\n",
    "        net = self.dense1(net)\n",
    "        net = self.batchnorm(net)\n",
    "        net = self.dense2(net)\n",
    "        net = self.softmax(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(tf.__version__)\n",
    "    print(keras.__version__)\n",
    "\n",
    "    training_epochs = 2500\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.9\n",
    "    lr_decay = 1e-6\n",
    "    lr_drop = 20\n",
    "\n",
    "    tf.random.set_seed(777)\n",
    "\n",
    "    def lr_scheduler(epoch):\n",
    "        return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "\n",
    "    reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    train_images, train_labels, val_images, val_labels, test_images, test_labels = load_images()\n",
    "\n",
    "\n",
    "    # data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model = VGG16Model()\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,\n",
    "                                        decay=1e-6, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.fit(datagen.flow(train_images, train_labels,\n",
    "                        batch_size=batch_size), \n",
    "          epochs=training_epochs, \n",
    "          verbose=0,  # 출력 숨기기\n",
    "          callbacks=[reduce_lr, EpochEndCallback((train_images, train_labels), (val_images, val_labels), (test_images, test_labels))],\n",
    "          steps_per_epoch=train_images.shape[0] // batch_size,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1e65b-0a9e-41e6-905a-deba203df942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n",
      "2.10.0\n",
      "2.10.0\n",
      "Epoch 1/500 - Train Accuracy: 0.1664 - Val Accuracy: 0.1650 - Test Accuracy: 0.1615\n",
      "Epoch 2/500 - Train Accuracy: 0.1834 - Val Accuracy: 0.1849 - Test Accuracy: 0.1831\n",
      "Epoch 3/500 - Train Accuracy: 0.1884 - Val Accuracy: 0.1898 - Test Accuracy: 0.1888\n",
      "Epoch 4/500 - Train Accuracy: 0.3582 - Val Accuracy: 0.3570 - Test Accuracy: 0.3488\n",
      "Epoch 5/500 - Train Accuracy: 0.3687 - Val Accuracy: 0.3660 - Test Accuracy: 0.3714\n",
      "Epoch 6/500 - Train Accuracy: 0.4013 - Val Accuracy: 0.4061 - Test Accuracy: 0.3997\n",
      "Epoch 7/500 - Train Accuracy: 0.4692 - Val Accuracy: 0.4672 - Test Accuracy: 0.4602\n",
      "Epoch 8/500 - Train Accuracy: 0.5501 - Val Accuracy: 0.5514 - Test Accuracy: 0.5443\n",
      "Epoch 9/500 - Train Accuracy: 0.5276 - Val Accuracy: 0.5241 - Test Accuracy: 0.5156\n",
      "Epoch 10/500 - Train Accuracy: 0.6087 - Val Accuracy: 0.6153 - Test Accuracy: 0.6017\n",
      "Epoch 11/500 - Train Accuracy: 0.6676 - Val Accuracy: 0.6673 - Test Accuracy: 0.6611\n",
      "Epoch 12/500 - Train Accuracy: 0.6387 - Val Accuracy: 0.6277 - Test Accuracy: 0.6283\n",
      "Epoch 13/500 - Train Accuracy: 0.6366 - Val Accuracy: 0.6357 - Test Accuracy: 0.6320\n",
      "Epoch 14/500 - Train Accuracy: 0.6859 - Val Accuracy: 0.6786 - Test Accuracy: 0.6772\n",
      "Epoch 15/500 - Train Accuracy: 0.7068 - Val Accuracy: 0.7062 - Test Accuracy: 0.7000\n",
      "Epoch 16/500 - Train Accuracy: 0.5890 - Val Accuracy: 0.5940 - Test Accuracy: 0.5822\n",
      "Epoch 17/500 - Train Accuracy: 0.7239 - Val Accuracy: 0.7209 - Test Accuracy: 0.7116\n",
      "Epoch 18/500 - Train Accuracy: 0.6647 - Val Accuracy: 0.6538 - Test Accuracy: 0.6570\n",
      "Epoch 19/500 - Train Accuracy: 0.7174 - Val Accuracy: 0.7130 - Test Accuracy: 0.7085\n",
      "Epoch 20/500 - Train Accuracy: 0.7200 - Val Accuracy: 0.7156 - Test Accuracy: 0.7112\n",
      "Epoch 21/500 - Train Accuracy: 0.8138 - Val Accuracy: 0.8078 - Test Accuracy: 0.7948\n",
      "Epoch 22/500 - Train Accuracy: 0.7990 - Val Accuracy: 0.7884 - Test Accuracy: 0.7834\n",
      "Epoch 23/500 - Train Accuracy: 0.7586 - Val Accuracy: 0.7497 - Test Accuracy: 0.7419\n",
      "Epoch 24/500 - Train Accuracy: 0.7703 - Val Accuracy: 0.7543 - Test Accuracy: 0.7490\n",
      "Epoch 25/500 - Train Accuracy: 0.7865 - Val Accuracy: 0.7705 - Test Accuracy: 0.7635\n",
      "Epoch 26/500 - Train Accuracy: 0.7895 - Val Accuracy: 0.7724 - Test Accuracy: 0.7733\n",
      "Epoch 27/500 - Train Accuracy: 0.8131 - Val Accuracy: 0.7983 - Test Accuracy: 0.7901\n",
      "Epoch 28/500 - Train Accuracy: 0.8121 - Val Accuracy: 0.8013 - Test Accuracy: 0.7944\n",
      "Epoch 29/500 - Train Accuracy: 0.8178 - Val Accuracy: 0.8022 - Test Accuracy: 0.7987\n",
      "Epoch 30/500 - Train Accuracy: 0.7841 - Val Accuracy: 0.7739 - Test Accuracy: 0.7623\n",
      "Epoch 31/500 - Train Accuracy: 0.8120 - Val Accuracy: 0.7988 - Test Accuracy: 0.7930\n",
      "Epoch 32/500 - Train Accuracy: 0.8026 - Val Accuracy: 0.7915 - Test Accuracy: 0.7793\n",
      "Epoch 33/500 - Train Accuracy: 0.8321 - Val Accuracy: 0.8176 - Test Accuracy: 0.8107\n",
      "Epoch 34/500 - Train Accuracy: 0.7975 - Val Accuracy: 0.7899 - Test Accuracy: 0.7807\n",
      "Epoch 35/500 - Train Accuracy: 0.8236 - Val Accuracy: 0.8087 - Test Accuracy: 0.8031\n",
      "Epoch 36/500 - Train Accuracy: 0.7909 - Val Accuracy: 0.7775 - Test Accuracy: 0.7681\n",
      "Epoch 37/500 - Train Accuracy: 0.8289 - Val Accuracy: 0.8145 - Test Accuracy: 0.8111\n",
      "Epoch 38/500 - Train Accuracy: 0.8504 - Val Accuracy: 0.8323 - Test Accuracy: 0.8280\n",
      "Epoch 39/500 - Train Accuracy: 0.8125 - Val Accuracy: 0.7992 - Test Accuracy: 0.7930\n",
      "Epoch 40/500 - Train Accuracy: 0.8240 - Val Accuracy: 0.8058 - Test Accuracy: 0.8049\n",
      "Epoch 41/500 - Train Accuracy: 0.8730 - Val Accuracy: 0.8521 - Test Accuracy: 0.8395\n",
      "Epoch 42/500 - Train Accuracy: 0.8845 - Val Accuracy: 0.8607 - Test Accuracy: 0.8542\n",
      "Epoch 43/500 - Train Accuracy: 0.8794 - Val Accuracy: 0.8612 - Test Accuracy: 0.8473\n",
      "Epoch 44/500 - Train Accuracy: 0.8812 - Val Accuracy: 0.8574 - Test Accuracy: 0.8535\n",
      "Epoch 45/500 - Train Accuracy: 0.8799 - Val Accuracy: 0.8557 - Test Accuracy: 0.8516\n",
      "Epoch 46/500 - Train Accuracy: 0.8956 - Val Accuracy: 0.8701 - Test Accuracy: 0.8643\n",
      "Epoch 47/500 - Train Accuracy: 0.8798 - Val Accuracy: 0.8558 - Test Accuracy: 0.8442\n",
      "Epoch 48/500 - Train Accuracy: 0.8806 - Val Accuracy: 0.8534 - Test Accuracy: 0.8518\n",
      "Epoch 49/500 - Train Accuracy: 0.8677 - Val Accuracy: 0.8452 - Test Accuracy: 0.8392\n",
      "Epoch 50/500 - Train Accuracy: 0.8705 - Val Accuracy: 0.8470 - Test Accuracy: 0.8365\n",
      "Epoch 51/500 - Train Accuracy: 0.8914 - Val Accuracy: 0.8635 - Test Accuracy: 0.8588\n",
      "Epoch 52/500 - Train Accuracy: 0.8808 - Val Accuracy: 0.8579 - Test Accuracy: 0.8469\n",
      "Epoch 53/500 - Train Accuracy: 0.8549 - Val Accuracy: 0.8314 - Test Accuracy: 0.8202\n",
      "Epoch 54/500 - Train Accuracy: 0.8653 - Val Accuracy: 0.8377 - Test Accuracy: 0.8280\n",
      "Epoch 55/500 - Train Accuracy: 0.8940 - Val Accuracy: 0.8694 - Test Accuracy: 0.8581\n",
      "Epoch 56/500 - Train Accuracy: 0.8752 - Val Accuracy: 0.8515 - Test Accuracy: 0.8411\n",
      "Epoch 57/500 - Train Accuracy: 0.8793 - Val Accuracy: 0.8539 - Test Accuracy: 0.8471\n",
      "Epoch 58/500 - Train Accuracy: 0.8911 - Val Accuracy: 0.8645 - Test Accuracy: 0.8558\n",
      "Epoch 59/500 - Train Accuracy: 0.8645 - Val Accuracy: 0.8360 - Test Accuracy: 0.8277\n",
      "Epoch 60/500 - Train Accuracy: 0.8647 - Val Accuracy: 0.8379 - Test Accuracy: 0.8312\n",
      "Epoch 61/500 - Train Accuracy: 0.9081 - Val Accuracy: 0.8735 - Test Accuracy: 0.8692\n",
      "Epoch 62/500 - Train Accuracy: 0.9153 - Val Accuracy: 0.8824 - Test Accuracy: 0.8709\n",
      "Epoch 63/500 - Train Accuracy: 0.9254 - Val Accuracy: 0.8900 - Test Accuracy: 0.8828\n",
      "Epoch 64/500 - Train Accuracy: 0.9313 - Val Accuracy: 0.8930 - Test Accuracy: 0.8897\n",
      "Epoch 65/500 - Train Accuracy: 0.9287 - Val Accuracy: 0.8940 - Test Accuracy: 0.8885\n",
      "Epoch 66/500 - Train Accuracy: 0.9200 - Val Accuracy: 0.8821 - Test Accuracy: 0.8767\n",
      "Epoch 67/500 - Train Accuracy: 0.9349 - Val Accuracy: 0.8943 - Test Accuracy: 0.8939\n",
      "Epoch 68/500 - Train Accuracy: 0.9377 - Val Accuracy: 0.9005 - Test Accuracy: 0.8924\n",
      "Epoch 69/500 - Train Accuracy: 0.9296 - Val Accuracy: 0.8875 - Test Accuracy: 0.8836\n",
      "Epoch 70/500 - Train Accuracy: 0.9270 - Val Accuracy: 0.8911 - Test Accuracy: 0.8854\n",
      "Epoch 71/500 - Train Accuracy: 0.9263 - Val Accuracy: 0.8866 - Test Accuracy: 0.8825\n",
      "Epoch 72/500 - Train Accuracy: 0.9287 - Val Accuracy: 0.8911 - Test Accuracy: 0.8818\n",
      "Epoch 73/500 - Train Accuracy: 0.9205 - Val Accuracy: 0.8808 - Test Accuracy: 0.8769\n",
      "Epoch 74/500 - Train Accuracy: 0.9331 - Val Accuracy: 0.8957 - Test Accuracy: 0.8909\n",
      "Epoch 75/500 - Train Accuracy: 0.9304 - Val Accuracy: 0.8907 - Test Accuracy: 0.8853\n",
      "Epoch 76/500 - Train Accuracy: 0.9301 - Val Accuracy: 0.8887 - Test Accuracy: 0.8864\n",
      "Epoch 77/500 - Train Accuracy: 0.9273 - Val Accuracy: 0.8894 - Test Accuracy: 0.8824\n",
      "Epoch 78/500 - Train Accuracy: 0.9244 - Val Accuracy: 0.8842 - Test Accuracy: 0.8797\n",
      "Epoch 79/500 - Train Accuracy: 0.9264 - Val Accuracy: 0.8904 - Test Accuracy: 0.8799\n",
      "Epoch 80/500 - Train Accuracy: 0.9185 - Val Accuracy: 0.8778 - Test Accuracy: 0.8730\n",
      "Epoch 81/500 - Train Accuracy: 0.9528 - Val Accuracy: 0.9063 - Test Accuracy: 0.9045\n",
      "Epoch 82/500 - Train Accuracy: 0.9516 - Val Accuracy: 0.9052 - Test Accuracy: 0.9053\n",
      "Epoch 83/500 - Train Accuracy: 0.9535 - Val Accuracy: 0.9078 - Test Accuracy: 0.9008\n",
      "Epoch 84/500 - Train Accuracy: 0.9545 - Val Accuracy: 0.9081 - Test Accuracy: 0.9050\n",
      "Epoch 85/500 - Train Accuracy: 0.9631 - Val Accuracy: 0.9158 - Test Accuracy: 0.9090\n",
      "Epoch 86/500 - Train Accuracy: 0.9600 - Val Accuracy: 0.9098 - Test Accuracy: 0.9022\n",
      "Epoch 87/500 - Train Accuracy: 0.9513 - Val Accuracy: 0.9015 - Test Accuracy: 0.8944\n",
      "Epoch 88/500 - Train Accuracy: 0.9619 - Val Accuracy: 0.9139 - Test Accuracy: 0.9105\n",
      "Epoch 89/500 - Train Accuracy: 0.9617 - Val Accuracy: 0.9094 - Test Accuracy: 0.9063\n",
      "Epoch 90/500 - Train Accuracy: 0.9594 - Val Accuracy: 0.9062 - Test Accuracy: 0.9028\n",
      "Epoch 91/500 - Train Accuracy: 0.9552 - Val Accuracy: 0.9044 - Test Accuracy: 0.9003\n",
      "Epoch 92/500 - Train Accuracy: 0.9580 - Val Accuracy: 0.9058 - Test Accuracy: 0.9054\n",
      "Epoch 93/500 - Train Accuracy: 0.9657 - Val Accuracy: 0.9133 - Test Accuracy: 0.9097\n",
      "Epoch 94/500 - Train Accuracy: 0.9606 - Val Accuracy: 0.9093 - Test Accuracy: 0.9031\n",
      "Epoch 95/500 - Train Accuracy: 0.9563 - Val Accuracy: 0.9079 - Test Accuracy: 0.8986\n",
      "Epoch 96/500 - Train Accuracy: 0.9567 - Val Accuracy: 0.9049 - Test Accuracy: 0.9022\n",
      "Epoch 97/500 - Train Accuracy: 0.9620 - Val Accuracy: 0.9081 - Test Accuracy: 0.9060\n",
      "Epoch 98/500 - Train Accuracy: 0.9537 - Val Accuracy: 0.8995 - Test Accuracy: 0.8937\n",
      "Epoch 99/500 - Train Accuracy: 0.9575 - Val Accuracy: 0.9053 - Test Accuracy: 0.9014\n",
      "Epoch 100/500 - Train Accuracy: 0.9603 - Val Accuracy: 0.9058 - Test Accuracy: 0.8993\n",
      "Epoch 101/500 - Train Accuracy: 0.9709 - Val Accuracy: 0.9149 - Test Accuracy: 0.9103\n",
      "Epoch 102/500 - Train Accuracy: 0.9745 - Val Accuracy: 0.9216 - Test Accuracy: 0.9154\n",
      "Epoch 103/500 - Train Accuracy: 0.9788 - Val Accuracy: 0.9253 - Test Accuracy: 0.9190\n",
      "Epoch 104/500 - Train Accuracy: 0.9734 - Val Accuracy: 0.9205 - Test Accuracy: 0.9115\n",
      "Epoch 105/500 - Train Accuracy: 0.9708 - Val Accuracy: 0.9128 - Test Accuracy: 0.9057\n",
      "Epoch 106/500 - Train Accuracy: 0.9717 - Val Accuracy: 0.9141 - Test Accuracy: 0.9067\n",
      "Epoch 107/500 - Train Accuracy: 0.9789 - Val Accuracy: 0.9229 - Test Accuracy: 0.9162\n",
      "Epoch 108/500 - Train Accuracy: 0.9758 - Val Accuracy: 0.9175 - Test Accuracy: 0.9073\n",
      "Epoch 109/500 - Train Accuracy: 0.9751 - Val Accuracy: 0.9157 - Test Accuracy: 0.9088\n",
      "Epoch 110/500 - Train Accuracy: 0.9769 - Val Accuracy: 0.9173 - Test Accuracy: 0.9093\n",
      "Epoch 111/500 - Train Accuracy: 0.9780 - Val Accuracy: 0.9180 - Test Accuracy: 0.9112\n",
      "Epoch 112/500 - Train Accuracy: 0.9786 - Val Accuracy: 0.9186 - Test Accuracy: 0.9112\n",
      "Epoch 113/500 - Train Accuracy: 0.9801 - Val Accuracy: 0.9199 - Test Accuracy: 0.9136\n",
      "Epoch 114/500 - Train Accuracy: 0.9755 - Val Accuracy: 0.9166 - Test Accuracy: 0.9096\n",
      "Epoch 115/500 - Train Accuracy: 0.9714 - Val Accuracy: 0.9102 - Test Accuracy: 0.9042\n",
      "Epoch 116/500 - Train Accuracy: 0.9775 - Val Accuracy: 0.9162 - Test Accuracy: 0.9105\n",
      "Epoch 117/500 - Train Accuracy: 0.9828 - Val Accuracy: 0.9213 - Test Accuracy: 0.9150\n",
      "Epoch 118/500 - Train Accuracy: 0.9775 - Val Accuracy: 0.9156 - Test Accuracy: 0.9080\n",
      "Epoch 119/500 - Train Accuracy: 0.9803 - Val Accuracy: 0.9186 - Test Accuracy: 0.9094\n",
      "Epoch 120/500 - Train Accuracy: 0.9760 - Val Accuracy: 0.9126 - Test Accuracy: 0.9092\n",
      "Epoch 121/500 - Train Accuracy: 0.9874 - Val Accuracy: 0.9259 - Test Accuracy: 0.9178\n",
      "Epoch 122/500 - Train Accuracy: 0.9866 - Val Accuracy: 0.9261 - Test Accuracy: 0.9192\n",
      "Epoch 123/500 - Train Accuracy: 0.9862 - Val Accuracy: 0.9211 - Test Accuracy: 0.9162\n",
      "Epoch 124/500 - Train Accuracy: 0.9805 - Val Accuracy: 0.9181 - Test Accuracy: 0.9095\n",
      "Epoch 125/500 - Train Accuracy: 0.9876 - Val Accuracy: 0.9232 - Test Accuracy: 0.9180\n",
      "Epoch 126/500 - Train Accuracy: 0.9891 - Val Accuracy: 0.9256 - Test Accuracy: 0.9190\n",
      "Epoch 127/500 - Train Accuracy: 0.9878 - Val Accuracy: 0.9235 - Test Accuracy: 0.9150\n",
      "Epoch 128/500 - Train Accuracy: 0.9888 - Val Accuracy: 0.9238 - Test Accuracy: 0.9192\n",
      "Epoch 129/500 - Train Accuracy: 0.9916 - Val Accuracy: 0.9275 - Test Accuracy: 0.9203\n",
      "Epoch 130/500 - Train Accuracy: 0.9904 - Val Accuracy: 0.9267 - Test Accuracy: 0.9208\n",
      "Epoch 131/500 - Train Accuracy: 0.9898 - Val Accuracy: 0.9247 - Test Accuracy: 0.9203\n",
      "Epoch 132/500 - Train Accuracy: 0.9888 - Val Accuracy: 0.9234 - Test Accuracy: 0.9169\n",
      "Epoch 133/500 - Train Accuracy: 0.9892 - Val Accuracy: 0.9246 - Test Accuracy: 0.9170\n",
      "Epoch 134/500 - Train Accuracy: 0.9918 - Val Accuracy: 0.9292 - Test Accuracy: 0.9210\n",
      "Epoch 135/500 - Train Accuracy: 0.9894 - Val Accuracy: 0.9280 - Test Accuracy: 0.9189\n",
      "Epoch 136/500 - Train Accuracy: 0.9909 - Val Accuracy: 0.9269 - Test Accuracy: 0.9197\n",
      "Epoch 137/500 - Train Accuracy: 0.9909 - Val Accuracy: 0.9239 - Test Accuracy: 0.9182\n",
      "Epoch 138/500 - Train Accuracy: 0.9888 - Val Accuracy: 0.9235 - Test Accuracy: 0.9141\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# GPU 메모리 즉시 사용 활성화\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        # GPU 메모리 즉시 사용 설정\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        print('GPU 메모리 즉시 사용이 활성화되었습니다.')\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 실행 중 에러 발생 시\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def normalization(train_images, test_images):\n",
    "    mean = np.mean(train_images, axis=(0, 1, 2, 3))\n",
    "    std = np.std(train_images, axis=(0, 1, 2, 3))\n",
    "    train_images = (train_images - mean) / (std + 1e-7)\n",
    "    test_images = (test_images - mean) / (std + 1e-7)\n",
    "    return train_images, test_images\n",
    "\n",
    "\n",
    "def load_images():\n",
    "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "    train_images = train_images.astype(np.float32)\n",
    "    test_images = test_images.astype(np.float32)\n",
    "\n",
    "    (train_images, test_images) = normalization(train_images, test_images)\n",
    "\n",
    "    train_labels = to_categorical(train_labels, 10)\n",
    "    test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "    # Randomly select 20% of the training data as validation data\n",
    "    validation_split = 0.2\n",
    "    split_index = int(train_images.shape[0] * (1 - validation_split))\n",
    "    train_images, val_images = train_images[:split_index], train_images[split_index:]\n",
    "    train_labels, val_labels = train_labels[:split_index], train_labels[split_index:]\n",
    "\n",
    "    return train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
    "class EpochEndCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_data, val_data, test_data):\n",
    "        super(EpochEndCallback, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_loss, train_accuracy = self.model.evaluate(self.train_data[0], self.train_data[1], verbose=0)\n",
    "        val_loss, val_accuracy = self.model.evaluate(self.val_data[0], self.val_data[1], verbose=0)\n",
    "        test_loss, test_accuracy = self.model.evaluate(self.test_data[0], self.test_data[1], verbose=0)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{training_epochs} - '\n",
    "              f'Train Accuracy: {train_accuracy:.4f} - '\n",
    "              f'Val Accuracy: {val_accuracy:.4f} - '\n",
    "              f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "class ConvBNRelu(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size=3, strides=1, padding='SAME', weight_decay=0.0005, rate=0.4, drop=True):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.drop = drop\n",
    "        self.conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                                        padding=padding, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        self.dropOut = keras.layers.Dropout(rate=rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        layer = self.conv(inputs)\n",
    "        layer = tf.nn.relu(layer)\n",
    "        layer = self.batchnorm(layer)\n",
    "        if self.drop:\n",
    "            layer = self.dropOut(layer)\n",
    "\n",
    "        return layer\n",
    "\n",
    "class VGG16Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16Model, self).__init__()\n",
    "        self.conv0 = ConvBNRelu(filters=64, kernel_size=[3, 3], rate=0.3)\n",
    "        self.conv1 = ConvBNRelu(filters=64, kernel_size=[3, 3])\n",
    "        self.conv2 = ConvBNRelu(filters=64, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling1 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv3 = ConvBNRelu(filters=128, kernel_size=[3, 3])\n",
    "        self.conv4 = ConvBNRelu(filters=128, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling2 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv5 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv6 = ConvBNRelu(filters=256, kernel_size=[3, 3])\n",
    "        self.conv7 = ConvBNRelu(filters=256, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling3 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv11 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv12 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv13 = ConvBNRelu(filters=512, kernel_size=[3, 3], drop=False)\n",
    "        self.maxPooling5 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.conv14 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv15 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv16 = ConvBNRelu(filters=512, kernel_size=[3, 3])\n",
    "        self.conv17 = ConvBNRelu(filters=512, kernel_size=[3, 3],drop=False)\n",
    "        self.maxPooling6 = keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flat = keras.layers.Flatten()\n",
    "        self.dropOut = keras.layers.Dropout(rate=0.5)\n",
    "        self.dense1 = keras.layers.Dense(units=512,\n",
    "                                         activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "        self.dense11 = keras.layers.Dense(units=512,\n",
    "                                         activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "        self.dense2 = keras.layers.Dense(units=10)\n",
    "        self.softmax = keras.layers.Activation('softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv0(inputs, training=training)\n",
    "        net = self.conv1(net, training=training)\n",
    "        net = self.conv2(net, training=training)\n",
    "        net = self.maxPooling1(net)\n",
    "        net = self.conv3(net, training=training)\n",
    "        net = self.conv4(net, training=training)\n",
    "        net = self.maxPooling2(net)\n",
    "        net = self.conv5(net, training=training)\n",
    "        net = self.conv6(net, training=training)\n",
    "        net = self.conv7(net, training=training)\n",
    "        net = self.maxPooling3(net)\n",
    "        net = self.conv11(net, training=training)\n",
    "        net = self.conv12(net, training=training)\n",
    "        net = self.conv13(net, training=training)\n",
    "        net = self.maxPooling5(net)\n",
    "        net = self.conv14(net, training=training)\n",
    "        net = self.conv15(net, training=training)\n",
    "        net = self.conv16(net, training=training)\n",
    "        net = self.conv17(net, training=training)\n",
    "        net = self.maxPooling6(net)\n",
    "        net = self.dropOut(net)\n",
    "        net = self.flat(net)\n",
    "        net = self.dense1(net)\n",
    "        net = self.dense11(net)\n",
    "        net = self.dense2(net)\n",
    "        net = self.softmax(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(tf.__version__)\n",
    "    print(keras.__version__)\n",
    "\n",
    "    training_epochs = 500\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.1\n",
    "    momentum = 0.9\n",
    "    lr_decay = 1e-6\n",
    "    lr_drop = 20\n",
    "\n",
    "    tf.random.set_seed(777)\n",
    "\n",
    "    def lr_scheduler(epoch):\n",
    "        return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "\n",
    "    reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    train_images, train_labels, val_images, val_labels, test_images, test_labels = load_images()\n",
    "\n",
    "\n",
    "    # data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    model = VGG16Model()\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,\n",
    "                                        decay=1e-6, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.fit(datagen.flow(train_images, train_labels,\n",
    "                        batch_size=batch_size), \n",
    "          epochs=training_epochs, \n",
    "          verbose=0,  # 출력 숨기기\n",
    "          callbacks=[reduce_lr, EpochEndCallback((train_images, train_labels), (val_images, val_labels), (test_images, test_labels))],\n",
    "          steps_per_epoch=train_images.shape[0] // batch_size,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba510be-6ae0-478b-a8fc-f339a9ebe8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
